{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment1_NaiveBayes.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtbXg2SGdOS+3P2HK5AZjK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment1_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoyWL2I4hcNZ"
      },
      "source": [
        "# Importing libraries that will be used \n",
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import re\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFuKWcjuKGIU"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ALIRR75kHO2"
      },
      "source": [
        "# Untar the dataset\n",
        "my_tar = tarfile.open('/content/lingspam_public.tar.gz')\n",
        "my_tar.extractall('/content/') \n",
        "my_tar.close()\n",
        "train_path = '/content/lingspam_public/lemm_stop/part1'  # for training      #spams: spmsg*.txt\n",
        "test_path = '/content/lingspam_public/lemm_stop/part10'   # for testing"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "0h8XN_Db61aE",
        "outputId": "de6abe0c-c04f-4e59-967e-e3f10bc6f45d"
      },
      "source": [
        "# Changing the data format of the dataset\n",
        "def to_dict (path):\n",
        "  data_dict = dict()\n",
        "  data_dict[1] = []   # Spam \n",
        "  data_dict[0] = []   # Not Spam\n",
        "  for file in os.listdir(path):  \n",
        "    doc = open (path + '/'+ file, 'r')\n",
        "    if 'spmsg' in file:\n",
        "      data_dict[1].append(doc.read())\n",
        "    else:\n",
        "      data_dict[0].append(doc.read())\n",
        "  print ('number of spams: {}'.format(len(data_dict[1])))\n",
        "  print ('number of not_spams: {}'.format(len(data_dict[0])))\n",
        "  sns.countplot(x=['spam']* len(data_dict[1])+['nonspam']* len(data_dict[0]))\n",
        "  plt.show()  \n",
        "  n_docs = len(os.listdir(path))\n",
        "  return data_dict, n_docs\n",
        "\n",
        "print('training set:')\n",
        "training, n_docs_train = to_dict (train_path)\n",
        "print('number of doc: {}'.format(n_docs_train))\n",
        "\n",
        "print('\\ntesting set:')\n",
        "testing, n_docs_test = to_dict (test_path)\n",
        "print('number of doc: {}'.format(n_docs_test))\n",
        "\n",
        "# Data formating for using functions built in Sklearn\n",
        "X_train = training[0]+ training[1]\n",
        "y_train = [0]*len(training[0]) + [1]*len(training[1])\n",
        "\n",
        "X_test = testing[0]+ testing[1]\n",
        "y_true = [0]*len(testing[0]) + [1]*len(testing[1])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set:\n",
            "number of spams: 48\n",
            "number of not_spams: 241\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of doc: 289\n",
            "\n",
            "testing set:\n",
            "number of spams: 49\n",
            "number of not_spams: 242\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of doc: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e36hb6INe7ZA"
      },
      "source": [
        "# Building a Naive Bayes classifier from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7vd1ITkgIlk"
      },
      "source": [
        "# Defining some util functions \n",
        "\n",
        "## Defining function to tokenize the documents\n",
        "def tokenizer (doc):\n",
        "  doc = doc.lower() # Lowercase documents\n",
        "  return re.split(\"\\W+\", doc)   # return a list of tokens without punctuations\n",
        "\n",
        "## Defining a function to count frequency of words in each class\n",
        "def count_words(data_dict):\n",
        "  tf = {}\n",
        "  tf[0], tf[1] = {}, {}\n",
        "  all_docs = data_dict[0] + data_dict[1]\n",
        "  temp0, temp1 = {},{}\n",
        "  for doc in data_dict[0]:\n",
        "    for token in tokenizer(doc):\n",
        "      temp0[token] = temp0.get(token, 0)+1\n",
        "    tf[0] = temp0\n",
        "  for doc in data_dict[1]: \n",
        "    for token in tokenizer(doc):\n",
        "      temp1[token] = temp1.get(token, 0)+1\n",
        "    tf[1] = temp1\n",
        "  # print('sum of tf0: {}, sum of tf1 {}'. format(sum(tf[0].values()), sum(tf[1].values())))\n",
        "  return tf\n",
        "\n",
        "## Defining a function to store tokens in classes with two different BOWS\n",
        "def to_bow (data_dict):\n",
        "  bows = {}\n",
        "  bows[0], bows[1] = [], []\n",
        "  for doc in data_dict[0]:\n",
        "    bows[0].extend(tokenizer(doc))\n",
        "  for doc in data_dict[1]:\n",
        "    bows[1].extend(tokenizer(doc))\n",
        "  return bows\n",
        "\n",
        "## Defining a function to calculate log prior for each class\n",
        "### Return a dict of classes' log priors\n",
        "def logprior(data_dict, n_docs):\n",
        "  logprior = {}\n",
        "  n_spams = len(data_dict[1])\n",
        "  n_nonspams = len(data_dict[0])\n",
        "  print('length of spams: {}, nonspam: {}'.format(n_spams, n_nonspams))\n",
        "  logprior[1] = np.log(n_spams/n_docs)\n",
        "  logprior[0] = np.log(n_nonspams/n_docs)\n",
        "  return logprior\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMiZjikgknL6"
      },
      "source": [
        "# Defining TRAINING and TESTING functions\n",
        "\n",
        "## Defining a function to train the Naive Bayes model \n",
        "### Returning logpriors of classes, a word loglikelihood list , set of vocabulary\n",
        "def train_NB (training, alpha):\n",
        "  bows = to_bow (training) \n",
        "  set_V = set(to_bow (training)[1] + to_bow (training)[0])\n",
        "  tf = count_words(training)\n",
        "  logpriors = logprior(training,n_docs_train)\n",
        "  # calculating loglikelihood for each class\n",
        "  loglikelihood = {}\n",
        "  loglikelihood[0], loglikelihood[1] = {}, {}\n",
        "  for c in training.keys():\n",
        "    bow_c = bows[c]\n",
        "    # print('.....length of bow {}:  {}.......'.format(c, len(bow_c)))\n",
        "    loglikelihood_c = {}\n",
        "    for w in set_V:\n",
        "      if w in tf[c]:\n",
        "        count_w = tf[c][w]  \n",
        "      else:\n",
        "        count_w = 0\n",
        "      # print('count ---{} ---in c: {} '.format(w, count_w))\n",
        "      loglikelihood_w = np.log((count_w + alpha)/(len(bow_c)+(len(set_V)*alpha)))\n",
        "      loglikelihood_c[w] = loglikelihood_w\n",
        "    loglikelihood[c] = loglikelihood_c\n",
        "  return logpriors, loglikelihood, set_V\n",
        "\n",
        "\n",
        "## Defining a function for NaiveBayes testing, returning predicted class\n",
        "def test_NB (testing):\n",
        "  prediction = []\n",
        "  X_test = testing[0]+ testing[1]\n",
        "  # Recalling BOW, log prior of each class, and vocabulary from training\n",
        "  spam_bow = training_result[1][1]\n",
        "  nonspam_bow = training_result[1][0]\n",
        "  spam_logprior = training_result[0][1]\n",
        "  nonspam_logprior = training_result[0][0]\n",
        "  set_V = training_result[2]\n",
        "  \n",
        "  ## Calculating probability of class occurred given trained class priors,\n",
        "  ## and trained word likelihoods\n",
        "  for doc in X_test:\n",
        "    spam_loglikelihoods, nonspam_loglikelihoods = [], []\n",
        "    spam_score=0\n",
        "    nonspam_score = 0\n",
        "    for w in tokenizer(doc):\n",
        "      if w not in set_V: \n",
        "        continue\n",
        "      if w in spam_bow.keys():\n",
        "        spam_score += spam_bow[w]\n",
        "      if w in nonspam_bow.keys():\n",
        "        nonspam_score += nonspam_bow[w]\n",
        "    spam_score += spam_logprior\n",
        "    nonspam_score += nonspam_logprior\n",
        "\n",
        "    ## Determining class by taking class\n",
        "    if spam_score > nonspam_score:\n",
        "      prediction.append(1)\n",
        "    else:\n",
        "      prediction.append(0)\n",
        "  return prediction"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQu-1F9VsVsr"
      },
      "source": [
        "# Printing model performance \n",
        "def printing_eval_scores (y_true, y_pred):\n",
        "  print('accuracy score: {}'.format(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
        "  print('precision score: {}'.format(sklearn.metrics.precision_score(y_true, y_pred)))\n",
        "  print('recall score: {}'.format(sklearn.metrics.recall_score(y_true, y_pred)))\n",
        "  print('F1 score: {}'.format(sklearn.metrics.f1_score(y_true, y_pred)))\n",
        "  print(classification_report(y_true, y_pred))\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gLiuGJR-dTA",
        "outputId": "cb7e0379-938b-4f13-c7e6-20822577f467"
      },
      "source": [
        "# Testing alphas\n",
        "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
        "for alpha in alphas:\n",
        "  print('---------------------------- \\nalpha = {}'.format(alpha))\n",
        "  # Training model on the training set\n",
        "  training_result = train_NB (training, alpha)\n",
        "\n",
        "  # Making prediction\n",
        "  y_pred = test_NB (testing)\n",
        "  ## on training set\n",
        "  print('Model performance on training set:')\n",
        "  printing_eval_scores (y_train, test_NB(training))\n",
        "\n",
        "  ## on test set\n",
        "  print('\\nModel performance on test set:')\n",
        "  printing_eval_scores (y_true, y_pred)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------- \n",
            "alpha = 0.1\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9347079037800687\n",
            "precision score: 0.7678571428571429\n",
            "recall score: 0.8775510204081632\n",
            "F1 score: 0.819047619047619\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96       242\n",
            "           1       0.77      0.88      0.82        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.87      0.91      0.89       291\n",
            "weighted avg       0.94      0.93      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.2\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9381443298969072\n",
            "precision score: 0.7719298245614035\n",
            "recall score: 0.8979591836734694\n",
            "F1 score: 0.8301886792452831\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.95      0.96       242\n",
            "           1       0.77      0.90      0.83        49\n",
            "\n",
            "    accuracy                           0.94       291\n",
            "   macro avg       0.88      0.92      0.90       291\n",
            "weighted avg       0.94      0.94      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.3\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9347079037800687\n",
            "precision score: 0.75\n",
            "recall score: 0.9183673469387755\n",
            "F1 score: 0.8256880733944955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       242\n",
            "           1       0.75      0.92      0.83        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.87      0.93      0.89       291\n",
            "weighted avg       0.94      0.93      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.4\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9347079037800687\n",
            "precision score: 0.75\n",
            "recall score: 0.9183673469387755\n",
            "F1 score: 0.8256880733944955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       242\n",
            "           1       0.75      0.92      0.83        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.87      0.93      0.89       291\n",
            "weighted avg       0.94      0.93      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.5\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9347079037800687\n",
            "precision score: 0.75\n",
            "recall score: 0.9183673469387755\n",
            "F1 score: 0.8256880733944955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       242\n",
            "           1       0.75      0.92      0.83        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.87      0.93      0.89       291\n",
            "weighted avg       0.94      0.93      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.6\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9347079037800687\n",
            "precision score: 0.75\n",
            "recall score: 0.9183673469387755\n",
            "F1 score: 0.8256880733944955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       242\n",
            "           1       0.75      0.92      0.83        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.87      0.93      0.89       291\n",
            "weighted avg       0.94      0.93      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.7\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9347079037800687\n",
            "precision score: 0.75\n",
            "recall score: 0.9183673469387755\n",
            "F1 score: 0.8256880733944955\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.94      0.96       242\n",
            "           1       0.75      0.92      0.83        49\n",
            "\n",
            "    accuracy                           0.93       291\n",
            "   macro avg       0.87      0.93      0.89       291\n",
            "weighted avg       0.94      0.93      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.8\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9381443298969072\n",
            "precision score: 0.7540983606557377\n",
            "recall score: 0.9387755102040817\n",
            "F1 score: 0.8363636363636363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96       242\n",
            "           1       0.75      0.94      0.84        49\n",
            "\n",
            "    accuracy                           0.94       291\n",
            "   macro avg       0.87      0.94      0.90       291\n",
            "weighted avg       0.95      0.94      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 0.9\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9896193771626297\n",
            "precision score: 0.9411764705882353\n",
            "recall score: 1.0\n",
            "F1 score: 0.9696969696969697\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       241\n",
            "           1       0.94      1.00      0.97        48\n",
            "\n",
            "    accuracy                           0.99       289\n",
            "   macro avg       0.97      0.99      0.98       289\n",
            "weighted avg       0.99      0.99      0.99       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9381443298969072\n",
            "precision score: 0.7540983606557377\n",
            "recall score: 0.9387755102040817\n",
            "F1 score: 0.8363636363636363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96       242\n",
            "           1       0.75      0.94      0.84        49\n",
            "\n",
            "    accuracy                           0.94       291\n",
            "   macro avg       0.87      0.94      0.90       291\n",
            "weighted avg       0.95      0.94      0.94       291\n",
            "\n",
            "---------------------------- \n",
            "alpha = 1.0\n",
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9896193771626297\n",
            "precision score: 0.9411764705882353\n",
            "recall score: 1.0\n",
            "F1 score: 0.9696969696969697\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       241\n",
            "           1       0.94      1.00      0.97        48\n",
            "\n",
            "    accuracy                           0.99       289\n",
            "   macro avg       0.97      0.99      0.98       289\n",
            "weighted avg       0.99      0.99      0.99       289\n",
            "\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9381443298969072\n",
            "precision score: 0.7540983606557377\n",
            "recall score: 0.9387755102040817\n",
            "F1 score: 0.8363636363636363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96       242\n",
            "           1       0.75      0.94      0.84        49\n",
            "\n",
            "    accuracy                           0.94       291\n",
            "   macro avg       0.87      0.94      0.90       291\n",
            "weighted avg       0.95      0.94      0.94       291\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcOl5T4TGHWJ",
        "outputId": "da5f9c09-8c0e-4681-9fd1-1292a5f4bfbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "selected_alpha = 1\n",
        "# Training model on the training set\n",
        "training_result = train_NB (training, alpha = selected_alpha)\n",
        "\n",
        "# Making prediction\n",
        "y_pred = test_NB (testing)\n",
        "\n",
        "## on training set\n",
        "print('Model performance on training set:')\n",
        "printing_eval_scores (y_train, test_NB(training))\n",
        "\n",
        "## on test set\n",
        "print('--------------------------------')\n",
        "print('\\nModel performance on test set:')\n",
        "printing_eval_scores (y_true, y_pred)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of spams: 48, nonspam: 241\n",
            "Model performance on training set:\n",
            "accuracy score: 0.9896193771626297\n",
            "precision score: 0.9411764705882353\n",
            "recall score: 1.0\n",
            "F1 score: 0.9696969696969697\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99       241\n",
            "           1       0.94      1.00      0.97        48\n",
            "\n",
            "    accuracy                           0.99       289\n",
            "   macro avg       0.97      0.99      0.98       289\n",
            "weighted avg       0.99      0.99      0.99       289\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "Model performance on test set:\n",
            "accuracy score: 0.9381443298969072\n",
            "precision score: 0.7540983606557377\n",
            "recall score: 0.9387755102040817\n",
            "F1 score: 0.8363636363636363\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96       242\n",
            "           1       0.75      0.94      0.84        49\n",
            "\n",
            "    accuracy                           0.94       291\n",
            "   macro avg       0.87      0.94      0.90       291\n",
            "weighted avg       0.95      0.94      0.94       291\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "TN4TD6l94epZ",
        "outputId": "cc599f74-5d3f-477c-9edd-e2fbae59fe2e"
      },
      "source": [
        "# printing and visualize the confusion metrics\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print('confusion metrics \\n', cm)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [0,1])\n",
        "disp.plot(include_values = True, values_format = 'd')\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion metrics \n",
            " [[227  15]\n",
            " [  3  46]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f311b944310>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrofQiv0fFEv"
      },
      "source": [
        "# Building a Naive Bayes classifier from Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "KvLBIIvzn9j8",
        "outputId": "c47f23ff-e583-4a94-d610-300f22d808a6"
      },
      "source": [
        "# Creating a vectorizer model that converts a collection of text documents to a matrix of token counts\n",
        "vectorizer = CountVectorizer(lowercase = True)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_test_vec = vectorizer.transform(X_test)\n",
        "# Converting  sparse matrix to a dense matrix\n",
        "X_train_vec = X_train_vec.toarray()\n",
        "X_test_vec = X_test_vec.toarray()\n",
        "\n",
        "# Creating NB classifier\n",
        "nb_2 = MultinomialNB()\n",
        "\n",
        "# Fitting the model into the training set for training\n",
        "nb_2.fit(X_train_vec, y_train)\n",
        "\n",
        "# Using NB clssifier to make prediction on test set\n",
        "y_pred_2 = nb_2.predict(X_test_vec)\n",
        "\n",
        "# Printing model performance \n",
        "## on training set\n",
        "print ('on training set')\n",
        "printing_eval_scores (y_train, nb_2.predict(X_train_vec))\n",
        "\n",
        "## on test set\n",
        "print ('\\n-------------------------------\\non test set')\n",
        "printing_eval_scores (y_true, y_pred_2)\n",
        "\n",
        "# printing and visualize the confusion metrics\n",
        "cm = confusion_matrix(y_true, y_pred_2)\n",
        "print('confusion metrics \\n', cm)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = [0,1])\n",
        "disp.plot(include_values = True, values_format = 'd')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "on training set\n",
            "accuracy score: 0.9965397923875432\n",
            "precision score: 0.9795918367346939\n",
            "recall score: 1.0\n",
            "F1 score: 0.9896907216494846\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       241\n",
            "           1       0.98      1.00      0.99        48\n",
            "\n",
            "    accuracy                           1.00       289\n",
            "   macro avg       0.99      1.00      0.99       289\n",
            "weighted avg       1.00      1.00      1.00       289\n",
            "\n",
            "\n",
            "-------------------------------\n",
            "on test set\n",
            "accuracy score: 0.9896907216494846\n",
            "precision score: 1.0\n",
            "recall score: 0.9387755102040817\n",
            "F1 score: 0.968421052631579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       242\n",
            "           1       1.00      0.94      0.97        49\n",
            "\n",
            "    accuracy                           0.99       291\n",
            "   macro avg       0.99      0.97      0.98       291\n",
            "weighted avg       0.99      0.99      0.99       291\n",
            "\n",
            "confusion metrics \n",
            " [[242   0]\n",
            " [  3  46]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f311b605390>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}