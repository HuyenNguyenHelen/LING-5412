{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpe2HW+qtHTDh+EYRwNd5O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment2_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRoN8MBWFLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ab764af-3739-4654-cf4b-ace94976899f"
      },
      "source": [
        "# Importing libraries that will be used \n",
        "import numpy as np\n",
        "import tarfile\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "#from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNqCpCGDJrZz"
      },
      "source": [
        "# Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Krvu3FbyUwOn"
      },
      "source": [
        "# Untar the dataset\n",
        "my_tar = tarfile.open('/content/review_polarity.tar.gz')\n",
        "my_tar.extractall('/content/') \n",
        "my_tar.close()\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCAKXzrfWYEc",
        "outputId": "f8cffb87-7673-412d-c8c4-410f70ddbccc"
      },
      "source": [
        "# Exploring the data sizes\n",
        "\n",
        "paths_pos = glob.glob('/content/txt_sentoken/pos/*.txt')\n",
        "paths_neg = glob.glob('/content/txt_sentoken/neg/*.txt')\n",
        "pos_neg_paths = paths_pos + paths_neg\n",
        "\n",
        "n_pos = len(paths_pos)\n",
        "n_neg = len(paths_neg)\n",
        "\n",
        "print('the number of positive instances: {} \\nthe number of positive instances: {}'.format(n_pos, n_neg))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the number of positive instances: 1000 \n",
            "the number of positive instances: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_HBaup_JiGU"
      },
      "source": [
        "# Exploring the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe-1M-pGYxd2",
        "outputId": "a04526fc-95a3-4399-b9cc-c5099cc682d1"
      },
      "source": [
        "# Exploring the words in the dataset\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def tokenizer (doc):\n",
        "  #doc = doc.lower() # Lowercase documents\n",
        "  return re.split(\"\\W+\", doc)   # return a list of tokens without punctuations\n",
        "\n",
        "# def BOW (doc):\n",
        "#   bow = set()\n",
        "#   for token in tokenizer (doc):\n",
        "#     bow.add(token)\n",
        "#   return list(bow)\n",
        "\n",
        "#def word_counter (doc):\n",
        "\n",
        "def stopword_remover (bow):\n",
        "  filtered_bow = [w for w in bow if not w.lower() in stopwords]\n",
        "  return filtered_bow\n",
        "\n",
        "def top_freq_w (freq_dic, top_n, stopword_removing = ''):\n",
        "  sorted_dic = {k:v for k, v in sorted(freq_dic.items(), key = lambda item: item[1], reverse=True)}\n",
        "  if stopword_removing is False:\n",
        "    return {k:v for k, v in list(sorted_dic.items())[:top_n]}\n",
        "  elif stopword_removing is True:\n",
        "    filtered_dic = {k: v for k, v in sorted_dic.items() if k not in stopwords}\n",
        "    return {k:v for k, v in list(filtered_dic.items())[:top_n]}\n",
        "  \n",
        "\n",
        "\n",
        "word_freq = {}\n",
        "for path in pos_neg_paths:\n",
        "  fo = open(path)\n",
        "  doc = fo.read()\n",
        "  for token in tokenizer (doc):\n",
        "    word_freq[token] = word_freq.get(token,0)+1\n",
        "\n",
        "top_100_w = top_freq_w(word_freq, 100, stopword_removing = False) \n",
        "\n",
        "print('the number of unique words in the dataset: ', len(word_freq.keys()))\n",
        "print ('top 100 most frequent words:\\n', top_100_w )\n",
        "print('\\nthe number of words in the top 100 which are stopwords: ', len([w for w in top_100_w.keys() if w in stopwords]))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "the number of unique words in the dataset:  39697\n",
            "top 100 most frequent words:\n",
            " {'the': 76529, 'a': 38106, 'and': 35576, 'of': 34123, 'to': 31937, 'is': 25195, 'in': 21822, 's': 18513, 'it': 16107, 'that': 15924, 'as': 11378, 'with': 10792, 'for': 9961, 'his': 9587, 'this': 9578, 'film': 9517, 'i': 8889, 'he': 8864, 'but': 8634, 'on': 7385, 'are': 6949, 't': 6410, 'by': 6261, 'be': 6174, 'one': 5852, 'movie': 5771, 'an': 5744, 'who': 5692, 'not': 5577, 'you': 5316, 'from': 4999, 'at': 4986, 'was': 4940, 'have': 4901, 'they': 4825, 'has': 4719, 'her': 4522, 'all': 4373, 'there': 3770, 'like': 3690, 'so': 3683, 'out': 3637, 'about': 3523, 'up': 3405, 'more': 3347, 'what': 3322, 'when': 3258, 'which': 3161, 'or': 3148, 'she': 3141, 'their': 3122, 'some': 2985, 'just': 2905, 'can': 2882, 'if': 2799, 'we': 2775, 'him': 2633, 'into': 2623, 'even': 2565, 'only': 2495, 'than': 2474, 'no': 2472, 'good': 2411, 'time': 2411, 'most': 2306, 'its': 2270, 'will': 2216, 'story': 2169, '': 2152, 'would': 2109, 'been': 2050, 'much': 2049, 'character': 2020, 'also': 1967, 'get': 1949, 'other': 1948, 'do': 1915, 'two': 1911, 'well': 1906, 'them': 1877, 'very': 1863, 'characters': 1859, 'first': 1836, 'after': 1762, 'see': 1749, 'way': 1693, 'because': 1684, 'make': 1642, 'life': 1586, 'off': 1581, 'too': 1577, 'any': 1574, 'does': 1568, 'really': 1558, 'had': 1546, 'while': 1539, 'films': 1536, 'how': 1517, 'plot': 1513, 'little': 1501}\n",
            "\n",
            "the number of words in the top 100 which are stopwords:  74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "XZlPlHizshiT",
        "outputId": "31d929c1-d9ab-456d-d327-875f87afbef2"
      },
      "source": [
        "# Reformating the dataset into csv for convenience \n",
        "def to_df (folder):\n",
        "  data_dic = {}\n",
        "  data_dic['doc'], data_dic['label'] = [], []\n",
        "  for file in folder:\n",
        "    fo = open(file)\n",
        "    doc = fo.read()\n",
        "    data_dic['doc'].append(doc)\n",
        "    if 'pos' in file:\n",
        "      data_dic['label'].append(1)\n",
        "    elif 'neg' in file:\n",
        "      data_dic['label'].append(0)\n",
        "    else:\n",
        "      print('error', file)\n",
        "  df = pd.DataFrame.from_dict(data_dic)\n",
        "  return df\n",
        "    \n",
        "data = to_df(pos_neg_paths)\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ingredients : london gal , fate , true love , ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>quiz show , an almost perfectly accurate true ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>after a stylistic detour with mrs . \\nparker a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>all great things come to an end , and the dot-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>melvin udall is a heartless man . \\nhe spends ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 doc  label\n",
              "0  ingredients : london gal , fate , true love , ...      1\n",
              "1  quiz show , an almost perfectly accurate true ...      1\n",
              "2  after a stylistic detour with mrs . \\nparker a...      1\n",
              "3  all great things come to an end , and the dot-...      1\n",
              "4  melvin udall is a heartless man . \\nhe spends ...      1"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEFEUMkgJYGz"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "jGSEg3J8ktsC",
        "outputId": "e1163f50-5451-4d13-e66d-6e4341ef4f95"
      },
      "source": [
        "# Data preprocessing\n",
        "stemmer = nltk.stem.porter.PorterStemmer()\n",
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "def preprocessor (text):\n",
        "  ## removing punctuations and characters\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  # stripping\n",
        "  text = ' '.join([w.strip() for w in text.split()])\n",
        "  # print(text)\n",
        "  ## lowcasing\n",
        "  text = text.lower()\n",
        "  # ## removing stopword\n",
        "  text = stopword_remover (text.split())\n",
        "  # ##stemmming\n",
        "  text = [stemmer.stem(w) for w in text]\n",
        "  # ## lematization\n",
        "  text = [lemmatizer.lemmatize(w) for w in text]\n",
        "  return ' '.join([w for w in text])\n",
        "\n",
        "data['doc'] = data['doc'].apply(lambda x:  preprocessor (x) )\n",
        "data "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>doc</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ingredi london gal fate true love run joke mon...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>quiz show almost perfectli accur true stori ba...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>stylist detour mr parker viciou circl despit u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>great thing come end dotcom era embodi perfect...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>melvin udal heartless man spend day insid spac...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>often similar littl boy lost park right ventur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>13th warrior reek badli melodrama poor act car...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>accord hitchcock variou filmmak isol motel din...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>warn follow review contain spoiler cast gari s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>went saw film right call battlefield earth nev...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    doc  label\n",
              "0     ingredi london gal fate true love run joke mon...      1\n",
              "1     quiz show almost perfectli accur true stori ba...      1\n",
              "2     stylist detour mr parker viciou circl despit u...      1\n",
              "3     great thing come end dotcom era embodi perfect...      1\n",
              "4     melvin udal heartless man spend day insid spac...      1\n",
              "...                                                 ...    ...\n",
              "1995  often similar littl boy lost park right ventur...      0\n",
              "1996  13th warrior reek badli melodrama poor act car...      0\n",
              "1997  accord hitchcock variou filmmak isol motel din...      0\n",
              "1998  warn follow review contain spoiler cast gari s...      0\n",
              "1999  went saw film right call battlefield earth nev...      0\n",
              "\n",
              "[2000 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4FEl86wJ2Zv"
      },
      "source": [
        "# Developing a Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10p5-fLZLetp"
      },
      "source": [
        "# Preparing vocabulary\n",
        "## As required, we will use 1000 most frequent word, excluding stopwords\n",
        "### Preprocessing data for building vocabulary\n",
        "cleaned_word_freq = {}\n",
        "for path in pos_neg_paths:\n",
        "  fo = open(path)\n",
        "  doc = fo.read()\n",
        "  cleaned_doc = preprocessor(doc)\n",
        "  for token in tokenizer (cleaned_doc):\n",
        "    cleaned_word_freq[token] = cleaned_word_freq.get(token,0)+1\n",
        "\n",
        "vocabulary = top_freq_w(cleaned_word_freq, 1000, stopword_removing = True) \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPM073ASYl5i"
      },
      "source": [
        "# Feature engineering\n",
        "# def feature_extractor (doc):\n",
        "#   doc_vec = []\n",
        "#   for feature in vocabulary.keys():\n",
        "#     feature_count = 0\n",
        "#     if feature in tokenizer (doc):\n",
        "#       feature_count+=1\n",
        "#     else:\n",
        "#       feature_count+=0\n",
        "#     doc_vec.append(feature_count) \n",
        "#   return doc_vec\n",
        "\n",
        "def feature_extractor (doc):\n",
        "  doc_vec = []\n",
        "  token_list = tokenizer (doc)\n",
        "  for feature in vocabulary.keys():\n",
        "    # feature_count=0\n",
        "    feature_count = token_list.count(feature)\n",
        "    doc_vec.append(feature_count) \n",
        "  return doc_vec\n",
        "\n",
        "X = data['doc'].apply(lambda x: feature_extractor(x))\n",
        "y = data['label']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-qW3hQL2GFe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "0e7ff1e6-0c88-46e1-800b-c9bf8efe3286"
      },
      "source": [
        "\n",
        "X = X.apply(pd.Series)\n",
        "X.columns = vocabulary.keys()\n",
        "X"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film</th>\n",
              "      <th>movi</th>\n",
              "      <th>one</th>\n",
              "      <th>like</th>\n",
              "      <th>charact</th>\n",
              "      <th>get</th>\n",
              "      <th>make</th>\n",
              "      <th>time</th>\n",
              "      <th>scene</th>\n",
              "      <th>even</th>\n",
              "      <th>good</th>\n",
              "      <th>play</th>\n",
              "      <th>stori</th>\n",
              "      <th>see</th>\n",
              "      <th>would</th>\n",
              "      <th>much</th>\n",
              "      <th>also</th>\n",
              "      <th>go</th>\n",
              "      <th>way</th>\n",
              "      <th>seem</th>\n",
              "      <th>look</th>\n",
              "      <th>end</th>\n",
              "      <th>two</th>\n",
              "      <th>take</th>\n",
              "      <th>first</th>\n",
              "      <th>come</th>\n",
              "      <th>well</th>\n",
              "      <th>work</th>\n",
              "      <th>thing</th>\n",
              "      <th>year</th>\n",
              "      <th>realli</th>\n",
              "      <th>plot</th>\n",
              "      <th>know</th>\n",
              "      <th>perform</th>\n",
              "      <th>littl</th>\n",
              "      <th>life</th>\n",
              "      <th>peopl</th>\n",
              "      <th>love</th>\n",
              "      <th>could</th>\n",
              "      <th>bad</th>\n",
              "      <th>...</th>\n",
              "      <th>rush</th>\n",
              "      <th>realist</th>\n",
              "      <th>scare</th>\n",
              "      <th>manner</th>\n",
              "      <th>command</th>\n",
              "      <th>standard</th>\n",
              "      <th>menac</th>\n",
              "      <th>spent</th>\n",
              "      <th>adam</th>\n",
              "      <th>agre</th>\n",
              "      <th>cinematographi</th>\n",
              "      <th>front</th>\n",
              "      <th>ground</th>\n",
              "      <th>budget</th>\n",
              "      <th>fairli</th>\n",
              "      <th>pair</th>\n",
              "      <th>virtual</th>\n",
              "      <th>suddenli</th>\n",
              "      <th>fantasi</th>\n",
              "      <th>connect</th>\n",
              "      <th>disturb</th>\n",
              "      <th>90</th>\n",
              "      <th>appropri</th>\n",
              "      <th>godzilla</th>\n",
              "      <th>brown</th>\n",
              "      <th>grant</th>\n",
              "      <th>cultur</th>\n",
              "      <th>greatest</th>\n",
              "      <th>store</th>\n",
              "      <th>trip</th>\n",
              "      <th>key</th>\n",
              "      <th>fascin</th>\n",
              "      <th>cute</th>\n",
              "      <th>brief</th>\n",
              "      <th>cameo</th>\n",
              "      <th>count</th>\n",
              "      <th>foot</th>\n",
              "      <th>addit</th>\n",
              "      <th>satir</th>\n",
              "      <th>bug</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>11</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 1000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      film  movi  one  like  charact  ...  count  foot  addit  satir  bug\n",
              "0        3     0    4     1        2  ...      0     0      0      0    0\n",
              "1        2     1    1     0        0  ...      0     0      0      0    0\n",
              "2        4     4    3     2        7  ...      0     0      0      0    0\n",
              "3        5     0    0     0        0  ...      0     0      0      0    0\n",
              "4        2     0    2     0        0  ...      0     0      0      0    0\n",
              "...    ...   ...  ...   ...      ...  ...    ...   ...    ...    ...  ...\n",
              "1995    10     1    5     0        2  ...      0     0      1      0    0\n",
              "1996     6     1    2     2        1  ...      0     0      0      0    0\n",
              "1997     3     0    2     0        0  ...      0     0      0      0    0\n",
              "1998    14     4    8     5        6  ...      0     1      0      0    0\n",
              "1999    11     2    2     3        0  ...      0     0      0      0    0\n",
              "\n",
              "[2000 rows x 1000 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA7yjtdsJ_ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d949ca-689f-4b7a-fa18-0174ce438494"
      },
      "source": [
        "# Spliting the dataset for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split (X[vocabulary.keys()], y , train_size = 0.8, random_state = 42, shuffle = True, stratify=data['label'])\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (1600, 1000) (1600,)\n",
            "Shapes of X_test, y_test:  (400, 1000) (400,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3koUq4K2EJLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a51cdc27-d222-4207-8cdf-4a5563a31ea1"
      },
      "source": [
        "X_train.values"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  1,  1, ...,  0,  0,  0],\n",
              "       [ 6,  0,  4, ...,  0,  0,  0],\n",
              "       [ 0,  3,  4, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 5,  5,  2, ...,  0,  0,  0],\n",
              "       [ 5,  2,  3, ...,  0,  0,  0],\n",
              "       [ 4,  3,  6, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsSfRLnHvKT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26699266-b93c-40c1-ad51-331d337276b6"
      },
      "source": [
        "# class LogisticRegression ():\n",
        "#   def __init__ (lr = '', n_iter = 10):\n",
        "lr = 0.1\n",
        "n_iter = 10\n",
        "weight = None\n",
        "bias = None\n",
        "def computing_gradient (X, Y):\n",
        "  weight = np.zeros(X.shape[1])\n",
        "  bias = 0\n",
        "  for iter in range(n_iter):\n",
        "    for x,y in zip (X.values,Y):\n",
        "      z = np.dot(weight, x) + bias\n",
        "      y_pred = sigmoid(z)\n",
        "      #loss = -(y*log(y_pred)+(1-y)*log(1-y_pred))\n",
        "      d_weight = np.dot((y_pred - y), x)\n",
        "      d_bias = (y_pred - y)\n",
        "      weight -= lr*d_weight\n",
        "      bias -= lr*d_bias\n",
        "  return  weight, bias\n",
        "\n",
        "def predict(X, weight, bias):\n",
        "    z = np.dot(weight, X.values.T) + bias\n",
        "    y_pred = sigmoid(z)\n",
        "    y_class = [1 if i > 0.5 else 0 for i in y_pred]\n",
        "    return y_class\n",
        "\n",
        "def sigmoid (z):\n",
        "  p=1/(1+np.exp(-z))\n",
        "  return p\n",
        "\n",
        "# Printing model performance \n",
        "def printing_eval_scores (y_true, y_pred):\n",
        "  print('accuracy score: {}'.format(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
        "  print('precision score: {}'.format(sklearn.metrics.precision_score(y_true, y_pred)))\n",
        "  print('recall score: {}'.format(sklearn.metrics.recall_score(y_true, y_pred)))\n",
        "  print('F1 score: {}'.format(sklearn.metrics.f1_score(y_true, y_pred)))\n",
        "  print(classification_report(y_true, y_pred))\n",
        "\n",
        "\n",
        "weight, bias = computing_gradient (X_train, y_train)\n",
        "y_predict = predict(X_test,weight, bias)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance on training set:')\n",
        "printing_eval_scores (y_train, predict(X_train,weight, bias))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('Model performance on test set:')\n",
        "printing_eval_scores (y_test, y_predict)\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model performance on training set:\n",
            "accuracy score: 0.965625\n",
            "precision score: 0.9408284023668639\n",
            "recall score: 0.99375\n",
            "F1 score: 0.966565349544073\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.94      0.96       800\n",
            "           1       0.94      0.99      0.97       800\n",
            "\n",
            "    accuracy                           0.97      1600\n",
            "   macro avg       0.97      0.97      0.97      1600\n",
            "weighted avg       0.97      0.97      0.97      1600\n",
            "\n",
            "\n",
            "===========================\n",
            "Model performance on test set:\n",
            "accuracy score: 0.7925\n",
            "precision score: 0.76\n",
            "recall score: 0.855\n",
            "F1 score: 0.8047058823529413\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.73      0.78       200\n",
            "           1       0.76      0.85      0.80       200\n",
            "\n",
            "    accuracy                           0.79       400\n",
            "   macro avg       0.80      0.79      0.79       400\n",
            "weighted avg       0.80      0.79      0.79       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wviTYBaXOCxF"
      },
      "source": [
        "#Minibatch training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt0rgm4ULuTQ",
        "outputId": "6e3fc7b6-6862-483d-f61f-364ddd92064f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "# class LogisticRegression ():\n",
        "#   def __init__ (lr = '', n_iter = 10):\n",
        "lr = 0.1\n",
        "n_iter = 10\n",
        "weight = None\n",
        "bias = None\n",
        "def computing_MiniBatch_gradient (X, Y, batch_size):\n",
        "  n_instances, n_features = X.shape\n",
        "  weight = np.zeros(n_features)\n",
        "  bias = 0\n",
        "  for iter in range(n_iter):\n",
        "    i=0 \n",
        "    while i< round(n_instances/batch_size):\n",
        "      m = batch_size * i\n",
        "      n = m + batch_size\n",
        "      sum_w = 0\n",
        "      sum_b = 0\n",
        "      for x,y in zip (X[m:n].values,Y[m:n]):\n",
        "        z = np.dot(weight, x) + bias\n",
        "        y_pred = sigmoid(z)\n",
        "        #loss = -(y*log(y_pred)+(1-y)*log(1-y_pred))\n",
        "        sum_w += np.dot((y_pred - y), x)\n",
        "        sum_b += (y_pred - y)\n",
        "      d_weight = (1/batch_size)*sum_w\n",
        "      d_bias = (1/batch_size)*sum_b\n",
        "      weight -= lr*d_weight\n",
        "      bias -= lr*d_bias\n",
        "      i+=1\n",
        "  return  weight, bias\n",
        "\n",
        "\n",
        "weight, bias = computing_MiniBatch_gradient (X_train, y_train, batch_size = 32)\n",
        "y_predict = predict(X_test,weight, bias)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance on training set:')\n",
        "printing_eval_scores (y_train, predict(X_train,weight, bias))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('Model performance on test set:')\n",
        "printing_eval_scores (y_test, y_predict)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model performance on training set:\n",
            "accuracy score: 0.945\n",
            "precision score: 0.9129930394431555\n",
            "recall score: 0.98375\n",
            "F1 score: 0.9470517448856799\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94       800\n",
            "           1       0.91      0.98      0.95       800\n",
            "\n",
            "    accuracy                           0.94      1600\n",
            "   macro avg       0.95      0.95      0.94      1600\n",
            "weighted avg       0.95      0.94      0.94      1600\n",
            "\n",
            "\n",
            "===========================\n",
            "Model performance on test set:\n",
            "accuracy score: 0.83\n",
            "precision score: 0.7844827586206896\n",
            "recall score: 0.91\n",
            "F1 score: 0.8425925925925926\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.82       200\n",
            "           1       0.78      0.91      0.84       200\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.84      0.83      0.83       400\n",
            "weighted avg       0.84      0.83      0.83       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qSYOmfA1x70"
      },
      "source": [
        "# L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ESdBPV11xP",
        "outputId": "46bc099c-e703-44da-bf7f-37062b55a531",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "# class LogisticRegression ():\n",
        "#   def __init__ (lr = '', n_iter = 10):\n",
        "lr = 0.1\n",
        "n_iter = 10\n",
        "alpha = 0.01\n",
        "weight = None\n",
        "bias = None\n",
        "def MiniBatch_gradient_L2 (X, Y, batch_size):\n",
        "  n_instances, n_features = X.shape\n",
        "  weight = np.zeros(n_features)\n",
        "  bias = 0\n",
        "  for iter in range(n_iter):\n",
        "    i=0 \n",
        "    while i< round(n_instances/batch_size):\n",
        "      m = batch_size * i\n",
        "      n = m + batch_size\n",
        "      sum_w = 0\n",
        "      sum_b = 0\n",
        "      for x,y in zip (X[m:n].values,Y[m:n]):\n",
        "        z = np.dot(weight, x) + bias\n",
        "        y_pred = sigmoid(z)\n",
        "        w_i = np.dot((y_pred - y), x)\n",
        "        b_i = y_pred - y\n",
        "        sum_w +=  w_i + (alpha * w_i) # L2\n",
        "        sum_b += b_i\n",
        "      d_weight = (1/batch_size)*sum_w\n",
        "      d_bias = (1/batch_size)*sum_b\n",
        "      weight -= lr*d_weight\n",
        "      bias -= lr*d_bias\n",
        "      i+=1\n",
        "  return  weight, bias\n",
        "\n",
        "\n",
        "weight, bias = MiniBatch_gradient_L2 (X_train, y_train, batch_size = 32)\n",
        "y_predict = predict(X_test,weight, bias)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance on training set:')\n",
        "printing_eval_scores (y_train, predict(X_train,weight, bias))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('Model performance on test set:')\n",
        "printing_eval_scores (y_test, y_predict)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model performance on training set:\n",
            "accuracy score: 0.945625\n",
            "precision score: 0.9140534262485482\n",
            "recall score: 0.98375\n",
            "F1 score: 0.9476219145093318\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94       800\n",
            "           1       0.91      0.98      0.95       800\n",
            "\n",
            "    accuracy                           0.95      1600\n",
            "   macro avg       0.95      0.95      0.95      1600\n",
            "weighted avg       0.95      0.95      0.95      1600\n",
            "\n",
            "\n",
            "===========================\n",
            "Model performance on test set:\n",
            "accuracy score: 0.83\n",
            "precision score: 0.7844827586206896\n",
            "recall score: 0.91\n",
            "F1 score: 0.8425925925925926\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.75      0.82       200\n",
            "           1       0.78      0.91      0.84       200\n",
            "\n",
            "    accuracy                           0.83       400\n",
            "   macro avg       0.84      0.83      0.83       400\n",
            "weighted avg       0.84      0.83      0.83       400\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rklpxbuq8pcR",
        "outputId": "08e95d2c-d6f6-4aa7-d152-33aac73f9cbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range len(weight):\n",
        "  print "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 5.58907413e-02,  3.80273237e-04,  9.50347879e-02, -4.40981040e-02,\n",
              "       -1.53685172e-03, -7.48106616e-03, -4.26559917e-03,  5.75626981e-02,\n",
              "       -2.87654406e-02, -1.86068559e-01,  2.42226336e-01,  9.15305973e-02,\n",
              "       -3.79939309e-02,  2.48135752e-01, -2.66829862e-01, -7.82549980e-02,\n",
              "        2.58367160e-01,  3.88781660e-02,  5.61460748e-02, -1.13192114e-01,\n",
              "       -2.80581094e-01,  3.03664293e-02, -4.60233738e-02,  2.23658146e-01,\n",
              "        2.25305257e-01, -1.41277377e-01,  2.27884659e-01,  3.02122010e-02,\n",
              "        1.07844591e-01,  1.61570892e-01,  7.46093366e-03, -2.65159080e-01,\n",
              "        6.03463870e-02,  2.77356641e-01,  8.28307660e-03,  1.77902968e-01,\n",
              "        1.82325550e-01,  6.86963264e-02, -3.00127403e-01, -5.78826354e-01,\n",
              "        1.23308668e-02, -4.31633579e-02, -1.72382071e-01, -7.98117365e-02,\n",
              "        1.20582836e-01, -4.69150608e-02,  4.00167608e-02, -1.06761182e-01,\n",
              "        1.24303976e-01,  6.01631582e-02, -8.67966179e-02, -1.36044635e-02,\n",
              "       -1.24155764e-01, -1.23488458e-01, -7.05930455e-02,  1.22063773e-02,\n",
              "        1.45948470e-01, -1.33511308e-02,  4.07350989e-01, -1.29847169e-01,\n",
              "        1.36991659e-02, -1.11894789e-02, -1.03492139e-01,  3.27768419e-03,\n",
              "       -1.33582493e-01, -9.14676099e-02, -6.21629681e-02,  7.36584692e-02,\n",
              "        1.97400344e-01, -1.10325172e-01,  4.44730748e-03,  7.03636511e-02,\n",
              "       -1.89836378e-01, -4.80253614e-02, -1.85817256e-01,  3.81725705e-02,\n",
              "        2.11435945e-02,  1.11535114e-01, -1.33968878e-01,  1.64266025e-01,\n",
              "       -5.46237567e-02,  1.23028237e-01, -4.87329420e-03,  6.19176396e-02,\n",
              "       -2.82854557e-01, -8.61724169e-02, -1.97530945e-03, -5.49486683e-02,\n",
              "        9.84558823e-02,  3.22195558e-01, -4.02888824e-02,  2.34948429e-02,\n",
              "       -1.63081971e-01, -2.25797371e-01, -1.91241359e-01, -6.05006718e-02,\n",
              "        6.50519493e-02,  1.05078988e-01,  2.37760181e-02, -2.30827208e-02,\n",
              "        7.39077279e-02, -7.93488194e-02,  3.89785872e-02, -2.15259805e-01,\n",
              "       -2.13734319e-01,  1.52350786e-01, -1.16280967e-01,  1.96889121e-01,\n",
              "        9.63806733e-02, -3.20470306e-03, -3.89823160e-01,  1.22368170e-02,\n",
              "        1.44069555e-01,  9.11381586e-02,  1.12723865e-01, -5.38689776e-02,\n",
              "       -1.96692803e-01, -1.74863982e-01,  1.70768925e-02, -1.74529210e-01,\n",
              "        8.24514166e-02, -1.15911448e-01,  4.60222517e-02,  3.64363338e-02,\n",
              "        8.33169419e-02, -1.20309585e-01, -3.30005555e-02, -8.06718921e-02,\n",
              "        9.67349771e-02, -3.32718320e-03,  3.46656895e-02, -2.63514690e-02,\n",
              "        1.90226287e-01,  2.28161909e-01,  2.62645390e-01, -2.24247519e-01,\n",
              "        1.06245635e-01,  1.70693880e-01, -4.08563906e-02, -6.06057101e-02,\n",
              "       -1.56590484e-01, -1.93003504e-01,  1.16747996e-01, -6.61956844e-02,\n",
              "       -1.73372844e-02, -7.07038519e-02, -1.69417704e-01, -2.82981095e-02,\n",
              "        5.84212691e-02, -9.41151338e-02,  4.68012980e-02, -1.89330923e-01,\n",
              "        1.16444848e-01, -3.57667986e-02, -2.41749902e-01, -8.46426811e-02,\n",
              "        7.55526866e-02,  1.51103119e-01, -5.22675911e-02,  1.57574540e-01,\n",
              "        4.48878813e-02,  3.74804945e-01,  1.58867705e-01, -1.03379407e-01,\n",
              "        2.71841207e-01,  2.53697087e-01, -1.52654812e-01,  1.65983052e-01,\n",
              "        3.08550487e-01,  2.46889254e-02,  1.15202393e-01,  2.30511426e-01,\n",
              "        1.61973621e-01,  5.77625887e-02, -2.67425278e-03,  3.23889357e-02,\n",
              "        2.14198944e-01,  1.00134488e-01,  1.24066846e-01,  3.29652251e-02,\n",
              "        1.55818795e-01,  3.67953644e-02,  4.22651548e-01, -3.64098038e-01,\n",
              "        2.34263932e-01, -8.35088581e-02, -3.09570468e-02, -2.33905945e-02,\n",
              "        3.33371835e-02,  1.27991173e-01, -3.51591820e-01,  9.98093320e-02,\n",
              "       -3.31307251e-02, -6.67151486e-02,  4.38576900e-02,  6.87857099e-02,\n",
              "       -5.01643432e-02,  7.93021978e-02, -1.19430925e-01,  1.06585781e-01,\n",
              "       -1.32169715e-02, -3.28551826e-03,  8.57990501e-02, -2.08541020e-02,\n",
              "        8.59883159e-02,  1.75362844e-01,  7.33419903e-02, -1.11307061e-01,\n",
              "       -9.02792312e-02, -1.55691761e-01,  1.16832160e-02,  1.10570892e-01,\n",
              "       -1.10825799e-01,  8.53897382e-02,  1.48609901e-01,  2.74242202e-01,\n",
              "        1.41194690e-01, -6.03627394e-02, -2.80606334e-02,  3.29541099e-02,\n",
              "       -5.64920005e-02, -1.29233452e-01,  1.79797672e-01, -1.40348101e-01,\n",
              "       -6.16013965e-03, -2.87509394e-01,  1.66199534e-01, -9.49802447e-02,\n",
              "       -6.66575371e-02, -2.36313362e-01,  3.11235058e-01,  2.04872826e-04,\n",
              "        2.62407198e-01, -3.24762915e-02,  7.39331903e-03, -2.24914972e-01,\n",
              "        1.97891498e-02,  1.28916632e-01,  9.17037320e-02,  2.64051644e-02,\n",
              "        1.71125129e-01, -5.19597292e-02,  6.72891093e-02, -8.67792614e-02,\n",
              "        1.29406783e-01, -2.08937856e-01, -1.42399690e-01,  2.75146229e-01,\n",
              "        1.13791446e-01, -5.89424611e-02, -1.37262878e-02, -8.95849437e-02,\n",
              "        6.21823163e-02, -4.26921968e-02,  2.72901390e-01, -4.98650267e-02,\n",
              "       -3.06444067e-02,  1.00449964e-01, -8.80512972e-03,  2.17091177e-01,\n",
              "       -4.67983590e-02, -1.32239015e-01, -4.97762581e-01, -1.10484470e-01,\n",
              "       -1.56733246e-01,  9.56705201e-02, -1.00081816e-01,  4.94210904e-02,\n",
              "       -1.54267990e-01,  1.44726019e-01,  1.42815667e-01,  1.49673326e-01,\n",
              "        9.34227587e-02,  2.08465510e-02, -6.75176799e-02, -2.00241059e-01,\n",
              "        4.61435396e-03, -7.34132677e-02,  9.30654270e-03, -7.93091997e-03,\n",
              "        6.59362745e-02,  1.84753316e-01,  4.74995254e-02, -4.84474559e-01,\n",
              "       -1.15595393e-01,  1.07926917e-01, -4.75911845e-02,  5.79411891e-02,\n",
              "        9.35848214e-03, -2.35425001e-02, -2.03243739e-01, -4.65410099e-02,\n",
              "       -7.77550740e-03,  1.18107572e-01, -8.06461873e-02,  2.93844100e-02,\n",
              "        7.67558894e-04, -5.55093679e-01,  3.84637428e-02, -2.08443248e-02,\n",
              "       -6.45963271e-02,  5.38200696e-02, -1.16105736e-01,  4.01322534e-02,\n",
              "        6.18451887e-02,  2.52629397e-01, -2.09342433e-02, -2.02409254e-01,\n",
              "       -5.33840508e-02, -1.29161690e-01,  3.89058759e-02, -1.26776415e-01,\n",
              "        4.45852559e-02,  7.03475994e-03, -8.20050692e-02,  3.31297125e-01,\n",
              "        2.44767563e-01, -1.79735328e-01, -4.57987942e-02, -7.24310117e-02,\n",
              "        1.37950524e-01,  3.22494687e-02, -6.05100767e-02,  2.20491498e-01,\n",
              "       -8.50662366e-02,  2.21616929e-01,  4.55389784e-02, -2.62417775e-02,\n",
              "        1.40257165e-01, -1.04198705e-01, -1.56854146e-01,  6.08321680e-02,\n",
              "       -1.32346137e-01, -1.58526964e-01, -2.59087313e-02, -2.06256508e-02,\n",
              "        1.23039134e-01,  1.50734187e-01, -1.88015283e-01,  9.69751482e-02,\n",
              "       -5.96896689e-02,  7.51782421e-02,  1.87251122e-01, -1.59643250e-01,\n",
              "        2.78201842e-01,  4.60811646e-03,  9.33431707e-02, -8.35509287e-02,\n",
              "        3.46780709e-02,  2.01322318e-01,  8.14035033e-02,  7.14625925e-02,\n",
              "        1.81211278e-02, -3.15353593e-01,  3.41442074e-02,  4.08768988e-02,\n",
              "        8.90293299e-02, -2.78475113e-01, -1.43078002e-01,  1.10570777e-01,\n",
              "        8.00690654e-02, -6.60688131e-02, -4.32189748e-02, -6.27201544e-02,\n",
              "        1.12819554e-01,  6.70433126e-02,  1.99735855e-01,  9.13775890e-02,\n",
              "        1.73579110e-02, -1.30288696e-01, -1.20292020e-01,  1.55080624e-01,\n",
              "        1.18186722e-01,  6.87314530e-02,  5.43137555e-02, -1.00631901e-01,\n",
              "        1.32958451e-01,  1.14230196e-01,  2.38549545e-01, -3.11863854e-02,\n",
              "        1.05677097e-01,  5.61348622e-02, -6.80931075e-04, -2.29517745e-01,\n",
              "       -3.13728371e-02, -2.98437423e-02,  9.97641690e-02, -8.85332828e-02,\n",
              "        8.26556797e-02,  5.58072204e-02, -2.08323237e-02, -4.87904061e-03,\n",
              "        3.76666543e-02, -1.79876481e-01,  8.81849980e-02, -8.90381268e-03,\n",
              "        8.69340665e-04,  1.38291636e-02,  2.02226956e-02, -3.53000598e-02,\n",
              "       -1.89218390e-01, -5.84058009e-01, -4.84267451e-03,  5.76883604e-02,\n",
              "       -4.21892464e-03, -9.48874208e-02,  7.54052601e-02,  1.75395624e-01,\n",
              "       -6.39818268e-03, -2.02804158e-02,  2.33921149e-02, -1.44455791e-01,\n",
              "       -6.65433447e-02,  1.92741113e-01,  6.72213485e-02,  2.22032886e-04,\n",
              "        7.28649451e-02,  5.09938844e-02,  6.77497581e-03, -2.13405757e-01,\n",
              "       -6.24119959e-02,  1.59436664e-01,  2.44717738e-02,  7.87914551e-02,\n",
              "       -3.96466958e-01,  2.05854860e-01, -2.79825052e-02, -1.39023783e-01,\n",
              "       -9.36758316e-03, -3.07765275e-01, -5.19437048e-01, -7.56850666e-02,\n",
              "       -3.86275944e-02, -1.00989290e-01,  1.67741330e-02,  1.40515218e-01,\n",
              "       -2.78606647e-01, -8.82147644e-02,  1.19509067e-01,  9.37642540e-02,\n",
              "       -8.78026167e-02, -1.97023520e-01,  3.24606078e-02,  1.07326727e-01,\n",
              "        3.60704113e-01, -1.11446019e-01,  9.69182450e-02,  8.44457531e-02,\n",
              "       -7.61514795e-02, -1.47533783e-01, -6.67786415e-02,  1.62514116e-01,\n",
              "       -1.17483707e-02,  1.02912062e-01, -5.84324982e-02, -9.79782821e-02,\n",
              "       -4.34643356e-02,  8.50854574e-02,  2.96434423e-01,  5.33923664e-02,\n",
              "        1.69488175e-02, -1.66306548e-02,  1.59635021e-01,  1.49687521e-01,\n",
              "        1.80695561e-01, -1.38368043e-01, -2.08306753e-02,  1.01570078e-01,\n",
              "        1.32614045e-01,  9.09356624e-02,  2.43185407e-03,  5.22030874e-02,\n",
              "        8.93837041e-02, -1.49759339e-01, -6.14131332e-02, -1.81914402e-02,\n",
              "        9.04598866e-02, -2.46402099e-02,  3.01762792e-02,  8.22601542e-02,\n",
              "        9.78150644e-02, -4.70122679e-02,  2.07494582e-02,  2.76194982e-01,\n",
              "        1.55000944e-01, -1.01206925e-03, -5.49485361e-02, -2.61337713e-02,\n",
              "        1.49645093e-02,  7.40720275e-02,  8.97899367e-02, -5.11500246e-02,\n",
              "       -1.04656474e-01,  1.39163073e-01,  1.14082917e-02,  1.27847015e-02,\n",
              "        1.18882409e-04,  4.32764490e-02,  7.45479738e-02, -5.12039120e-02,\n",
              "        1.64600864e-01, -3.81935316e-02, -1.35040396e-01, -1.59652404e-01,\n",
              "       -9.29514157e-02,  7.65612945e-02,  1.06148722e-01, -2.93987150e-01,\n",
              "        1.38294914e-01,  1.62894754e-02, -1.07609578e-01, -1.57955410e-01,\n",
              "        1.91121025e-01, -1.12759966e-01,  6.54146521e-02,  1.34424111e-01,\n",
              "        5.82953409e-02,  4.58740798e-02, -1.89562456e-02, -4.68010857e-02,\n",
              "        6.72187686e-02, -1.56901490e-02, -4.65957766e-02,  7.22677280e-02,\n",
              "       -5.19924032e-03,  3.41497648e-01,  6.23315075e-02, -2.98923614e-02,\n",
              "       -9.68399684e-02, -2.21183598e-01,  3.89992028e-02,  2.90200031e-01,\n",
              "       -1.17546174e-01,  3.48279309e-02,  2.74653274e-01,  4.96053754e-02,\n",
              "       -2.21425730e-03,  2.78084961e-02, -1.01393249e-01, -1.48050473e-01,\n",
              "       -1.48670641e-01,  4.89585436e-02, -1.53214497e-01,  3.00837599e-01,\n",
              "       -7.23478694e-02, -6.78628911e-02, -4.09177824e-02,  1.06636976e-01,\n",
              "        1.17735606e-01,  1.06645405e-01,  1.08675389e-01, -2.02753374e-02,\n",
              "        4.98529978e-02,  9.48822617e-02,  7.00106275e-02, -1.99648337e-01,\n",
              "       -7.27421339e-02, -2.46451507e-01,  1.93351695e-01,  1.49885824e-01,\n",
              "       -1.07917915e-01,  1.01588917e-01,  3.45047557e-02,  8.14423761e-02,\n",
              "       -5.63587029e-03, -1.20656767e-01,  1.80203853e-01,  1.88243151e-02,\n",
              "        5.56913159e-02,  4.62437910e-02, -2.02340478e-02, -9.58674514e-02,\n",
              "       -1.99531345e-01,  1.47812346e-01, -5.95057874e-02, -3.02640827e-02,\n",
              "        1.35881548e-01,  4.17103440e-03, -1.89637798e-02,  8.71395803e-02,\n",
              "        2.58437677e-02, -6.14532300e-03, -1.84278404e-01, -8.67480231e-02,\n",
              "        3.39809605e-03, -6.76596948e-02, -1.12865448e-01, -6.62275481e-02,\n",
              "        2.88325473e-01, -9.06305653e-02,  4.34113825e-02,  6.17428682e-02,\n",
              "       -3.69954811e-02, -1.12712996e-02, -9.40322087e-02, -1.29056424e-01,\n",
              "       -4.38318005e-02,  1.64055137e-01,  9.93115897e-02, -1.67567421e-01,\n",
              "        1.06237654e-01, -2.71287981e-01, -1.01280860e-01, -8.67677457e-03,\n",
              "        1.26655443e-01, -3.80856445e-03,  2.98351706e-02,  1.05196954e-01,\n",
              "       -7.27236536e-02, -2.86070296e-02, -6.27453051e-02, -5.23292879e-03,\n",
              "       -8.08210698e-02, -1.47915113e-01,  1.63260787e-02, -3.62430689e-02,\n",
              "       -2.99402055e-02, -5.78263833e-02, -6.86106151e-02,  1.22141822e-01,\n",
              "       -2.74918872e-01, -1.38592752e-01, -9.11545396e-02,  2.41094685e-01,\n",
              "        5.18819446e-02, -1.32499710e-01,  7.40690067e-02,  1.40809481e-01,\n",
              "       -1.44237489e-01, -3.34026689e-01, -4.73070782e-02, -1.41552490e-02,\n",
              "       -5.80034905e-02,  1.96295601e-01, -3.86133882e-01,  2.13509035e-01,\n",
              "       -9.09076452e-02,  6.60716072e-02,  5.66695914e-03, -2.57744053e-02,\n",
              "       -2.60663455e-02, -9.44746052e-02,  3.56319762e-01,  9.96531411e-02,\n",
              "        1.60899335e-01, -3.06590608e-02, -1.93998144e-02, -4.29403574e-03,\n",
              "       -1.35567366e-01, -3.36750515e-02,  6.66551533e-02, -1.48656643e-01,\n",
              "        6.61854676e-03,  1.21251251e-01, -5.20370437e-02,  4.51349188e-02,\n",
              "        7.78215077e-02,  1.55359271e-01, -3.09277505e-02, -7.10826951e-02,\n",
              "        2.04982471e-01, -1.31620539e-01, -7.41247320e-02,  1.72667587e-01,\n",
              "       -7.74471991e-02, -7.17408733e-02, -5.28399134e-02, -7.00854941e-02,\n",
              "       -2.98102237e-01, -1.82513847e-01, -1.19289103e-01,  9.40914636e-02,\n",
              "       -6.14647391e-02,  3.73822372e-04,  9.69348073e-03,  1.70176671e-01,\n",
              "       -1.74082237e-01, -6.38920668e-02,  4.08186241e-02,  4.85057570e-02,\n",
              "       -3.22607801e-01, -6.22841383e-02, -4.25242939e-02, -1.90961452e-02,\n",
              "       -2.26251923e-01,  9.56117412e-03, -6.05763309e-03, -1.36111706e-01,\n",
              "       -1.98709849e-01,  1.40185529e-01,  3.00669290e-02, -2.29948461e-01,\n",
              "       -4.17722317e-02, -2.42901285e-02, -1.07579580e-01, -1.80762266e-02,\n",
              "        2.08269633e-01,  8.46562510e-02,  1.25883739e-01,  2.52321485e-02,\n",
              "       -1.40096219e-01,  7.61581964e-02, -8.64239122e-02, -1.02307298e-01,\n",
              "       -4.06288294e-03,  1.43549314e-01,  6.31253187e-02,  1.53347226e-01,\n",
              "        5.55675542e-02, -1.85740441e-01,  1.35135334e-01, -1.36398188e-01,\n",
              "        7.20261749e-02, -3.65766317e-02, -8.65097968e-02,  6.48059031e-02,\n",
              "       -1.52200458e-01, -4.59547948e-02,  5.86475693e-02, -4.78344419e-02,\n",
              "       -1.22800300e-01,  7.44353628e-02, -1.01504065e-02,  3.22857012e-03,\n",
              "        7.73485505e-03, -8.16962709e-02,  5.53343755e-02,  2.24478301e-02,\n",
              "        3.81721604e-02,  3.84972903e-02, -1.44272742e-01, -5.60407317e-02,\n",
              "       -1.01547101e-01,  2.79884290e-02, -1.20772709e-01,  6.82718991e-02,\n",
              "        3.64055440e-02, -8.41148061e-02, -1.13328391e-01, -3.11560032e-02,\n",
              "       -1.72847865e-01,  9.16683241e-02,  1.18738113e-01, -1.78264169e-02,\n",
              "        1.51369035e-01, -6.13927139e-02,  3.64255910e-02,  1.53006492e-01,\n",
              "       -1.62869470e-02,  2.33677603e-02, -6.65157346e-03,  1.10703891e-01,\n",
              "       -1.02907457e-01,  2.69689805e-02,  1.31408863e-01, -9.34740303e-02,\n",
              "       -6.91681567e-02, -5.18378237e-03,  2.14368478e-01,  1.27501201e-01,\n",
              "       -6.94557616e-02,  4.95900440e-02, -3.33514794e-01,  4.47618159e-02,\n",
              "       -7.29480108e-02,  2.59619202e-01,  6.22827729e-02,  4.33023145e-02,\n",
              "       -2.85360804e-01,  3.73296286e-02,  6.02662085e-02,  8.83266835e-02,\n",
              "        1.32003708e-01, -6.91649347e-02, -1.20105604e-02, -8.84268038e-02,\n",
              "       -9.79954762e-02,  8.99943691e-02,  5.85493798e-03,  1.58422196e-01,\n",
              "        6.01512220e-02,  1.14054474e-01, -1.17977008e-02, -1.19280106e-02,\n",
              "        8.67716978e-02, -9.43781216e-02,  5.80016556e-02,  4.62960401e-02,\n",
              "       -7.34282538e-02,  6.82240357e-02, -4.96934596e-03, -1.90256296e-01,\n",
              "       -6.96151529e-02,  7.36001750e-02,  2.64570619e-01,  7.32615808e-02,\n",
              "        2.79254881e-02,  2.36394940e-01, -8.76603116e-02,  3.78546180e-02,\n",
              "        8.63745649e-02, -1.94901905e-01,  5.72719046e-03,  4.99581633e-02,\n",
              "       -1.15855650e-01,  1.08842201e-02,  2.67343644e-02,  1.94747366e-01,\n",
              "       -1.00514697e-01,  4.17504012e-02, -1.61897785e-03, -7.87379046e-02,\n",
              "        2.55514831e-01, -4.05536895e-03, -1.20887050e-01,  1.01758726e-02,\n",
              "       -1.85110653e-01, -5.92894856e-02, -5.46526547e-02,  6.68783168e-02,\n",
              "        1.07340949e-01,  3.38336077e-03,  2.90322923e-02, -2.41610585e-01,\n",
              "        1.26849088e-01,  8.49186125e-02,  5.79834909e-02, -5.71080469e-02,\n",
              "        9.13812229e-02,  5.67142969e-04,  1.71707633e-01,  8.36688842e-03,\n",
              "        3.20419746e-02,  7.77462590e-02, -1.64046672e-01, -1.51226505e-01,\n",
              "        8.89037680e-02, -9.11609695e-02,  4.63956408e-03,  7.45466823e-02,\n",
              "        4.00338019e-03,  5.09386013e-02, -6.62028982e-02,  8.97313596e-02,\n",
              "        2.56445897e-02,  1.66680959e-01,  1.35553052e-01, -3.52638481e-02,\n",
              "       -8.28266065e-03,  6.35990687e-03, -9.92890557e-03,  3.50854263e-02,\n",
              "        9.68280154e-02,  4.68075072e-02, -7.18427217e-02, -7.81563114e-02,\n",
              "        2.46727467e-02, -3.03882878e-02, -1.16224101e-01,  2.50028263e-02,\n",
              "       -2.19535911e-02, -6.26032140e-02,  2.82785523e-01, -1.21098632e-02,\n",
              "       -5.71384551e-02, -1.13207799e-02,  1.22804409e-01, -2.31605267e-02,\n",
              "       -7.89319417e-04, -1.06960558e-01, -5.31425143e-02,  7.95466508e-02,\n",
              "        1.11727999e-02, -4.26952156e-02,  4.55680397e-02, -2.00949312e-01,\n",
              "        1.74663368e-01,  1.30969117e-01, -5.03833797e-02,  4.41894675e-02,\n",
              "        8.03598150e-03, -2.48811726e-01,  1.41123096e-02,  1.62771739e-01,\n",
              "        1.52734518e-02,  6.77578158e-02,  6.49839774e-02, -1.20662416e-01,\n",
              "       -9.15697246e-02, -5.72223486e-02,  9.16895251e-02, -1.10391133e-01,\n",
              "        6.35367933e-02,  1.26565312e-01, -2.50376140e-01,  2.02123663e-02,\n",
              "        5.54306142e-02,  6.17053488e-02, -8.74030837e-02, -1.35277527e-01,\n",
              "       -8.42172438e-02, -1.14568995e-01, -6.14753722e-03,  1.03772301e-01,\n",
              "       -8.26656980e-02, -3.84977479e-02, -1.72592347e-02, -4.02433790e-02,\n",
              "        9.18695480e-02,  2.24002960e-01, -2.17531096e-03, -1.29183375e-01,\n",
              "       -1.02087273e-01, -1.34210057e-03,  3.44003383e-02, -1.53068962e-01,\n",
              "       -1.06702833e-01,  1.92707472e-01,  3.43237949e-02, -4.41653247e-02,\n",
              "       -7.89966874e-02, -1.12647477e-01, -8.29924605e-02,  5.46300201e-02,\n",
              "       -1.35837587e-01, -1.38457629e-02, -7.63790171e-02, -9.60946266e-02,\n",
              "        7.21329272e-02, -6.96843048e-02, -9.59792189e-02,  9.09784401e-02,\n",
              "       -1.15521030e-01,  2.68070114e-03, -5.05646283e-02,  4.65613619e-02,\n",
              "       -5.43595586e-02,  1.91509714e-01,  2.51964976e-02, -6.12575890e-02,\n",
              "       -2.94300076e-01,  7.44606267e-02, -3.55382276e-02, -1.23185730e-02,\n",
              "       -2.76986204e-02, -1.30142248e-01, -4.04778724e-02, -1.27159434e-01,\n",
              "       -2.77759587e-02, -8.43730773e-02, -9.82076207e-02,  5.92639507e-03,\n",
              "        7.06909172e-02, -6.20656401e-02, -9.64245040e-02,  5.76674526e-02,\n",
              "        7.54882923e-02,  4.22528414e-02,  1.90469636e-01,  7.56229719e-02,\n",
              "        1.72913227e-01,  1.69387219e-01, -7.54278837e-02,  3.52020355e-02,\n",
              "        7.53491008e-02, -9.31820248e-02,  5.84415887e-02, -3.12600307e-02,\n",
              "       -6.86697680e-02, -2.15740971e-02,  7.84550083e-03, -5.79520152e-02,\n",
              "       -3.42132406e-02, -1.66536548e-02,  2.14093665e-02,  2.44276171e-03,\n",
              "       -8.38013482e-03, -2.34944013e-02,  3.24230715e-02,  8.23323951e-02,\n",
              "        4.96189001e-02, -2.05808300e-02,  3.81201318e-02, -1.15327084e-01,\n",
              "        8.08091184e-02,  1.37761831e-02,  1.35279261e-01,  7.42131145e-02,\n",
              "        7.88871332e-02, -4.89542458e-02,  1.15720686e-01,  9.11792056e-02,\n",
              "        8.34884859e-02, -4.38852958e-03, -6.71069265e-02, -1.18204230e-01,\n",
              "        9.93111859e-02,  2.18464241e-02,  7.22627631e-02, -1.29002946e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}