{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Feedforward-Network.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOViXRXENgrSneDRR8L7gg3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment_Feedforward_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybsamp8T__sG",
        "outputId": "1c04b03b-dc44-4ddc-b35f-ad954db543a5"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import string\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "import pandas as pd\n",
        "import glob\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEecDn_cAPUR"
      },
      "source": [
        "# Part 1: IMDB sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I37czSdvAJGh"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTrU1EcAaJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb48e43-425c-4a04-8be7-709882aa7e5f"
      },
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "data = tf.keras.utils.get_file ('aclImdb_v1',\n",
        "                                url,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "data_dir = os.path.join (os.path.dirname(data), 'aclImdb')\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imdb.vocab', 'test', 'README', 'imdbEr.txt', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl4s0XGxECq4",
        "outputId": "26f455fe-7736-4f29-973b-a3efd52aabc4"
      },
      "source": [
        "train_dir = os.path.join (data_dir, 'train')\n",
        "test_dir = os.path.join (data_dir, 'test')\n",
        "print(os.listdir(train_dir))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'urls_neg.txt', 'urls_pos.txt', 'unsup', 'pos', 'urls_unsup.txt', 'unsupBow.feat', 'labeledBow.feat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqLbtPKfNc5Z"
      },
      "source": [
        "# We only use files in the two folders: pos, and neg, so let's remove other files\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5fHSce2Rk-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b0b3d9-0a9e-4829-9d66-91fc39a4c6db"
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('aclImdb/test',\n",
        "                                                       batch_size = batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuL_ipXkaAyv"
      },
      "source": [
        "## Text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KVgg_ZWaFtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6759664b-7198-4c19-8911-56c1151ef114"
      },
      "source": [
        "def custom_preprocessing (text):\n",
        "  lowercase = tf.strings.lower (text)\n",
        "  stripped_html = tf.strings.regex_replace (lowercase,'<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), \n",
        "                                  '')\n",
        "  \n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(standardize = custom_preprocessing,\n",
        "                                           max_tokens = max_features,\n",
        "                                           output_mode = 'int',\n",
        "                                           output_sequence_length = sequence_length)\n",
        "# Extracting features for vectorizing using training set\n",
        "train_text = raw_train.map (lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "# Defining a function for fitting vectorizer function/layer to vectorize text (review)\n",
        "def fitting_vectorizer (text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer (text), label\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(raw_train))\n",
        "\n",
        "## print an instance with vectorized review and label for observing\n",
        "print ('REVIEW:', text_batch[0])\n",
        "print('LABEL:', raw_train.class_names[label_batch[0]] )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REVIEW: tf.Tensor(b'Silent Night, Deadly Night 5 is the very last of the series, and like part 4, it\\'s unrelated to the first three except by title and the fact that it\\'s a Christmas-themed horror flick.<br /><br />Except to the oblivious, there\\'s some obvious things going on here...Mickey Rooney plays a toymaker named Joe Petto and his creepy son\\'s name is Pino. Ring a bell, anyone? Now, a little boy named Derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him. Even though it said \"don\\'t open till Christmas\", he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself. Inside is a little red ball that sprouts Santa arms and a head, and proceeds to kill dad. Oops, maybe he should have left well-enough alone. Of course Derek is then traumatized by the incident since he watched it from the stairs, but he doesn\\'t grow up to be some killer Santa, he just stops talking.<br /><br />There\\'s a mysterious stranger lurking around, who seems very interested in the toys that Joe Petto makes. We even see him buying a bunch when Derek\\'s mom takes him to the store to find a gift for him to bring him out of his trauma. And what exactly is this guy doing? Well, we\\'re not sure but he does seem to be taking these toys apart to see what makes them tick. He does keep his landlord from evicting him by promising him to pay him in cash the next day and presents him with a \"Larry the Larvae\" toy for his kid, but of course \"Larry\" is not a good toy and gets out of the box in the car and of course, well, things aren\\'t pretty.<br /><br />Anyway, eventually what\\'s going on with Joe Petto and Pino is of course revealed, and as with the old story, Pino is not a \"real boy\". Pino is probably even more agitated and naughty because he suffers from \"Kenitalia\" (a smooth plastic crotch) so that could account for his evil ways. And the identity of the lurking stranger is revealed too, and there\\'s even kind of a happy ending of sorts. Whee.<br /><br />A step up from part 4, but not much of one. Again, Brian Yuzna is involved, and Screaming Mad George, so some decent special effects, but not enough to make this great. A few leftovers from part 4 are hanging around too, like Clint Howard and Neith Hunter, but that doesn\\'t really make any difference. Anyway, I now have seeing the whole series out of my system. Now if I could get some of it out of my brain. 4 out of 5.', shape=(), dtype=string)\n",
            "LABEL: neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdhUEflLG1-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be62d575-2096-456d-c245-c22a5943d2c7"
      },
      "source": [
        "# print an example of vectorized data\n",
        "print ('Vocabulary size: ', len(vectorize_layer.get_vocabulary()))\n",
        "for i in range (90, 100):\n",
        "  print ('{} ------> {}'.format(i, vectorize_layer.get_vocabulary()[i]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size:  10000\n",
            "90 ------> made\n",
            "91 ------> movies\n",
            "92 ------> then\n",
            "93 ------> them\n",
            "94 ------> films\n",
            "95 ------> way\n",
            "96 ------> make\n",
            "97 ------> any\n",
            "98 ------> could\n",
            "99 ------> too\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49aXKTf-LYpE"
      },
      "source": [
        "train = raw_train.map(fitting_vectorizer)\n",
        "val = raw_val.map(fitting_vectorizer)\n",
        "test = raw_test.map(fitting_vectorizer)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqxSoCqORfY"
      },
      "source": [
        "# Configure the dataset for performance\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train = train.cache().prefetch (buffer_size = autotune)\n",
        "val = val.cache().prefetch (buffer_size = autotune)\n",
        "test = test.cache().prefetch (buffer_size = autotune)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoADSjBJMHL7"
      },
      "source": [
        "## Building a neural network classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS4xOvZ_ZqLC"
      },
      "source": [
        "# Defining an evaluation metric function\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred, average='macro')\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred, average='macro')\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred , average='macro')\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaffgzJaRMKe"
      },
      "source": [
        "### With different numbers of embedding dimentions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnp8gN87MPaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3621a6c8-9ef8-4231-d14d-31bbe0af5f8c"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = [16, 28, 50, 100]\n",
        "for n in embedding_dim:\n",
        "  print (\"========= embedding vectors'size= %s ============\" %n)\n",
        "  model = tf.keras.Sequential([layers.Embedding(max_features + 1, n, name=\"embedding\"),\n",
        "                              layers.Dropout(0.2),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              layers.Dropout(0.2),\n",
        "                              layers.Dense(1)])\n",
        "  print(model.summary())\n",
        "\n",
        "  # configure the model uisng optimizer and loss function\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = 'adam',\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = tf.argmax(model.predict(test),1)\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= embedding vectors'size= 16 ============\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 6ms/step - loss: 0.6641 - binary_accuracy: 0.6877 - val_loss: 0.6143 - val_binary_accuracy: 0.7722\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5481 - binary_accuracy: 0.7979 - val_loss: 0.4980 - val_binary_accuracy: 0.8200\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4450 - binary_accuracy: 0.8454 - val_loss: 0.4197 - val_binary_accuracy: 0.8488\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3784 - binary_accuracy: 0.8648 - val_loss: 0.3736 - val_binary_accuracy: 0.8606\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3354 - binary_accuracy: 0.8787 - val_loss: 0.3449 - val_binary_accuracy: 0.8688\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3052 - binary_accuracy: 0.8882 - val_loss: 0.3259 - val_binary_accuracy: 0.8718\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2816 - binary_accuracy: 0.8964 - val_loss: 0.3126 - val_binary_accuracy: 0.8728\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2631 - binary_accuracy: 0.9043 - val_loss: 0.3032 - val_binary_accuracy: 0.8758\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2459 - binary_accuracy: 0.9119 - val_loss: 0.2962 - val_binary_accuracy: 0.8768\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2316 - binary_accuracy: 0.9155 - val_loss: 0.2918 - val_binary_accuracy: 0.8794\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3101 - binary_accuracy: 0.8732\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.310 - Accuracy: 0.873\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= embedding vectors'size= 28 ============\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 28)          280028    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, None, 28)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_2 ( (None, 28)                0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 28)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 29        \n",
            "=================================================================\n",
            "Total params: 280,057\n",
            "Trainable params: 280,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 6s 8ms/step - loss: 0.6495 - binary_accuracy: 0.7006 - val_loss: 0.5783 - val_binary_accuracy: 0.7840\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.4984 - binary_accuracy: 0.8203 - val_loss: 0.4443 - val_binary_accuracy: 0.8384\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3902 - binary_accuracy: 0.8604 - val_loss: 0.3749 - val_binary_accuracy: 0.8588\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3317 - binary_accuracy: 0.8776 - val_loss: 0.3390 - val_binary_accuracy: 0.8690\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2939 - binary_accuracy: 0.8929 - val_loss: 0.3179 - val_binary_accuracy: 0.8724\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2673 - binary_accuracy: 0.9019 - val_loss: 0.3045 - val_binary_accuracy: 0.8752\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2457 - binary_accuracy: 0.9103 - val_loss: 0.2958 - val_binary_accuracy: 0.8770\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2277 - binary_accuracy: 0.9172 - val_loss: 0.2906 - val_binary_accuracy: 0.8794\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2119 - binary_accuracy: 0.9226 - val_loss: 0.2879 - val_binary_accuracy: 0.8804\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1979 - binary_accuracy: 0.9288 - val_loss: 0.2867 - val_binary_accuracy: 0.8810\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3076 - binary_accuracy: 0.8746\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.308 - Accuracy: 0.875\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= embedding vectors'size= 50 ============\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 50)          500050    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, None, 50)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_3 ( (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 500,101\n",
            "Trainable params: 500,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 9s 13ms/step - loss: 0.6298 - binary_accuracy: 0.7130 - val_loss: 0.5342 - val_binary_accuracy: 0.7982\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.4458 - binary_accuracy: 0.8403 - val_loss: 0.3968 - val_binary_accuracy: 0.8512\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3448 - binary_accuracy: 0.8732 - val_loss: 0.3419 - val_binary_accuracy: 0.8670\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2936 - binary_accuracy: 0.8906 - val_loss: 0.3150 - val_binary_accuracy: 0.8728\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2607 - binary_accuracy: 0.9034 - val_loss: 0.3003 - val_binary_accuracy: 0.8770\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2355 - binary_accuracy: 0.9143 - val_loss: 0.2918 - val_binary_accuracy: 0.8778\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2148 - binary_accuracy: 0.9220 - val_loss: 0.2878 - val_binary_accuracy: 0.8802\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.1969 - binary_accuracy: 0.9300 - val_loss: 0.2862 - val_binary_accuracy: 0.8816\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1823 - binary_accuracy: 0.9359 - val_loss: 0.2876 - val_binary_accuracy: 0.8824\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1685 - binary_accuracy: 0.9419 - val_loss: 0.2903 - val_binary_accuracy: 0.8832\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3166 - binary_accuracy: 0.8720\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.317 - Accuracy: 0.872\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= embedding vectors'size= 100 ============\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         1000100   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,000,201\n",
            "Trainable params: 1,000,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.5986 - binary_accuracy: 0.7296 - val_loss: 0.4743 - val_binary_accuracy: 0.8228\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 14s 22ms/step - loss: 0.3882 - binary_accuracy: 0.8566 - val_loss: 0.3540 - val_binary_accuracy: 0.8622\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.3016 - binary_accuracy: 0.8856 - val_loss: 0.3147 - val_binary_accuracy: 0.8738\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.2573 - binary_accuracy: 0.9052 - val_loss: 0.2970 - val_binary_accuracy: 0.8776\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.2271 - binary_accuracy: 0.9168 - val_loss: 0.2894 - val_binary_accuracy: 0.8798\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.2026 - binary_accuracy: 0.9277 - val_loss: 0.2871 - val_binary_accuracy: 0.8808\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.1834 - binary_accuracy: 0.9349 - val_loss: 0.2880 - val_binary_accuracy: 0.8824\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.1667 - binary_accuracy: 0.9424 - val_loss: 0.2920 - val_binary_accuracy: 0.8818\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.1518 - binary_accuracy: 0.9481 - val_loss: 0.2980 - val_binary_accuracy: 0.8816\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.1388 - binary_accuracy: 0.9545 - val_loss: 0.3060 - val_binary_accuracy: 0.8798\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3419 - binary_accuracy: 0.8652\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.342 - Accuracy: 0.865\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvJLzGQbZZD8"
      },
      "source": [
        "### With different dropout "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn5GRRbvaB3k",
        "outputId": "60f61af0-271c-423f-c441-75f3a750766a"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropouts = [0.0, 0.1, 0.2, 0.3]\n",
        "for i in dropouts:\n",
        "  print (\"========= dropout = %s ============\" %i)\n",
        "  model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim,  name=\"embedding\"),\n",
        "                              layers.Dropout(i),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              layers.Dropout(0.2),\n",
        "                              layers.Dense(1)])\n",
        "  print(model.summary())\n",
        "\n",
        "  # configure the model uisng optimizer and loss function\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = 'adam',\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = tf.argmax(model.predict(test),1)\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= dropout = 0.0 ============\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.6631 - binary_accuracy: 0.6933 - val_loss: 0.6115 - val_binary_accuracy: 0.7750\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5431 - binary_accuracy: 0.8048 - val_loss: 0.4909 - val_binary_accuracy: 0.8250\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.4360 - binary_accuracy: 0.8497 - val_loss: 0.4123 - val_binary_accuracy: 0.8492\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3699 - binary_accuracy: 0.8690 - val_loss: 0.3670 - val_binary_accuracy: 0.8610\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3269 - binary_accuracy: 0.8816 - val_loss: 0.3392 - val_binary_accuracy: 0.8698\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2972 - binary_accuracy: 0.8925 - val_loss: 0.3210 - val_binary_accuracy: 0.8722\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2734 - binary_accuracy: 0.9007 - val_loss: 0.3085 - val_binary_accuracy: 0.8742\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2537 - binary_accuracy: 0.9081 - val_loss: 0.2998 - val_binary_accuracy: 0.8778\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2365 - binary_accuracy: 0.9147 - val_loss: 0.2938 - val_binary_accuracy: 0.8774\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.2231 - binary_accuracy: 0.9204 - val_loss: 0.2896 - val_binary_accuracy: 0.8806\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3087 - binary_accuracy: 0.8744\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.309 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= dropout = 0.1 ============\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_6 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 5s 7ms/step - loss: 0.6620 - binary_accuracy: 0.6924 - val_loss: 0.6120 - val_binary_accuracy: 0.7718\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5453 - binary_accuracy: 0.8012 - val_loss: 0.4946 - val_binary_accuracy: 0.8228\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4403 - binary_accuracy: 0.8467 - val_loss: 0.4161 - val_binary_accuracy: 0.8490\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3738 - binary_accuracy: 0.8684 - val_loss: 0.3700 - val_binary_accuracy: 0.8612\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3311 - binary_accuracy: 0.8810 - val_loss: 0.3416 - val_binary_accuracy: 0.8688\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2999 - binary_accuracy: 0.8902 - val_loss: 0.3231 - val_binary_accuracy: 0.8722\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2774 - binary_accuracy: 0.8981 - val_loss: 0.3100 - val_binary_accuracy: 0.8740\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2569 - binary_accuracy: 0.9067 - val_loss: 0.3011 - val_binary_accuracy: 0.8764\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2410 - binary_accuracy: 0.9140 - val_loss: 0.2947 - val_binary_accuracy: 0.8772\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2275 - binary_accuracy: 0.9184 - val_loss: 0.2906 - val_binary_accuracy: 0.8782\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3091 - binary_accuracy: 0.8740\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.309 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= dropout = 0.2 ============\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 6ms/step - loss: 0.6638 - binary_accuracy: 0.6902 - val_loss: 0.6152 - val_binary_accuracy: 0.7718\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5498 - binary_accuracy: 0.7990 - val_loss: 0.4989 - val_binary_accuracy: 0.8218\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4458 - binary_accuracy: 0.8450 - val_loss: 0.4205 - val_binary_accuracy: 0.8482\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3787 - binary_accuracy: 0.8657 - val_loss: 0.3737 - val_binary_accuracy: 0.8598\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3354 - binary_accuracy: 0.8790 - val_loss: 0.3448 - val_binary_accuracy: 0.8678\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3057 - binary_accuracy: 0.8874 - val_loss: 0.3260 - val_binary_accuracy: 0.8726\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2809 - binary_accuracy: 0.8967 - val_loss: 0.3124 - val_binary_accuracy: 0.8732\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2623 - binary_accuracy: 0.9039 - val_loss: 0.3030 - val_binary_accuracy: 0.8758\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2455 - binary_accuracy: 0.9107 - val_loss: 0.2964 - val_binary_accuracy: 0.8778\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2323 - binary_accuracy: 0.9165 - val_loss: 0.2914 - val_binary_accuracy: 0.8774\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3101 - binary_accuracy: 0.8738\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.310 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= dropout = 0.3 ============\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6677 - binary_accuracy: 0.6789 - val_loss: 0.6190 - val_binary_accuracy: 0.7696\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5530 - binary_accuracy: 0.7969 - val_loss: 0.5026 - val_binary_accuracy: 0.8186\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4499 - binary_accuracy: 0.8420 - val_loss: 0.4243 - val_binary_accuracy: 0.8454\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.3836 - binary_accuracy: 0.8634 - val_loss: 0.3775 - val_binary_accuracy: 0.8598\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3410 - binary_accuracy: 0.8780 - val_loss: 0.3483 - val_binary_accuracy: 0.8664\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3100 - binary_accuracy: 0.8859 - val_loss: 0.3289 - val_binary_accuracy: 0.8714\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2883 - binary_accuracy: 0.8943 - val_loss: 0.3152 - val_binary_accuracy: 0.8730\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2681 - binary_accuracy: 0.9031 - val_loss: 0.3054 - val_binary_accuracy: 0.8756\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2511 - binary_accuracy: 0.9091 - val_loss: 0.2983 - val_binary_accuracy: 0.8762\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2387 - binary_accuracy: 0.9137 - val_loss: 0.2932 - val_binary_accuracy: 0.8794\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3116 - binary_accuracy: 0.8732\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.312 - Accuracy: 0.873\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te4tKnBY8mXP"
      },
      "source": [
        "### Adding a Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la1m7MZW9Ah5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5193393e-8fa2-4c98-a50e-0cfbfb6e5899"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropout =  0.1\n",
        "activations = ['relu', 'softmax', 'sigmoid']\n",
        "for f in activations:\n",
        "  print (\"========= activation function = %s ============\" %f)\n",
        "  model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim,  name=\"embedding\"),\n",
        "                              layers.Dropout(dropout),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              layers.Dropout(dropout),\n",
        "                              layers.Dense(32, activation= f),\n",
        "                              layers.Dense(1)])\n",
        "  print(model.summary())\n",
        "\n",
        "  # configure the model uisng optimizer and loss function\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = 'adam',\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = tf.argmax(model.predict(test),1)\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= activation function = relu ============\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_9 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 6ms/step - loss: 0.5436 - binary_accuracy: 0.7478 - val_loss: 0.3545 - val_binary_accuracy: 0.8584\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2905 - binary_accuracy: 0.8841 - val_loss: 0.2997 - val_binary_accuracy: 0.8744\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2248 - binary_accuracy: 0.9128 - val_loss: 0.2986 - val_binary_accuracy: 0.8752\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1849 - binary_accuracy: 0.9324 - val_loss: 0.3108 - val_binary_accuracy: 0.8750\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1547 - binary_accuracy: 0.9454 - val_loss: 0.3300 - val_binary_accuracy: 0.8712\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1308 - binary_accuracy: 0.9561 - val_loss: 0.3554 - val_binary_accuracy: 0.8718\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1102 - binary_accuracy: 0.9656 - val_loss: 0.3959 - val_binary_accuracy: 0.8660\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0922 - binary_accuracy: 0.9730 - val_loss: 0.4167 - val_binary_accuracy: 0.8684\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0793 - binary_accuracy: 0.9776 - val_loss: 0.4601 - val_binary_accuracy: 0.8644\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0649 - binary_accuracy: 0.9829 - val_loss: 0.4911 - val_binary_accuracy: 0.8656\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.5829 - binary_accuracy: 0.8415\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.583 - Accuracy: 0.842\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= activation function = softmax ============\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_10  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 5s 6ms/step - loss: 0.6883 - binary_accuracy: 0.5843 - val_loss: 0.6680 - val_binary_accuracy: 0.7476\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5838 - binary_accuracy: 0.7926 - val_loss: 0.4933 - val_binary_accuracy: 0.8324\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4159 - binary_accuracy: 0.8586 - val_loss: 0.3758 - val_binary_accuracy: 0.8626\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.3303 - binary_accuracy: 0.8786 - val_loss: 0.3314 - val_binary_accuracy: 0.8700\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2834 - binary_accuracy: 0.8945 - val_loss: 0.3117 - val_binary_accuracy: 0.8744\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2519 - binary_accuracy: 0.9093 - val_loss: 0.3022 - val_binary_accuracy: 0.8758\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2278 - binary_accuracy: 0.9205 - val_loss: 0.2983 - val_binary_accuracy: 0.8776\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2088 - binary_accuracy: 0.9280 - val_loss: 0.2980 - val_binary_accuracy: 0.8790\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1932 - binary_accuracy: 0.9355 - val_loss: 0.2982 - val_binary_accuracy: 0.8796\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1772 - binary_accuracy: 0.9424 - val_loss: 0.3013 - val_binary_accuracy: 0.8806\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3219 - binary_accuracy: 0.8734\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.322 - Accuracy: 0.873\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= activation function = sigmoid ============\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_11  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_23 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 6ms/step - loss: 0.6502 - binary_accuracy: 0.6556 - val_loss: 0.5556 - val_binary_accuracy: 0.7766\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4340 - binary_accuracy: 0.8360 - val_loss: 0.3646 - val_binary_accuracy: 0.8554\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.3087 - binary_accuracy: 0.8778 - val_loss: 0.3141 - val_binary_accuracy: 0.8718\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2591 - binary_accuracy: 0.9000 - val_loss: 0.2968 - val_binary_accuracy: 0.8752\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2259 - binary_accuracy: 0.9142 - val_loss: 0.2912 - val_binary_accuracy: 0.8802\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2014 - binary_accuracy: 0.9247 - val_loss: 0.2906 - val_binary_accuracy: 0.8808\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1799 - binary_accuracy: 0.9345 - val_loss: 0.2957 - val_binary_accuracy: 0.8830\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1618 - binary_accuracy: 0.9428 - val_loss: 0.3035 - val_binary_accuracy: 0.8824\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1460 - binary_accuracy: 0.9498 - val_loss: 0.3141 - val_binary_accuracy: 0.8826\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1316 - binary_accuracy: 0.9565 - val_loss: 0.3282 - val_binary_accuracy: 0.8810\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3672 - binary_accuracy: 0.8654\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.367 - Accuracy: 0.865\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOBe7jHOHLQ_"
      },
      "source": [
        "### With different Batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dPOERiaH501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12d4940-f23a-49ba-f9e4-f55d6ef85320"
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 64\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('aclImdb/test',\n",
        "                                                       batch_size = batch_size)\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(raw_train))\n",
        "\n",
        "## print an instance with vectorized review and label for observing\n",
        "print ('REVIEW:', text_batch[0])\n",
        "print('LABEL:', raw_train.class_names[label_batch[0]] )\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropout =  0.1\n",
        "activation =  'softmax'\n",
        "\n",
        "print (\"======== activation function = {}, dropout = {}, batch size = {} ============\".format(activation, dropout, batch_size ))\n",
        "model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim, name=\"embedding\"),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.GlobalAveragePooling1D(),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.Dense(32, activation= activation),\n",
        "                            layers.Dense(1)])\n",
        "print(model.summary())\n",
        "\n",
        "# configure the model uisng optimizer and loss function\n",
        "model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "              optimizer = 'adam',\n",
        "              metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "# training the model\n",
        "epochs = 10\n",
        "history = model.fit(train,\n",
        "                    validation_data = val,\n",
        "                    epochs = epochs)\n",
        "# testing the model\n",
        "pred_label = tf.argmax(model.predict(test),1)\n",
        "true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "loss, accuracy = model.evaluate(test)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "REVIEW: tf.Tensor(b\"First of all, I liked very much the central idea of locating the '' intruders'', Others in the fragile Self, on various levels - mainly subconscious but sometimes more allegorical. In fact the intruders are omnipresent throughout the film : in the Swiss-French border where the pretagonist leads secluded life; in the his recurring daydream and nightmare; inside his ailing body after heart transplantation.... In the last half of the film, he becomes intruder himself, returning in ancient french colony in the hope of atoning for the past. <br /><br />The overall tone is bitter rather than pathetic, full of regrets and guilts, sense of failure being more or less dominant. This is a quite grim picture of an old age, ostensibly self-dependent but hopelessly void and lonely inside. The directer composes the images more to convey passing sensations of anxiety and desire than any explicit meanings. Some of them are mesmerizing, not devoid of humor though, kind of absurdist play only somnambulist can visualize.\", shape=(), dtype=string)\n",
            "LABEL: pos\n",
            "======== activation function = softmax, dropout = 0.1, batch size = 64 ============\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_24 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_12  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.6855 - binary_accuracy: 0.6068 - val_loss: 0.6589 - val_binary_accuracy: 0.7460\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5772 - binary_accuracy: 0.7974 - val_loss: 0.4925 - val_binary_accuracy: 0.8328\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4141 - binary_accuracy: 0.8598 - val_loss: 0.3730 - val_binary_accuracy: 0.8618\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3235 - binary_accuracy: 0.8808 - val_loss: 0.3267 - val_binary_accuracy: 0.8702\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2758 - binary_accuracy: 0.8986 - val_loss: 0.3083 - val_binary_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2446 - binary_accuracy: 0.9120 - val_loss: 0.3008 - val_binary_accuracy: 0.8760\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2220 - binary_accuracy: 0.9224 - val_loss: 0.2976 - val_binary_accuracy: 0.8784\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2053 - binary_accuracy: 0.9295 - val_loss: 0.2970 - val_binary_accuracy: 0.8794\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1877 - binary_accuracy: 0.9378 - val_loss: 0.2992 - val_binary_accuracy: 0.8804\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1717 - binary_accuracy: 0.9441 - val_loss: 0.3033 - val_binary_accuracy: 0.8816\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3246 - binary_accuracy: 0.8737\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.325 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.5, 0.25, 0.5, 0.3333333333333333)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7OsTdtjWfge"
      },
      "source": [
        "### With different training algorithm\n",
        "Here we mostly focus on adapting learning rate method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnIwxcEVW4CC",
        "outputId": "0856b1fc-5097-41a8-a873-2d285c272cc6"
      },
      "source": [
        "# configure the model uisng optimizer and loss function\n",
        "optimizers = ['adagrad', 'rmsprop', 'adam']\n",
        "\n",
        "print (\"======== activation function = {}, dropout = {}, batch size = {} ============\".format(activation, dropout, batch_size ))\n",
        "for opt in optimizers:\n",
        "  print( '========== optimizer = %s' %opt)\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = opt,\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = tf.argmax(model.predict(test),1)\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== activation function = softmax, dropout = 0.1, batch size = 64 ============\n",
            "========== optimizer = adagrad\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 5ms/step - loss: 0.1576 - binary_accuracy: 0.9516 - val_loss: 0.3045 - val_binary_accuracy: 0.8802\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1571 - binary_accuracy: 0.9520 - val_loss: 0.3045 - val_binary_accuracy: 0.8804\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 6ms/step - loss: 0.1574 - binary_accuracy: 0.9513 - val_loss: 0.3045 - val_binary_accuracy: 0.8802\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1567 - binary_accuracy: 0.9529 - val_loss: 0.3046 - val_binary_accuracy: 0.8802\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1573 - binary_accuracy: 0.9513 - val_loss: 0.3046 - val_binary_accuracy: 0.8802\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1570 - binary_accuracy: 0.9523 - val_loss: 0.3047 - val_binary_accuracy: 0.8802\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1571 - binary_accuracy: 0.9525 - val_loss: 0.3047 - val_binary_accuracy: 0.8798\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1572 - binary_accuracy: 0.9516 - val_loss: 0.3047 - val_binary_accuracy: 0.8800\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1569 - binary_accuracy: 0.9521 - val_loss: 0.3047 - val_binary_accuracy: 0.8800\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1562 - binary_accuracy: 0.9520 - val_loss: 0.3048 - val_binary_accuracy: 0.8798\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3256 - binary_accuracy: 0.8738\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.326 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========== optimizer = rmsprop\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 5ms/step - loss: 0.1584 - binary_accuracy: 0.9510 - val_loss: 0.3123 - val_binary_accuracy: 0.8802\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1513 - binary_accuracy: 0.9527 - val_loss: 0.3169 - val_binary_accuracy: 0.8810\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1475 - binary_accuracy: 0.9545 - val_loss: 0.3211 - val_binary_accuracy: 0.8828\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1446 - binary_accuracy: 0.9546 - val_loss: 0.3245 - val_binary_accuracy: 0.8826\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1420 - binary_accuracy: 0.9548 - val_loss: 0.3271 - val_binary_accuracy: 0.8838\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1386 - binary_accuracy: 0.9559 - val_loss: 0.3296 - val_binary_accuracy: 0.8838\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1361 - binary_accuracy: 0.9568 - val_loss: 0.3328 - val_binary_accuracy: 0.8822\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1344 - binary_accuracy: 0.9576 - val_loss: 0.3349 - val_binary_accuracy: 0.8804\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1323 - binary_accuracy: 0.9591 - val_loss: 0.3375 - val_binary_accuracy: 0.8800\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.1302 - binary_accuracy: 0.9599 - val_loss: 0.3411 - val_binary_accuracy: 0.8798\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3825 - binary_accuracy: 0.8650\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.383 - Accuracy: 0.865\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========== optimizer = adam\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1301 - binary_accuracy: 0.9588 - val_loss: 0.3391 - val_binary_accuracy: 0.8830\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1219 - binary_accuracy: 0.9635 - val_loss: 0.3426 - val_binary_accuracy: 0.8810\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1139 - binary_accuracy: 0.9668 - val_loss: 0.3479 - val_binary_accuracy: 0.8812\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1064 - binary_accuracy: 0.9702 - val_loss: 0.3575 - val_binary_accuracy: 0.8830\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0990 - binary_accuracy: 0.9733 - val_loss: 0.3662 - val_binary_accuracy: 0.8824\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0930 - binary_accuracy: 0.9757 - val_loss: 0.3766 - val_binary_accuracy: 0.8818\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0866 - binary_accuracy: 0.9782 - val_loss: 0.3865 - val_binary_accuracy: 0.8802\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.0803 - binary_accuracy: 0.9811 - val_loss: 0.3999 - val_binary_accuracy: 0.8802\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0756 - binary_accuracy: 0.9829 - val_loss: 0.4097 - val_binary_accuracy: 0.8788\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0695 - binary_accuracy: 0.9847 - val_loss: 0.4213 - val_binary_accuracy: 0.8784\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.4963 - binary_accuracy: 0.8522\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.496 - Accuracy: 0.852\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln0waE00a6eE"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LsKSP4Sa-kC"
      },
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im8CyYCyWuOI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a116d08-7891-429e-9d6c-b4ae99c36221"
      },
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def Find_similar_w (word, n):\n",
        "  all_cos_sim = {}\n",
        "  idx = vocab.index(word)\n",
        "  weight = weights[idx]\n",
        "  for i in range(len(weights)-1):\n",
        "    cosine_sim = cosine_similarity(weight.reshape(1, -1), weights[i].reshape(1, -1))\n",
        "    all_cos_sim[vocab[i]] = cosine_sim\n",
        "  # Sorting the dictionary in descending order\n",
        "  sorted_cos = {k:v for k, v in sorted(all_cos_sim.items(), key = lambda item: item[1], reverse=True)}\n",
        "  print (\"Top {} most similar with '{}' \\n\".format(n, word))\n",
        "  for k, v in list(sorted_cos.items())[:n]:\n",
        "    print ('{} =====> {}'. format(k,v))\n",
        "  return  sorted_cos\n",
        "most_similar_w = Find_similar_w (word = 'boring', n = 20)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 most similar with 'boring' \n",
            "\n",
            "boring =====> [[0.99999994]]\n",
            "mess =====> [[0.9989057]]\n",
            "disappointment =====> [[0.99860525]]\n",
            "waste =====> [[0.99847364]]\n",
            "redeeming =====> [[0.9984642]]\n",
            "staff =====> [[0.99844575]]\n",
            "reanimator =====> [[0.99843556]]\n",
            "stalks =====> [[0.99842757]]\n",
            "meyer =====> [[0.9984252]]\n",
            "nasa =====> [[0.99840856]]\n",
            "toes =====> [[0.9983841]]\n",
            "lacks =====> [[0.9983781]]\n",
            "tolerance =====> [[0.9983752]]\n",
            "lousy =====> [[0.99834603]]\n",
            "ludicrous =====> [[0.99833924]]\n",
            "thunderbirds =====> [[0.99833924]]\n",
            "weak =====> [[0.9983222]]\n",
            "eg =====> [[0.9983173]]\n",
            "miscast =====> [[0.9983164]]\n",
            "poorly =====> [[0.99828535]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiijE5K_bARq"
      },
      "source": [
        "## Comparing with a Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKdXFowRwer9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248290f2-e3a2-45e3-8808-7ef03b95d98b"
      },
      "source": [
        "# loading the ds\n",
        "def Getdata(dir):\n",
        "  review, label = [], []\n",
        "  for folder in glob.glob (dir+'/*'):\n",
        "    for file in glob.glob(folder+'/*'): \n",
        "      fo = open(file)\n",
        "      doc = fo.read()\n",
        "      review.append (doc)\n",
        "      if 'pos' in file:\n",
        "        label.append(1)\n",
        "      elif 'neg' in file:\n",
        "        label.append(0)\n",
        "  df = pd.DataFrame(zip(review,label), columns = ['review', 'label'])\n",
        "  return df\n",
        "  \n",
        "train_df = Getdata(train_dir)\n",
        "test_df = Getdata(test_dir)\n",
        "# Spliting the dataset for training and testing\n",
        "X_train, X_val, y_train, y_val = train_test_split (train_df['review'],train_df['label'], train_size = 0.8, random_state = 42, shuffle = True)\n",
        "X_test, y_test = test_df['review'], test_df['label']\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_val, y_val: ', X_val.shape, y_val.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape) "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (20000,) (20000,)\n",
            "Shapes of X_val, y_val:  (5000,) (5000,)\n",
            "Shapes of X_test, y_test:  (25000,) (25000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhfG0yG8meEX"
      },
      "source": [
        "\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred)\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred)\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred)\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hALCMWMSmLhv"
      },
      "source": [
        "### With Countvectorizer text presentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9BcQ-UebIcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a09961c-6de7-4782-9e6a-d3f200467100"
      },
      "source": [
        "\n",
        "# Vectorizing the documents\n",
        "vectorizer = CountVectorizer(binary = True)\n",
        "X_train_count = vectorizer.fit_transform(X_train.to_list())\n",
        "X_val_count = vectorizer.transform(X_val.to_list())\n",
        "X_test_count = vectorizer.transform(X_test.to_list())\n",
        "print ('Shapes of X_train, y_train: ', X_train_count.shape, y_train.shape)\n",
        "print ('Shapes of X_val, y_val: ', X_val_count.shape, y_val.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test_count.shape, y_test.shape)\n",
        "\n",
        "# Sklearn Logistic Regression Model\n",
        "sk_lr_1 = LogisticRegression(solver='lbfgs', max_iter=500).fit(X_train_count, y_train )\n",
        "y_predict = sk_lr_1.predict(X_test_count)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance with Countvectorizer: \\non validation set:')\n",
        "printing_eval_scores (y_val, sk_lr_1.predict(X_val_count))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('on test set:')\n",
        "printing_eval_scores (y_test, y_predict, report = True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (20000, 68468) (20000,)\n",
            "Shapes of X_val, y_val:  (5000, 68468) (5000,)\n",
            "Shapes of X_test, y_test:  (25000, 68468) (25000,)\n",
            "Model performance with Countvectorizer: \n",
            "on validation set:\n",
            "accuracy score: 0.872\n",
            "precision score: 0.862\n",
            "recall score: 0.883\n",
            "F1 score: 0.873\n",
            "\n",
            "===========================\n",
            "on test set:\n",
            "accuracy score: 0.866\n",
            "precision score: 0.866\n",
            "recall score: 0.866\n",
            "F1 score: 0.866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87     12500\n",
            "           1       0.87      0.87      0.87     12500\n",
            "\n",
            "    accuracy                           0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8658, 0.8659463785514205, 0.8656, 0.8657731546309262)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ex3J6rmVKu"
      },
      "source": [
        "### With tf-idf text presentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av3pjC83mUbt",
        "outputId": "ec8939df-40fc-43f3-a5af-ea50845b9643"
      },
      "source": [
        "# Vectorizing the documents\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train.to_list())\n",
        "X_val_tfidf = tfidf.transform(X_val.to_list())\n",
        "X_test_tfidf = tfidf.transform(X_test.to_list())\n",
        "print ('Shapes of X_train, y_train: ', X_train_tfidf.shape, y_train.shape)\n",
        "print ('Shapes of X_val, y_val: ', X_val_tfidf.shape, y_val.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test_tfidf.shape, y_test.shape)\n",
        "\n",
        "# Sklearn Logistic Regression Model\n",
        "sk_lr_2 = LogisticRegression(solver='lbfgs', max_iter=500).fit(X_train_tfidf, y_train )\n",
        "y_predict = sk_lr_2.predict(X_test_tfidf)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance with tfidf: \\non validation set:')\n",
        "printing_eval_scores (y_val, sk_lr_2.predict(X_val_tfidf))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('on test set:')\n",
        "printing_eval_scores (y_test, y_predict, report = True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (20000, 68468) (20000,)\n",
            "Shapes of X_val, y_val:  (5000, 68468) (5000,)\n",
            "Shapes of X_test, y_test:  (25000, 68468) (25000,)\n",
            "Model performance with tfidf: \n",
            "on validation set:\n",
            "accuracy score: 0.893\n",
            "precision score: 0.888\n",
            "recall score: 0.898\n",
            "F1 score: 0.893\n",
            "\n",
            "===========================\n",
            "on test set:\n",
            "accuracy score: 0.882\n",
            "precision score: 0.881\n",
            "recall score: 0.883\n",
            "F1 score: 0.882\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88     12500\n",
            "           1       0.88      0.88      0.88     12500\n",
            "\n",
            "    accuracy                           0.88     25000\n",
            "   macro avg       0.88      0.88      0.88     25000\n",
            "weighted avg       0.88      0.88      0.88     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.882, 0.8811462324393359, 0.88312, 0.8821320121463961)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUMJOCJYERVd"
      },
      "source": [
        "# Part 2: Multiclass classification - Stackoverflow DS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WThVxknkGiXc"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xxae0yIEyQW",
        "outputId": "577ed3c5-3b0e-4574-d0f3-d27fc24a2863"
      },
      "source": [
        "url_2 = 'http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
        "train_dir = tf.keras.utils.get_file ('train',\n",
        "                                url_2,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "test_dir = tf.keras.utils.get_file ('test',\n",
        "                                url_2,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "\n",
        "print(os.listdir(train_dir))\n",
        "print(os.listdir(test_dir))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['java', 'javascript', 'python', 'csharp']\n",
            "['java', 'javascript', 'python', 'csharp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_BzBYOENa8D",
        "outputId": "96ab8f9d-6ba8-4b02-d83b-479acb5d81fd"
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('test',\n",
        "                                                       batch_size = batch_size)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 files belonging to 4 classes.\n",
            "Using 6400 files for training.\n",
            "Found 8000 files belonging to 4 classes.\n",
            "Using 1600 files for validation.\n",
            "Found 8000 files belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YKsqlUKNsmz"
      },
      "source": [
        "## Text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPCScxOwNwQr",
        "outputId": "abb66faa-f26a-4aef-933e-09eee214932b"
      },
      "source": [
        "def custom_preprocessing (text):\n",
        "  lowercase = tf.strings.lower (text)\n",
        "  stripped_html = tf.strings.regex_replace (lowercase,'<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), \n",
        "                                  '')\n",
        "  \n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(standardize = custom_preprocessing,\n",
        "                                           max_tokens = max_features,\n",
        "                                           output_mode = 'int',\n",
        "                                           output_sequence_length = sequence_length)\n",
        "# Extracting features for vectorizing using training set\n",
        "train_text = raw_train.map (lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "# Defining a function for fitting vectorizer function/layer to vectorize text (review)\n",
        "def fitting_vectorizer (text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer (text), label\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(raw_train))\n",
        "\n",
        "## print an instance with vectorized review and label for observing\n",
        "print ('text:', text_batch[0])\n",
        "print('label:', raw_train.class_names[label_batch[0]] )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text: tf.Tensor(b'\"unit testing of setters and getters teacher wanted us to do a comprehensive unit test. for me, this will be the first time that i use junit. i am confused about testing set and get methods. do you think should i test them? if the answer is yes; is this code enough for testing?..  public void testsetandget(){.    int a = 10;.    class firstclass = new class();.    firstclass.setvalue(10);.    int value = firstclass.getvalue();.    assert.asserttrue(\"\"error\"\", value==a);.  }...in my code, i think if there is an error, we can\\'t know that the error is deriving because of setter or getter.\"\\n', shape=(), dtype=string)\n",
            "label: java\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJnvsj58OXds"
      },
      "source": [
        "train = raw_train.map(fitting_vectorizer)\n",
        "val = raw_val.map(fitting_vectorizer)\n",
        "test = raw_test.map(fitting_vectorizer)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8TSwV8VOdBD"
      },
      "source": [
        "# Configure the dataset for performance\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train = train.cache().prefetch (buffer_size = autotune)\n",
        "val = val.cache().prefetch (buffer_size = autotune)\n",
        "test = test.cache().prefetch (buffer_size = autotune)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0PwGsDTTdnO",
        "outputId": "fe2e6ff1-0cba-4628-edb0-8f1d443b2166"
      },
      "source": [
        "for i, j in test:\n",
        "  print(j)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 2 0 3 0 0 3 2 0 0 2 2 3 1 1 2 0 3 0 3 0 2 0 3 0 2 3 1 1 0 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 2 1 3 1 2 3 0 1 0 2 3 3 1 0 3 2 1 2 3 0 0 3 1 0 3 1 3 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 2 3 2 0 2 1 3 1 3 2 3 0 2 2 1 3 0 0 1 3 1 2 0 1 2 3 3 0 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 0 3 2 0 2 1 0 2 2 0 3 0 1 3 0 2 2 3 2 1 2 0 1 2 2 1 1 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 0 3 1 3 3 2 1 3 3 1 3 2 2 1 2 1 0 1 1 0 2 1 2 2 1 3 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 3 3 0 2 2 3 2 2 2 0 1 0 0 2 3 0 1 0 2 0 1 1 1 2 2 0 1 2 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 3 2 1 2 0 3 3 0 0 2 3 0 3 3 1 0 3 3 1 1 3 3 0 3 3 0 1 1 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 3 1 1 0 2 3 3 0 1 2 2 0 0 0 0 2 3 3 3 0 0 2 0 0 2 3 1 0 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 3 2 3 2 2 2 0 1 3 2 0 1 2 1 1 0 2 1 0 2 2 1 2 2 1 3 1 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 1 0 2 1 0 3 0 3 3 1 0 0 1 3 1 0 3 2 3 2 1 0 3 1 2 2 0 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 1 2 1 2 1 3 3 3 1 2 0 0 3 2 1 3 1 3 3 0 1 3 2 3 3 0 0 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 1 2 1 3 1 3 2 0 0 0 1 1 1 0 2 2 1 1 0 0 1 0 0 0 1 2 3 1 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 0 2 3 3 1 1 2 0 2 2 3 1 2 3 3 2 3 1 1 3 2 3 1 2 1 2 3 0 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 0 1 2 2 0 3 0 0 1 2 2 2 3 0 2 3 0 3 0 1 2 3 3 3 3 1 3 0 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 2 3 1 2 3 2 1 3 2 1 3 2 3 1 0 2 0 0 1 1 0 3 0 1 0 1 2 3 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 0 2 2 3 1 0 2 0 1 0 2 1 3 2 2 0 1 2 1 2 2 2 2 1 1 1 1 3 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 3 0 0 0 2 3 1 0 0 2 1 2 3 2 1 1 2 3 3 1 1 3 0 1 3 0 0 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 0 2 2 2 2 1 3 1 3 1 2 2 2 1 0 2 0 1 3 1 3 1 3 0 0 2 1 3 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 3 0 2 1 1 1 3 0 3 1 0 0 2 2 2 1 0 2 2 2 3 3 0 3 3 3 0 2 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 3 3 1 0 0 1 0 1 0 3 2 0 2 1 1 2 3 2 1 0 3 2 1 1 2 3 0 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 2 2 3 3 3 3 2 0 3 3 1 1 2 2 1 2 3 1 2 1 2 0 0 2 3 1 3 3 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 2 0 3 3 3 0 0 3 2 0 0 0 3 3 3 1 2 3 1 0 3 0 0 3 1 3 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 1 2 3 3 1 0 0 2 2 0 0 3 2 1 2 3 2 1 1 2 1 3 3 1 1 3 0 2 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 0 3 1 0 2 3 2 3 2 3 3 1 1 1 0 3 3 3 2 3 0 0 2 1 1 0 2 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 3 2 0 0 2 1 3 3 1 0 3 1 3 1 3 0 2 0 2 1 3 3 1 1 1 2 1 0 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 3 0 2 2 0 1 1 2 0 2 3 3 3 2 0 0 2 2 1 3 2 3 2 0 1 1 1 0 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 1 3 1 1 1 2 0 2 3 0 0 2 0 0 1 0 2 2 3 0 1 3 2 1 1 1 3 1 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 3 0 2 2 3 0 1 1 0 1 1 1 3 1 1 3 0 2 0 0 3 2 3 0 0 0 1 0 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 0 0 0 3 3 3 2 2 2 3 3 3 2 2 3 3 2 3 3 1 0 0 3 3 1 2 3 3 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 1 3 0 3 3 0 1 1 2 1 3 3 2 3 1 0 3 3 1 2 0 0 0 3 2 2 3 2 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 3 2 0 0 1 3 1 3 0 1 3 0 2 0 2 3 3 0 0 0 0 2 0 3 0 3 1 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 2 0 2 2 1 2 0 3 2 2 0 0 3 3 2 2 3 1 1 0 1 1 2 0 3 1 2 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 3 1 1 3 1 2 3 3 0 3 1 1 3 1 2 0 3 2 3 0 3 0 2 3 0 0 0 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 3 1 1 1 3 1 2 2 3 0 1 2 2 3 0 1 1 0 1 1 1 2 0 1 2 2 1 3 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 3 0 1 2 2 0 1 3 3 1 3 3 1 2 0 1 2 2 1 0 0 0 2 3 0 3 1 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 3 3 1 1 1 3 0 0 3 1 2 0 3 2 1 1 3 1 1 0 0 3 1 2 3 1 0 0 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 2 2 3 0 2 3 1 3 1 0 0 2 0 0 1 1 2 1 2 1 3 3 0 2 1 3 3 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 3 2 2 1 0 0 0 1 2 0 0 2 3 0 2 0 1 2 3 2 2 3 2 1 2 3 3 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 1 0 0 1 2 2 3 1 3 1 3 0 3 3 3 3 2 0 3 3 3 3 0 1 1 1 0 1 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 3 0 0 2 2 2 0 0 0 3 0 3 2 2 0 1 3 3 2 2 1 1 0 3 0 1 3 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 1 0 3 2 1 3 1 2 1 2 3 1 1 1 1 1 1 0 2 1 0 2 0 0 0 2 0 3 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 0 2 3 1 0 1 0 0 2 1 1 3 1 2 1 0 1 3 1 1 0 3 1 3 1 2 2 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 0 3 0 2 3 0 0 2 3 3 1 3 3 0 2 0 0 3 2 3 1 2 0 0 0 2 3 2 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 0 3 2 2 2 1 0 1 2 1 0 1 0 1 1 0 1 0 1 2 0 0 3 3 3 2 2 2 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 3 1 3 0 0 2 1 1 0 2 2 0 2 3 0 2 2 2 3 0 3 2 3 1 1 0 2 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 2 3 3 0 2 1 2 2 0 1 0 1 3 3 1 1 1 1 3 1 3 0 1 2 2 2 1 1 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 1 1 2 2 2 0 1 2 0 0 1 1 1 2 1 1 2 3 3 0 3 0 0 1 0 1 0 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 0 3 3 1 1 0 3 2 2 0 3 2 2 3 2 2 0 2 2 3 0 3 0 2 3 2 3 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 1 3 2 0 2 3 3 2 3 0 3 3 3 0 2 3 0 2 0 3 1 1 1 1 2 0 2 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 2 0 3 2 1 2 3 1 1 0 2 1 3 0 2 2 0 3 1 1 0 3 3 2 0 1 2 0 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 3 0 3 0 2 3 2 3 1 0 2 2 3 3 0 0 3 0 2 3 3 1 1 2 1 2 2 3 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 1 3 1 2 0 2 0 1 2 3 3 2 3 0 2 1 3 1 1 3 2 1 2 3 3 2 2 3 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 3 2 3 0 2 2 3 1 3 2 2 1 3 2 0 2 2 1 0 1 0 0 1 1 3 2 0 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 3 2 2 3 3 2 1 3 3 3 1 3 3 0 1 2 2 2 1 0 1 0 3 3 2 0 0 3 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 0 2 3 2 2 1 1 2 0 1 0 2 0 3 2 3 1 3 3 0 1 3 3 2 2 1 3 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 2 2 0 3 2 2 0 0 0 2 0 3 1 3 0 0 1 1 0 1 2 0 3 2 0 2 3 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 1 2 2 3 2 1 2 0 2 2 3 2 3 3 3 1 0 1 3 0 0 1 0 2 1 2 2 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 3 0 3 2 2 3 2 2 3 2 2 2 2 1 3 0 1 2 1 3 2 1 3 3 2 3 0 0 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 1 2 2 2 1 1 1 3 3 3 2 2 3 2 2 1 2 0 0 3 0 1 2 1 0 0 3 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 2 3 2 2 2 0 0 1 0 1 1 1 2 1 3 3 3 1 2 2 0 1 1 1 1 0 1 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 0 1 2 2 3 0 3 1 1 0 3 1 0 2 3 0 0 2 0 1 3 1 0 0 1 1 3 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 1 0 1 0 1 0 1 3 1 2 2 0 1 0 1 1 2 3 0 3 2 1 1 0 1 0 0 3 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 3 1 1 3 3 3 0 0 3 0 2 0 3 2 3 1 0 3 0 3 3 1 3 2 0 2 0 3 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 0 1 2 3 1 3 2 1 3 2 2 0 1 0 0 1 3 1 2 3 1 0 2 2 0 3 3 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 3 3 0 2 1 0 0 3 0 0 1 1 1 3 0 3 0 2 3 3 3 1 1 0 0 2 2 2 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 1 3 0 0 1 0 1 0 0 0 3 2 3 2 2 3 3 0 2 1 3 3 2 1 3 1 0 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 3 3 1 1 0 0 1 0 1 2 0 2 2 1 2 1 2 1 3 0 0 2 1 3 2 1 1 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 2 1 0 0 1 3 3 2 1 0 0 2 1 2 0 3 3 0 0 2 3 0 3 0 1 1 3 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 2 1 1 0 2 2 1 1 3 1 0 3 1 2 2 2 2 2 0 0 3 1 2 1 2 0 3 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 2 3 0 3 2 3 3 0 0 1 0 0 0 1 1 2 1 1 0 0 1 0 0 2 3 2 0 3 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 3 0 0 1 3 0 1 1 1 1 0 1 2 1 3 1 3 1 2 1 1 1 3 3 3 3 2 1 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 2 2 0 2 0 2 1 0 1 1 3 2 1 0 1 2 1 3 2 3 2 1 3 2 0 3 2 3 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 3 3 1 2 0 0 3 3 3 1 1 1 2 1 0 3 2 1 2 3 2 2 1 3 3 3 2 2 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 0 3 0 3 2 0 1 1 2 1 3 2 3 3 0 2 0 3 1 3 0 1 1 0 1 1 0 0 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 2 1 1 1 1 2 0 3 0 3 3 3 3 0 3 0 1 1 3 1 2 2 3 0 3 2 0 2 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 0 3 0 2 1 3 1 0 3 3 3 0 1 3 3 2 3 3 0 3 0 2 2 0 1 1 0 0 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 0 1 1 3 1 3 3 1 3 1 0 3 1 3 0 3 3 3 1 1 0 0 3 3 1 0 2 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 3 1 0 0 3 0 2 0 2 3 0 2 2 2 3 2 3 2 2 1 0 2 2 1 0 3 1 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 2 2 3 2 1 3 0 0 1 0 0 3 1 0 2 0 3 0 0 3 2 2 2 0 1 2 0 2 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 2 3 1 1 2 1 3 0 0 1 2 0 2 0 3 0 0 0 2 0 3 0 2 2 3 0 1 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 3 1 3 2 2 1 0 1 3 3 1 3 1 0 3 0 1 0 1 2 0 0 2 1 3 3 2 0 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 1 1 3 3 2 1 1 1 0 1 2 2 0 0 1 3 0 3 0 1 0 2 0 2 0 3 2 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 0 1 2 1 0 3 0 1 3 0 0 0 3 2 0 1 2 1 0 0 0 3 0 2 1 2 1 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 2 2 2 2 2 2 3 1 3 1 3 1 1 1 1 1 3 1 3 2 0 1 3 0 3 1 1 1 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 0 0 2 0 2 1 3 0 2 1 3 2 1 2 2 1 2 0 1 2 1 1 2 0 3 3 0 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 1 3 3 3 1 3 1 1 0 1 2 3 0 3 1 3 2 2 2 3 1 3 3 0 0 2 1 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 1 3 1 3 1 1 0 2 0 1 2 1 1 1 1 0 1 3 0 1 0 0 3 2 0 2 3 1 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 0 2 0 3 2 2 1 1 3 1 1 3 2 1 0 3 0 3 1 1 1 0 1 3 3 2 1 1 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 1 1 1 3 2 0 0 2 1 0 0 0 0 0 3 1 0 2 0 0 0 1 3 1 2 3 0 3 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 1 3 0 2 3 2 3 2 3 3 3 0 0 3 3 0 1 2 1 3 1 3 3 3 1 2 1 2 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 0 0 3 0 3 1 0 0 3 2 2 3 2 0 1 0 0 3 3 3 0 3 2 1 0 0 3 3 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 3 0 0 0 3 0 3 0 3 1 2 3 3 0 2 1 0 1 0 2 2 2 1 1 2 3 1 2 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 0 1 2 0 3 1 0 1 3 3 3 3 2 3 3 2 3 3 3 0 0 1 2 1 1 2 1 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 3 1 2 0 2 2 0 3 3 2 2 0 1 1 2 2 2 3 1 3 1 3 3 2 0 3 2 2 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 0 0 1 1 1 0 0 3 1 2 2 2 2 1 1 0 0 3 3 2 0 1 2 2 2 0 1 0 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 1 2 1 2 2 0 0 1 3 3 3 3 1 1 2 0 0 3 1 1 0 0 3 3 3 0 1 2 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 0 2 3 1 0 2 2 3 1 1 1 2 0 0 2 3 2 3 0 3 2 1 2 3 0 2 1 2 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 3 2 1 2 2 1 3 2 2 2 0 1 3 3 0 2 3 1 2 0 1 0 3 1 3 3 1 1 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 1 2 1 1 1 3 1 1 0 2 1 2 2 0 3 3 2 0 2 3 3 3 2 3 3 3 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 1 2 1 2 2 2 3 0 1 0 0 3 0 3 1 2 2 3 1 0 2 2 0 2 2 1 3 0 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 0 2 0 1 0 3 2 0 3 1 3 2 2 2 1 3 0 3 1 2 2 3 2 2 2 3 3 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 1 3 1 3 3 0 0 2 2 3 2 3 3 2 3 0 0 0 2 3 3 0 2 2 1 3 2 2 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 1 0 0 3 1 1 3 2 0 3 0 0 2 2 3 3 1 0 1 2 3 1 2 0 3 0 2 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 1 0 1 1 1 2 2 3 1 2 2 3 3 0 0 1 3 2 2 2 1 3 1 2 0 3 1 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 1 1 0 1 0 3 1 2 0 0 2 2 1 0 0 0 2 0 1 3 3 2 3 1 2 2 2 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 2 1 3 0 2 3 0 0 1 0 1 2 0 2 0 1 0 0 0 2 0 3 1 2 1 2 3 2 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 1 0 3 2 1 3 1 2 0 0 1 0 3 0 2 3 3 0 1 2 0 0 2 2 0 3 2 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 1 0 1 0 1 2 1 0 2 3 3 1 2 1 2 3 2 1 2 0 1 3 1 3 0 0 2 0 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 0 0 0 0 1 1 3 0 3 1 2 1 1 2 2 0 3 0 2 1 0 1 1 1 1 0 0 0 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 3 3 2 0 0 1 2 3 3 0 2 2 2 2 1 1 1 3 2 2 1 3 3 3 0 1 2 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 2 2 2 3 0 0 0 2 3 2 1 2 2 2 3 3 1 3 1 0 0 1 1 3 3 0 2 0 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 1 1 0 0 3 3 3 1 2 0 3 2 2 2 1 2 2 2 1 3 1 3 1 3 2 2 0 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 1 3 3 0 0 1 0 2 1 3 1 2 1 1 3 0 3 3 1 2 3 2 1 3 2 1 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 2 0 0 1 0 3 2 3 0 0 3 0 2 1 1 0 3 1 0 1 2 3 0 1 2 2 2 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 0 0 0 3 0 2 0 2 0 3 1 1 2 1 0 1 1 0 0 0 1 2 1 2 2 0 3 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 1 2 0 2 3 3 3 1 3 1 2 2 1 3 1 0 3 2 2 0 2 0 2 2 0 1 1 1 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 2 0 1 3 3 2 0 2 2 2 0 2 3 2 2 0 0 2 2 2 3 1 1 1 0 2 1 3 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 1 1 1 1 1 3 0 3 2 3 0 1 1 3 1 3 0 0 1 2 3 3 0 0 1 1 1 3 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 2 0 1 2 0 3 2 3 0 0 1 1 2 1 2 2 0 3 3 3 3 0 1 2 3 2 2 0 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 3 2 1 3 3 0 0 3 3 1 0 1 3 2 3 3 2 1 3 1 3 0 0 1 1 1 2 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 3 1 2 2 2 3 3 2 2 0 2 3 3 3 0 2 1 2 3 2 1 3 0 3 1 3 2 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 2 1 2 1 0 0 0 2 0 0 1 3 0 1 3 2 3 2 1 2 1 0 1 0 1 1 3 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 1 2 1 0 3 2 2 3 2 0 2 3 3 3 1 1 2 0 0 3 0 2 3 2 0 3 2 2 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 0 3 1 1 3 2 0 1 2 2 2 2 1 3 2 3 1 0 2 3 0 0 1 0 1 2 2 0 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 0 0 2 3 0 0 2 2 2 1 2 2 2 1 3 1 0 2 2 1 1 0 1 3 1 3 3 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 1 2 2 3 3 3 3 1 1 3 3 3 1 2 2 3 0 3 0 0 2 2 0 3 0 0 0 1 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 3 1 0 1 2 1 3 1 1 3 2 3 3 0 0 3 1 1 3 1 0 3 1 0 2 2 0 3 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 2 3 0 0 2 3 1 0 2 0 0 2 3 0 0 3 2 2 3 2 2 3 3 2 0 0 3 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 1 1 2 1 2 0 3 2 1 2 2 2 1 3 1 1 0 1 2 3 1 3 1 0 2 3 2 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 3 3 1 2 2 3 0 2 0 1 0 3 1 3 0 0 1 3 3 1 0 2 3 2 1 1 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 0 1 3 2 0 1 0 3 1 2 0 3 3 1 3 3 3 1 0 3 0 1 3 3 1 1 0 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 0 0 2 0 3 2 1 0 3 0 1 0 0 2 0 0 3 0 0 1 2 0 3 1 2 0 3 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 3 2 1 3 1 1 1 0 1 0 0 2 1 2 2 0 0 2 1 1 2 3 2 1 1 0 2 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 1 0 2 2 1 0 1 2 2 3 3 0 0 3 1 3 2 1 0 1 2 2 3 0 0 0 1 3 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 0 2 3 3 2 1 2 1 3 1 3 2 3 1 0 0 1 2 2 2 3 1 1 0 2 3 3 1 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 0 2 2 3 3 2 3 1 2 0 3 1 2 3 1 2 1 1 2 1 2 1 3 2 1 0 0 3 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 0 1 3 3 1 1 0 0 1 0 3 2 2 0 3 1 0 2 1 1 0 3 3 2 0 1 2 2 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 0 1 1 3 3 2 0 2 2 2 1 0 1 2 2 3 3 2 1 2 1 3 2 0 1 0 1 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 1 2 0 0 1 3 2 1 1 1 3 1 1 2 0 2 0 2 2 1 1 2 3 0 3 2 1 1 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 0 0 0 3 2 2 1 0 2 3 2 1 0 3 0 3 0 1 3 0 1 3 1 3 0 0 0 2 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 1 2 0 3 2 0 2 2 1 2 2 3 2 3 2 0 0 2 1 2 2 2 0 1 3 2 0 0 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 3 3 1 0 2 0 1 1 2 1 0 2 1 1 1 2 2 3 2 1 0 3 1 0 3 0 0 0 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 0 1 3 2 1 0 1 0 0 0 2 3 2 2 1 0 3 0 3 2 1 3 2 0 3 2 0 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 0 0 0 0 3 2 0 1 1 2 1 1 1 3 0 2 2 0 3 3 1 2 3 3 2 2 2 1 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 2 1 2 0 0 3 2 2 2 3 0 1 1 3 2 2 0 0 3 1 3 0 3 3 0 1 1 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 3 0 1 1 2 3 0 0 3 3 2 0 2 3 1 1 1 0 3 3 2 2 1 0 1 1 1 0 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 3 2 0 0 1 0 2 2 2 3 3 0 1 2 1 0 1 2 0 1 0 2 0 1 1 0 3 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 0 1 1 1 3 0 3 3 1 1 3 2 3 1 1 0 0 3 2 0 0 1 0 3 0 2 1 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 2 3 0 1 0 2 0 0 0 1 2 3 1 2 2 0 0 2 2 3 2 0 0 2 3 0 3 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 0 1 0 1 3 2 3 3 3 3 3 2 0 0 3 3 2 3 3 1 1 3 3 3 1 3 2 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 2 0 1 3 2 1 3 1 0 0 1 3 2 0 1 0 2 0 0 2 2 0 1 1 1 1 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 3 0 1 2 1 0 1 3 0 0 0 0 3 2 2 1 1 1 3 0 0 0 2 2 2 1 1 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 2 2 3 0 3 0 1 2 2 0 2 2 2 3 0 2 0 0 3 2 0 2 1 1 2 1 0 1 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 3 2 3 0 1 1 0 0 2 1 2 2 2 3 0 0 2 3 0 2 3 0 1 3 1 3 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 0 2 1 0 3 0 1 3 2 2 2 2 2 0 0 3 2 2 0 2 3 1 1 3 3 3 2 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 1 3 3 1 0 0 3 0 0 0 2 1 3 3 2 2 2 3 0 3 0 0 1 2 3 1 1 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 1 0 0 0 0 0 0 1 1 0 1 2 3 1 1 2 1 2 0 3 2 3 2 2 3 0 2 3 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 2 3 0 0 3 2 2 0 0 1 3 2 1 1 3 3 3 1 1 3 2 3 1 0 1 0 1 2 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 1 2 2 0 1 2 3 2 1 0 3 3 2 0 1 2 1 0 2 0 3 2 0 3 1 1 3 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 0 2 0 0 0 3 0 0 1 2 3 2 1 1 2 2 0 0 3 3 1 3 1 1 2 1 3 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 2 1 2 1 3 3 2 2 0 2 1 1 0 0 3 2 1 0 2 1 2 3 0 0 1 0 0 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 1 1 3 1 1 1 0 2 2 2 1 0 1 0 2 1 2 0 2 0 0 0 3 0 0 1 2 0 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 2 2 3 3 0 3 1 2 2 1 0 2 3 3 3 3 0 3 3 3 0 3 3 3 0 0 1 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 2 2 0 3 3 1 3 2 0 1 0 3 1 3 1 1 1 1 3 3 0 0 1 3 1 0 2 3 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 0 3 1 0 2 0 3 0 3 2 3 2 0 3 0 1 2 0 3 1 3 2 2 2 2 2 2 2 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 0 2 3 0 3 0 3 0 2 3 2 1 2 1 0 1 2 2 0 2 3 2 0 2 1 0 0 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 2 2 1 3 2 0 0 0 2 3 2 3 0 1 0 1 3 2 2 3 0 1 1 2 2 3 2 3 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 1 2 1 0 1 3 0 3 0 2 3 0 2 3 3 2 0 2 0 1 1 1 2 3 0 1 3 1 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 2 3 2 1 1 1 0 1 1 3 0 3 1 3 0 3 0 2 0 1 0 3 3 1 3 1 3 0 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 1 0 1 1 0 3 2 2 2 1 3 2 2 3 1 2 0 0 0 1 3 3 2 2 3 0 2 1 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 2 1 1 2 3 2 1 1 3 1 1 1 2 0 3 2 1 3 0 0 3 3 2 2 1 1 0 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 3 2 3 0 3 1 0 0 2 2 0 3 0 2 1 3 2 3 1 0 0 2 0 3 0 1 0 3 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 2 2 2 1 1 2 0 1 2 1 1 2 3 0 1 2 2 2 3 1 2 0 2 2 2 3 2 3 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 1 1 2 1 3 0 2 3 1 0 0 3 2 2 1 3 2 3 0 2 3 1 3 2 1 1 1 1 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 3 2 2 1 1 2 1 0 0 2 3 3 0 2 1 0 1 1 0 3 2 2 1 3 1 2 1 0 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 0 0 3 3 2 3 1 3 2 3 2 1 1 2 2 0 1 3 0 3 2 0 0 0 1 3 0 2 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 2 0 2 1 1 0 3 1 0 1 3 3 2 2 2 2 2 1 2 1 2 3 1 3 1 1 1 0 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 2 0 2 1 1 3 0 1 1 0 1 2 2 3 3 3 2 1 2 1 1 1 0 0 2 3 0 0 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 0 0 1 1 2 3 0 1 1 0 1 2 2 1 3 3 1 3 2 1 2 3 0 3 3 0 0 0 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 3 1 1 3 2 0 1 2 2 3 0 3 2 3 0 3 2 1 1 1 0 3 1 3 2 2 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 0 0 2 2 2 3 1 0 0 1 1 0 1 1 0 3 3 3 1 3 1 0 1 0 3 2 0 1 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 1 1 0 2 1 2 2 3 2 0 2 1 1 0 3 3 0 1 0 2 3 1 3 1 0 0 2 3 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 1 3 3 0 1 3 3 0 0 2 0 3 3 0 0 3 1 2 1 1 1 2 0 0 1 1 3 0 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 0 0 1 2 3 0 1 1 2 0 0 3 2 1 0 2 2 0 2 3 1 0 1 3 0 3 0 1 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 1 1 2 3 0 3 3 3 0 0 1 3 3 3 0 2 3 2 1 2 1 3 3 2 1 0 1 0 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 0 2 3 3 0 1 2 3 1 2 3 2 1 2 3 1 2 2 1 2 0 2 3 1 1 2 1 1 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 1 1 1 2 3 1 2 0 0 0 0 1 1 0 1 1 1 1 3 1 2 1 3 0 1 3 3 1 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 3 3 0 0 1 0 2 0 0 3 2 2 0 2 2 2 2 1 1 3 1 3 3 1 2 2 3 3 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 3 3 2 3 2 0 3 3 0 0 1 1 0 2 3 0 1 0 1 2 3 3 1 2 2 0 3 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 3 3 3 0 1 2 1 2 1 3 3 2 2 0 0 0 3 3 2 1 2 3 2 1 1 3 1 2 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 1 2 0 3 3 3 0 3 3 3 0 1 1 1 3 3 1 2 2 2 0 0 1 0 3 3 1 0 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 1 3 2 1 1 1 2 3 0 2 2 3 1 0 0 2 3 3 1 2 2 1 3 3 1 0 3 2 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 0 0 3 1 1 1 2 2 1 3 1 3 3 3 1 2 2 0 0 2 2 2 2 3 3 2 3 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 2 2 2 3 2 3 0 0 1 3 3 2 2 3 0 1 1 2 1 1 3 2 0 1 0 2 2 2 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 0 3 0 0 2 3 0 0 0 3 0 2 0 0 1 3 3 1 3 1 1 0 0 1 2 1 1 2 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 3 2 1 1 1 0 1 3 0 0 3 2 2 1 0 3 0 3 0 3 2 2 0 2 1 0 1 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 3 1 0 1 1 0 3 2 2 2 1 1 0 0 2 0 2 1 0 2 2 3 2 0 3 0 2 0 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 2 2 2 2 2 1 3 0 3 1 1 0 0 3 3 0 2 1 1 0 2 0 3 3 0 2 2 0 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 1 1 2 2 2 1 0 1 0 0 3 1 3 0 3 1 2 2 0 0 3 3 0 1 0 1 0 2 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 2 3 2 0 2 2 2 1 0 0 0 1 3 1 3 3 1 3 0 0 3 0 3 1 2 2 1 1 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 2 0 3 2 1 3 0 1 0 2 2 3 3 0 1 1 2 3 2 3 1 0 0 3 0 0 0 0 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 1 2 0 0 2 3 3 3 2 0 2 1 1 3 0 0 2 3 2 0 2 1 0 3 0 2 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 1 1 2 2 2 2 0 2 1 1 3 1 1 1 0 2 3 0 0 1 0 0 2 2 1 2 3 1 0 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 0 2 3 3 3 3 3 2 1 2 3 3 1 0 0 3 0 1 1 3 2 3 0 1 2 1 1 3 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 2 0 3 1 1 1 3 1 3 2 0 0 3 1 0 3 0 3 0 0 2 0 2 1 1 2 0 0 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 3 3 0 1 3 3 1 1 3 2 1 1 3 1 2 1 3 0 2 1 0 3 1 0 3 0 0 2 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 0 2 3 1 2 3 0 0 2 1 0 0 0 1 2 3 2 3 2 2 2 0 0 2 3 3 2 2 1 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 2 3 3 2 0 3 0 0 3 0 3 3 1 3 2 2 2 3 0 1 2 3 2 2 0 0 3 3 3 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 1 2 2 1 2 2 0 1 2 2 2 1 3 0 3 0 2 1 3 2 2 1 2 2 3 2 0 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 0 1 1 0 1 2 3 0 2 0 2 2 3 1 0 3 2 2 3 0 1 2 1 0 2 1 2 0 0 3 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 3 3 0 1 0 3 0 0 0 0 0 0 0 0 2 0 1 0 0 2 2 2 1 1 0 1 0 0 1 0 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 2 1 1 0 0 1 0 2 2 3 1 3 0 3 3 1 3 1 0 1 0 3 1 0 2 1 0 2 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 3 2 1 0 1 3 0 0 0 1 0 1 3 1 3 2 3 2 3 2 2 1 3 2 2 3 1 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 3 0 2 2 3 0 0 0 1 3 1 3 3 2 3 1 3 2 3 2 2 0 2 2 1 3 2 2 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 3 3 1 0 1 0 1 2 1 1 2 0 0 1 0 2 1 1 1 2 2 1 0 3 1 3 2 3 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 3 1 2 2 0 2 2 1 3 2 2 0 2 2 0 3 1 2 1 0 2 3 1 2 0 1 0 0 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 1 3 2 0 1 3 0 3 0 1 3 1 0 0 1 0 1 1 2 2 2 2 2 0 2 2 1 2 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 1 0 3 1 3 0 0 3 1 3 2 2 1 1 1 3 2 0 2 2 0 3 0 0 3 3 2 3 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 2 0 3 2 2 1 2 1 2 1 0 1 2 1 3 3 1 0 3 1 0 1 2 0 1 3 1 2 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 0 2 3 3 3 1 2 2 0 1 1 1 2 0 0 0 1 1 1 0 3 3 2 2 0 0 1 1 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 1 0 0 2 1 3 0 1 3 2 2 2 0 1 0 2 3 0 2 1 1 2 3 0 1 2 2 3 2 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 0 2 0 3 3 2 2 2 1 2 3 2 3 0 2 3 1 0 3 3 2 3 0 3 0 3 0 3 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 1 0 3 3 3 1 0 1 0 1 0 1 3 2 1 2 0 2 1 2 3 1 2 2 0 0 2 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 0 3 0 3 1 0 3 2 0 1 1 2 0 3 3 1 3 0 2 0 2 0 1 3 2 0 3 0 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 0 3 3 3 1 1 0 2 3 1 2 0 1 0 3 1 2 3 0 3 3 0 3 0 2 0 1 1 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([2 1 0 1 3 1 0 3 3 2 3 3 3 3 2 1 0 1 2 1 1 0 0 1 0 2 1 1 2 1 3 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 0 2 1 2 2 2 3 1 0 0 3 2 1 2 3 1 1 1 1 3 3 1 3 1 0 0 3 2 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 1 3 3 3 1 1 2 0 1 2 2 1 1 1 3 0 3 3 3 0 3 1 1 1 3 0 1 2 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 0 2 3 0 2 3 3 2 0 1 0 0 0 3 0 0 1 0 3 3 1 3 0 3 2 1 1 3 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 0 0 0 1 0 1 3 2 3 0 3 2 3 0 1 0 1 1 3 2 1 3 0 0 2 0 1 1 1 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 2 0 0 0 2 3 1 2 1 3 0 3 3 1 1 3 1 1 3 0 1 1 3 0 2 0 0 2 2 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 1 2 0 1 3 1 1 1 3 1 1 1 2 0 1 0 3 0 2 0 0 0 0 3 1 3 1 0 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 3 3 1 1 1 0 2 1 0 0 1 3 1 2 3 0 2 2 3 2 3 2 1 3 3 1 2 2 2 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 1 0 1 0 2 0 3 2 0 3 1 3 0 0 3 2 1 2 0 1 3 3 0 2 2 1 1 0 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 0 3 0 2 1 2 0 2 1 3 1 0 1 2 0 3 1 2 3 3 3 1 0 3 3 3 3 0 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 3 3 1 0 3 0 2 0 2 1 2 0 3 1 2 2 2 1 0 1 3 3 3 3 2 3 0 1 2 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 0 2 0 1 3 2 2 0 2 0 1 2 2 2 3 1 1 3 2 0 2 0 3 1 3 1 0 1 1 2], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 0 1 2 2 3 2 3 1 2 0 3 2 2 0 1 2 0 0 0 2 3 3 3 3 1 0 0 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 2 2 1 0 1 0 1 3 1 0 1 0 1 1 0 2 1 2 1 1 3 2 0 0 1 3 3 0 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 0 3 3 0 2 2 0 1 3 2 0 0 3 1 0 3 3 2 3 1 0 3 2 3 1 3 0 3 2 0 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 2 3 3 1 1 0 3 2 3 0 3 0 2 1 2 3 0 3 2 3 2 1 1 1 1 3 2 2 0 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 0 2 0 3 3 0 1 1 2 1 3 0 2 1 1 2 0 2 2 3 3 0 1 1 2 0 3 2 3 0 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 1 0 0 3 0 2 3 1 2 3 3 0 0 2 3 3 3 0 0 1 2 0 3 1 2 2 1 1 0 2 1], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 1 3 1 1 0 3 2 3 1 1 0 2 2 3 2 3 1 2 2 0 3 1 0 3 1 0 1 2 2 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 1 2 2 2 1 3 2 3 2 0 1 0 3 3 2 0 0 2 0 2 0 3 2 0 0 1 0 3 2 3 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 1 1 0 2 2 3 2 2 3 3 0 0 1 2 3 2 0 3 3 2 1 1 0 2 1 0 1 2 3 0], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 0 2 3 0 3 0 2 2 1 1 2 0 0 2 2 2 1 3 0 0 1 1 0 2 2 1 3 3 1 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([0 3 1 0 1 0 0 2 0 2 1 3 0 0 0 0 2 3 0 0 2 0 0 1 1 0 0 3 1 2 2 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([1 2 3 1 0 1 2 1 2 3 2 1 2 0 0 1 1 0 2 2 0 2 3 2 3 1 1 3 1 2 1 3], shape=(32,), dtype=int32)\n",
            "tf.Tensor([3 3 2 3 3 2 3 3 3 1 1 3 0 2 2 2 2 0 1 2 3 3 3 0 1 3 1 2 1 3 3 0], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFknSi_VOfab"
      },
      "source": [
        "## Building a neural network multiclass classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRYKhiR6YU4-"
      },
      "source": [
        "# Defining an evaluation metric function\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred, average='macro')\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred, average='macro')\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred , average='macro')\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXgAJWxAOmPU",
        "outputId": "a63cb795-4bd3-4a58-d32a-dfcea501f4af"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropout =  0.1\n",
        "activation = 'relu'\n",
        "\n",
        "print (\"======== activation function = {}, dropout = {}, batch size = {} ============\".format(activation, dropout, batch_size ))\n",
        "model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim, name=\"embedding_2\"),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.GlobalAveragePooling1D(),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.Dense(32, activation= activation),\n",
        "                            layers.Dense(4)])\n",
        "print(model.summary())\n",
        "\n",
        "# configure the model uisng optimizer and loss function\n",
        "model.compile(loss = losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              optimizer = 'adam',\n",
        "              metrics = 'accuracy') \n",
        "# training the model\n",
        "epochs = 10\n",
        "history = model.fit(train,\n",
        "                    validation_data = val,\n",
        "                    epochs = epochs)\n",
        "# testing the model\n",
        "pred_label = tf.argmax(model.predict(test),1)\n",
        "true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "loss, accuracy = model.evaluate(test)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== activation function = relu, dropout = 0.1, batch size = 32 ============\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_13  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 4)                 132       \n",
            "=================================================================\n",
            "Total params: 160,692\n",
            "Trainable params: 160,692\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "200/200 [==============================] - 4s 17ms/step - loss: 1.3717 - accuracy: 0.3273 - val_loss: 1.3310 - val_accuracy: 0.5288\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 2s 9ms/step - loss: 1.2187 - accuracy: 0.5236 - val_loss: 1.0695 - val_accuracy: 0.6150\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.9700 - accuracy: 0.6323 - val_loss: 0.8677 - val_accuracy: 0.6787\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.7908 - accuracy: 0.6948 - val_loss: 0.7415 - val_accuracy: 0.7181\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.6723 - accuracy: 0.7427 - val_loss: 0.6625 - val_accuracy: 0.7406\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.5793 - accuracy: 0.7828 - val_loss: 0.6073 - val_accuracy: 0.7625\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.5124 - accuracy: 0.8105 - val_loss: 0.5726 - val_accuracy: 0.7713\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.4504 - accuracy: 0.8386 - val_loss: 0.5495 - val_accuracy: 0.7806\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.4002 - accuracy: 0.8631 - val_loss: 0.5340 - val_accuracy: 0.7925\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 1s 6ms/step - loss: 0.3527 - accuracy: 0.8831 - val_loss: 0.5268 - val_accuracy: 0.7975\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.7741\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.589 - Accuracy: 0.774\n",
            "accuracy score: 0.774\n",
            "precision score: 0.776\n",
            "recall score: 0.774\n",
            "F1 score: 0.773\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.73      0.72      2000\n",
            "           1       0.80      0.67      0.73      2000\n",
            "           2       0.83      0.82      0.83      2000\n",
            "           3       0.77      0.87      0.82      2000\n",
            "\n",
            "    accuracy                           0.77      8000\n",
            "   macro avg       0.78      0.77      0.77      8000\n",
            "weighted avg       0.78      0.77      0.77      8000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.774125, 0.7759676555740118, 0.7741250000000001, 0.7728803667560876)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}