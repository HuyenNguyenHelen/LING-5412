{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Feedforward-Network.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNcEYSy9veSWvE/SPpDA8/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment_Feedforward_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybsamp8T__sG",
        "outputId": "103564c0-8aa8-440b-9405-7ef8af56e69c"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import string\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "import pandas as pd\n",
        "import glob\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEecDn_cAPUR"
      },
      "source": [
        "# Part 1: IMDB sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I37czSdvAJGh"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTrU1EcAaJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc5815d3-236a-4748-ab86-265d7e78a307"
      },
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "data = tf.keras.utils.get_file ('aclImdb_v1',\n",
        "                                url,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "data_dir = os.path.join (os.path.dirname(data), 'aclImdb')\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imdb.vocab', 'test', 'README', 'imdbEr.txt', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl4s0XGxECq4",
        "outputId": "096e957a-8678-4daa-f2c7-95a8338b2fa6"
      },
      "source": [
        "train_dir = os.path.join (data_dir, 'train')\n",
        "test_dir = os.path.join (data_dir, 'test')\n",
        "print(os.listdir(train_dir))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'urls_neg.txt', 'urls_pos.txt', 'unsup', 'pos', 'urls_unsup.txt', 'unsupBow.feat', 'labeledBow.feat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqLbtPKfNc5Z"
      },
      "source": [
        "# We only use files in the two folders: pos, and neg, so let's remove other files\n",
        "remove_dir = os.path.join(train_dir, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5fHSce2Rk-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10f6aaf3-6ea9-46f2-dcdc-6e9330abff73"
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('aclImdb/test',\n",
        "                                                       batch_size = batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuL_ipXkaAyv"
      },
      "source": [
        "## Text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KVgg_ZWaFtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b3738f-8f59-45a5-8fea-48d5d6156c00"
      },
      "source": [
        "def custom_preprocessing (text):\n",
        "  lowercase = tf.strings.lower (text)\n",
        "  stripped_html = tf.strings.regex_replace (lowercase,'<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), \n",
        "                                  '')\n",
        "  \n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(standardize = custom_preprocessing,\n",
        "                                           max_tokens = max_features,\n",
        "                                           output_mode = 'int',\n",
        "                                           output_sequence_length = sequence_length)\n",
        "# Extracting features for vectorizing using training set\n",
        "train_text = raw_train.map (lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "# Defining a function for fitting vectorizer function/layer to vectorize text (review)\n",
        "def fitting_vectorizer (text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer (text), label\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(raw_train))\n",
        "\n",
        "## print an instance with vectorized review and label for observing\n",
        "print ('REVIEW:', text_batch[0])\n",
        "print('LABEL:', raw_train.class_names[label_batch[0]] )\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REVIEW: tf.Tensor(b'Silent Night, Deadly Night 5 is the very last of the series, and like part 4, it\\'s unrelated to the first three except by title and the fact that it\\'s a Christmas-themed horror flick.<br /><br />Except to the oblivious, there\\'s some obvious things going on here...Mickey Rooney plays a toymaker named Joe Petto and his creepy son\\'s name is Pino. Ring a bell, anyone? Now, a little boy named Derek heard a knock at the door one evening, and opened it to find a present on the doorstep for him. Even though it said \"don\\'t open till Christmas\", he begins to open it anyway but is stopped by his dad, who scolds him and sends him to bed, and opens the gift himself. Inside is a little red ball that sprouts Santa arms and a head, and proceeds to kill dad. Oops, maybe he should have left well-enough alone. Of course Derek is then traumatized by the incident since he watched it from the stairs, but he doesn\\'t grow up to be some killer Santa, he just stops talking.<br /><br />There\\'s a mysterious stranger lurking around, who seems very interested in the toys that Joe Petto makes. We even see him buying a bunch when Derek\\'s mom takes him to the store to find a gift for him to bring him out of his trauma. And what exactly is this guy doing? Well, we\\'re not sure but he does seem to be taking these toys apart to see what makes them tick. He does keep his landlord from evicting him by promising him to pay him in cash the next day and presents him with a \"Larry the Larvae\" toy for his kid, but of course \"Larry\" is not a good toy and gets out of the box in the car and of course, well, things aren\\'t pretty.<br /><br />Anyway, eventually what\\'s going on with Joe Petto and Pino is of course revealed, and as with the old story, Pino is not a \"real boy\". Pino is probably even more agitated and naughty because he suffers from \"Kenitalia\" (a smooth plastic crotch) so that could account for his evil ways. And the identity of the lurking stranger is revealed too, and there\\'s even kind of a happy ending of sorts. Whee.<br /><br />A step up from part 4, but not much of one. Again, Brian Yuzna is involved, and Screaming Mad George, so some decent special effects, but not enough to make this great. A few leftovers from part 4 are hanging around too, like Clint Howard and Neith Hunter, but that doesn\\'t really make any difference. Anyway, I now have seeing the whole series out of my system. Now if I could get some of it out of my brain. 4 out of 5.', shape=(), dtype=string)\n",
            "LABEL: neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdhUEflLG1-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083c2f11-d11c-4842-c9da-3e2c929bbe58"
      },
      "source": [
        "# print an example of vectorized data\n",
        "print ('Vocabulary size: ', len(vectorize_layer.get_vocabulary()))\n",
        "for i in range (90, 100):\n",
        "  print ('{} ------> {}'.format(i, vectorize_layer.get_vocabulary()[i]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size:  10000\n",
            "90 ------> made\n",
            "91 ------> movies\n",
            "92 ------> then\n",
            "93 ------> them\n",
            "94 ------> films\n",
            "95 ------> way\n",
            "96 ------> make\n",
            "97 ------> any\n",
            "98 ------> could\n",
            "99 ------> too\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49aXKTf-LYpE"
      },
      "source": [
        "train = raw_train.map(fitting_vectorizer)\n",
        "val = raw_val.map(fitting_vectorizer)\n",
        "test = raw_test.map(fitting_vectorizer)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqxSoCqORfY"
      },
      "source": [
        "# Configure the dataset for performance\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train = train.cache().prefetch (buffer_size = autotune)\n",
        "val = val.cache().prefetch (buffer_size = autotune)\n",
        "test = test.cache().prefetch (buffer_size = autotune)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoADSjBJMHL7"
      },
      "source": [
        "## Building a neural network classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS4xOvZ_ZqLC"
      },
      "source": [
        "# Defining an evaluation metric function\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred, average='binary')\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred, average='binary')\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred , average='binary')\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaffgzJaRMKe"
      },
      "source": [
        "### With different numbers of embedding dimentions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnp8gN87MPaF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401f023f-7a5b-4901-ec73-6c6eeb14b887"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = [16, 28, 50, 100]\n",
        "for n in embedding_dim:\n",
        "  print (\"========= embedding vectors'size= %s ============\" %n)\n",
        "  model = tf.keras.Sequential([layers.Embedding(max_features + 1, n, name=\"embedding\"),\n",
        "                              layers.Dropout(0.2),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              layers.Dropout(0.2),\n",
        "                              layers.Dense(1, activation = 'sigmoid')])\n",
        "  print(model.summary())\n",
        "\n",
        "  # configure the model uisng optimizer and loss function\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = 'adam',\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  # pred_label = tf.argmax(model.predict(test),1)\n",
        "  pred_label = (model.predict(test) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= embedding vectors'size= 16 ============\n",
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_44 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_22  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6627 - binary_accuracy: 0.6938 - val_loss: 0.6110 - val_binary_accuracy: 0.7770\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5441 - binary_accuracy: 0.8040 - val_loss: 0.4939 - val_binary_accuracy: 0.8230\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4408 - binary_accuracy: 0.8456 - val_loss: 0.4172 - val_binary_accuracy: 0.8472\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3751 - binary_accuracy: 0.8654 - val_loss: 0.3720 - val_binary_accuracy: 0.8614\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3341 - binary_accuracy: 0.8795 - val_loss: 0.3439 - val_binary_accuracy: 0.8682\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3035 - binary_accuracy: 0.8887 - val_loss: 0.3252 - val_binary_accuracy: 0.8720\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2801 - binary_accuracy: 0.8972 - val_loss: 0.3118 - val_binary_accuracy: 0.8752\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2603 - binary_accuracy: 0.9051 - val_loss: 0.3023 - val_binary_accuracy: 0.8768\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2439 - binary_accuracy: 0.9118 - val_loss: 0.2959 - val_binary_accuracy: 0.8776\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2298 - binary_accuracy: 0.9173 - val_loss: 0.2915 - val_binary_accuracy: 0.8796\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3097 - binary_accuracy: 0.8734\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.310 - Accuracy: 0.873\n",
            "accuracy score: 0.864\n",
            "precision score: 0.868\n",
            "recall score: 0.864\n",
            "F1 score: 0.864\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87     12500\n",
            "           1       0.90      0.82      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.87      0.86      0.86     25000\n",
            "weighted avg       0.87      0.86      0.86     25000\n",
            "\n",
            "========= embedding vectors'size= 28 ============\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 28)          280028    \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, None, 28)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_23  (None, 28)                0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 28)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 29        \n",
            "=================================================================\n",
            "Total params: 280,057\n",
            "Trainable params: 280,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.6476 - binary_accuracy: 0.7031 - val_loss: 0.5748 - val_binary_accuracy: 0.7848\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.4945 - binary_accuracy: 0.8237 - val_loss: 0.4417 - val_binary_accuracy: 0.8384\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3884 - binary_accuracy: 0.8613 - val_loss: 0.3740 - val_binary_accuracy: 0.8582\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.3301 - binary_accuracy: 0.8793 - val_loss: 0.3381 - val_binary_accuracy: 0.8700\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2938 - binary_accuracy: 0.8920 - val_loss: 0.3172 - val_binary_accuracy: 0.8720\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2661 - binary_accuracy: 0.9022 - val_loss: 0.3041 - val_binary_accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2451 - binary_accuracy: 0.9115 - val_loss: 0.2958 - val_binary_accuracy: 0.8776\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2282 - binary_accuracy: 0.9178 - val_loss: 0.2906 - val_binary_accuracy: 0.8794\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2110 - binary_accuracy: 0.9243 - val_loss: 0.2875 - val_binary_accuracy: 0.8820\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.1977 - binary_accuracy: 0.9295 - val_loss: 0.2862 - val_binary_accuracy: 0.8818\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3077 - binary_accuracy: 0.8740\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.308 - Accuracy: 0.874\n",
            "accuracy score: 0.867\n",
            "precision score: 0.870\n",
            "recall score: 0.867\n",
            "F1 score: 0.866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87     12500\n",
            "           1       0.90      0.82      0.86     12500\n",
            "\n",
            "    accuracy                           0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n",
            "========= embedding vectors'size= 50 ============\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 50)          500050    \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, None, 50)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_24  (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 500,101\n",
            "Trainable params: 500,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 9s 14ms/step - loss: 0.6292 - binary_accuracy: 0.7159 - val_loss: 0.5337 - val_binary_accuracy: 0.8014\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.4461 - binary_accuracy: 0.8403 - val_loss: 0.3969 - val_binary_accuracy: 0.8524\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.3449 - binary_accuracy: 0.8734 - val_loss: 0.3416 - val_binary_accuracy: 0.8678\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2938 - binary_accuracy: 0.8906 - val_loss: 0.3147 - val_binary_accuracy: 0.8726\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.2602 - binary_accuracy: 0.9039 - val_loss: 0.3001 - val_binary_accuracy: 0.8764\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.2353 - binary_accuracy: 0.9135 - val_loss: 0.2919 - val_binary_accuracy: 0.8788\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.2141 - binary_accuracy: 0.9219 - val_loss: 0.2876 - val_binary_accuracy: 0.8808\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1971 - binary_accuracy: 0.9286 - val_loss: 0.2863 - val_binary_accuracy: 0.8818\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1823 - binary_accuracy: 0.9350 - val_loss: 0.2873 - val_binary_accuracy: 0.8820\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 8s 13ms/step - loss: 0.1682 - binary_accuracy: 0.9420 - val_loss: 0.2899 - val_binary_accuracy: 0.8836\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3165 - binary_accuracy: 0.8718\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.316 - Accuracy: 0.872\n",
            "accuracy score: 0.867\n",
            "precision score: 0.869\n",
            "recall score: 0.867\n",
            "F1 score: 0.867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87     12500\n",
            "           1       0.90      0.83      0.86     12500\n",
            "\n",
            "    accuracy                           0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n",
            "========= embedding vectors'size= 100 ============\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 100)         1000100   \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, None, 100)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_25  (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 1,000,201\n",
            "Trainable params: 1,000,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.6002 - binary_accuracy: 0.7287 - val_loss: 0.4755 - val_binary_accuracy: 0.8230\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.3893 - binary_accuracy: 0.8564 - val_loss: 0.3544 - val_binary_accuracy: 0.8628\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.3025 - binary_accuracy: 0.8852 - val_loss: 0.3146 - val_binary_accuracy: 0.8740\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.2580 - binary_accuracy: 0.9046 - val_loss: 0.2971 - val_binary_accuracy: 0.8778\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.2271 - binary_accuracy: 0.9170 - val_loss: 0.2891 - val_binary_accuracy: 0.8812\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.2043 - binary_accuracy: 0.9258 - val_loss: 0.2867 - val_binary_accuracy: 0.8808\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 15s 23ms/step - loss: 0.1838 - binary_accuracy: 0.9341 - val_loss: 0.2876 - val_binary_accuracy: 0.8820\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 15s 24ms/step - loss: 0.1670 - binary_accuracy: 0.9418 - val_loss: 0.2917 - val_binary_accuracy: 0.8814\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.1520 - binary_accuracy: 0.9488 - val_loss: 0.2980 - val_binary_accuracy: 0.8794\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 14s 23ms/step - loss: 0.1387 - binary_accuracy: 0.9546 - val_loss: 0.3055 - val_binary_accuracy: 0.8792\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3417 - binary_accuracy: 0.8653\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.342 - Accuracy: 0.865\n",
            "accuracy score: 0.863\n",
            "precision score: 0.865\n",
            "recall score: 0.863\n",
            "F1 score: 0.863\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87     12500\n",
            "           1       0.89      0.83      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.86      0.86      0.86     25000\n",
            "weighted avg       0.86      0.86      0.86     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvJLzGQbZZD8"
      },
      "source": [
        "### With different dropout "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn5GRRbvaB3k",
        "outputId": "4e3ffdc5-50c6-4a01-e869-5419f72f99df"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropouts = [0.0, 0.1, 0.2, 0.3]\n",
        "for i in dropouts:\n",
        "  print (\"========= dropout = %s ============\" %i)\n",
        "  model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim,  name=\"embedding\"),\n",
        "                              layers.Dropout(i),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              layers.Dropout(0.2),\n",
        "                              layers.Dense(1)])\n",
        "  print(model.summary())\n",
        "\n",
        "  # configure the model uisng optimizer and loss function\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = 'adam',\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = (model.predict(test) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= dropout = 0.0 ============\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.6606 - binary_accuracy: 0.6994 - val_loss: 0.6075 - val_binary_accuracy: 0.7772\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.5389 - binary_accuracy: 0.8061 - val_loss: 0.4879 - val_binary_accuracy: 0.8238\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.4336 - binary_accuracy: 0.8493 - val_loss: 0.4108 - val_binary_accuracy: 0.8502\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3679 - binary_accuracy: 0.8690 - val_loss: 0.3661 - val_binary_accuracy: 0.8624\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3254 - binary_accuracy: 0.8819 - val_loss: 0.3387 - val_binary_accuracy: 0.8702\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2956 - binary_accuracy: 0.8913 - val_loss: 0.3208 - val_binary_accuracy: 0.8728\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2719 - binary_accuracy: 0.9000 - val_loss: 0.3082 - val_binary_accuracy: 0.8744\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2526 - binary_accuracy: 0.9082 - val_loss: 0.2997 - val_binary_accuracy: 0.8774\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2364 - binary_accuracy: 0.9142 - val_loss: 0.2939 - val_binary_accuracy: 0.8780\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2223 - binary_accuracy: 0.9200 - val_loss: 0.2900 - val_binary_accuracy: 0.8802\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3083 - binary_accuracy: 0.8740\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.308 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= dropout = 0.1 ============\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_5 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6639 - binary_accuracy: 0.6878 - val_loss: 0.6132 - val_binary_accuracy: 0.7734\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5456 - binary_accuracy: 0.8023 - val_loss: 0.4946 - val_binary_accuracy: 0.8230\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4403 - binary_accuracy: 0.8468 - val_loss: 0.4160 - val_binary_accuracy: 0.8490\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3741 - binary_accuracy: 0.8680 - val_loss: 0.3704 - val_binary_accuracy: 0.8618\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3312 - binary_accuracy: 0.8806 - val_loss: 0.3419 - val_binary_accuracy: 0.8682\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3010 - binary_accuracy: 0.8893 - val_loss: 0.3234 - val_binary_accuracy: 0.8726\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2773 - binary_accuracy: 0.8988 - val_loss: 0.3103 - val_binary_accuracy: 0.8742\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2582 - binary_accuracy: 0.9075 - val_loss: 0.3013 - val_binary_accuracy: 0.8758\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2421 - binary_accuracy: 0.9117 - val_loss: 0.2951 - val_binary_accuracy: 0.8770\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2268 - binary_accuracy: 0.9173 - val_loss: 0.2905 - val_binary_accuracy: 0.8792\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3093 - binary_accuracy: 0.8738\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.309 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= dropout = 0.2 ============\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_6 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6638 - binary_accuracy: 0.6906 - val_loss: 0.6147 - val_binary_accuracy: 0.7744\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5492 - binary_accuracy: 0.8001 - val_loss: 0.4984 - val_binary_accuracy: 0.8220\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4451 - binary_accuracy: 0.8436 - val_loss: 0.4202 - val_binary_accuracy: 0.8472\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3787 - binary_accuracy: 0.8655 - val_loss: 0.3737 - val_binary_accuracy: 0.8608\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3360 - binary_accuracy: 0.8785 - val_loss: 0.3450 - val_binary_accuracy: 0.8684\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3050 - binary_accuracy: 0.8879 - val_loss: 0.3259 - val_binary_accuracy: 0.8726\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2818 - binary_accuracy: 0.8968 - val_loss: 0.3126 - val_binary_accuracy: 0.8736\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2622 - binary_accuracy: 0.9045 - val_loss: 0.3030 - val_binary_accuracy: 0.8762\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2453 - binary_accuracy: 0.9106 - val_loss: 0.2963 - val_binary_accuracy: 0.8774\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2313 - binary_accuracy: 0.9157 - val_loss: 0.2917 - val_binary_accuracy: 0.8792\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3103 - binary_accuracy: 0.8736\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.310 - Accuracy: 0.874\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= dropout = 0.3 ============\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6636 - binary_accuracy: 0.6878 - val_loss: 0.6150 - val_binary_accuracy: 0.7736\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5504 - binary_accuracy: 0.8008 - val_loss: 0.5011 - val_binary_accuracy: 0.8210\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4481 - binary_accuracy: 0.8436 - val_loss: 0.4234 - val_binary_accuracy: 0.8472\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3827 - binary_accuracy: 0.8631 - val_loss: 0.3768 - val_binary_accuracy: 0.8598\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3401 - binary_accuracy: 0.8776 - val_loss: 0.3478 - val_binary_accuracy: 0.8672\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3095 - binary_accuracy: 0.8861 - val_loss: 0.3288 - val_binary_accuracy: 0.8710\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2857 - binary_accuracy: 0.8956 - val_loss: 0.3148 - val_binary_accuracy: 0.8728\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2663 - binary_accuracy: 0.9042 - val_loss: 0.3052 - val_binary_accuracy: 0.8760\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2489 - binary_accuracy: 0.9089 - val_loss: 0.2978 - val_binary_accuracy: 0.8776\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2359 - binary_accuracy: 0.9147 - val_loss: 0.2929 - val_binary_accuracy: 0.8774\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3111 - binary_accuracy: 0.8733\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.311 - Accuracy: 0.873\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te4tKnBY8mXP"
      },
      "source": [
        "### Adding a Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la1m7MZW9Ah5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b618f36-2d4c-41a1-c694-c7f7b084a21c"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropout =  0.1\n",
        "activations = ['relu', 'softmax', 'sigmoid']\n",
        "for f in activations:\n",
        "  print (\"========= activation function = %s ============\" %f)\n",
        "  model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim,  name=\"embedding\"),\n",
        "                              layers.Dropout(dropout),\n",
        "                              layers.GlobalAveragePooling1D(),\n",
        "                              layers.Dropout(dropout),\n",
        "                              layers.Dense(32, activation= f),\n",
        "                              layers.Dense(1)])\n",
        "  print(model.summary())\n",
        "\n",
        "  # configure the model uisng optimizer and loss function\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = 'adam',\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = (model.predict(test) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========= activation function = relu ============\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_8 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.5426 - binary_accuracy: 0.7498 - val_loss: 0.3545 - val_binary_accuracy: 0.8562\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2927 - binary_accuracy: 0.8831 - val_loss: 0.3000 - val_binary_accuracy: 0.8748\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2263 - binary_accuracy: 0.9151 - val_loss: 0.2975 - val_binary_accuracy: 0.8754\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1872 - binary_accuracy: 0.9295 - val_loss: 0.3095 - val_binary_accuracy: 0.8752\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1572 - binary_accuracy: 0.9452 - val_loss: 0.3290 - val_binary_accuracy: 0.8706\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1318 - binary_accuracy: 0.9562 - val_loss: 0.3554 - val_binary_accuracy: 0.8686\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1125 - binary_accuracy: 0.9632 - val_loss: 0.3800 - val_binary_accuracy: 0.8684\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.0955 - binary_accuracy: 0.9705 - val_loss: 0.4124 - val_binary_accuracy: 0.8650\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0801 - binary_accuracy: 0.9772 - val_loss: 0.4395 - val_binary_accuracy: 0.8680\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.0671 - binary_accuracy: 0.9814 - val_loss: 0.4788 - val_binary_accuracy: 0.8658\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.5690 - binary_accuracy: 0.8409\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.569 - Accuracy: 0.841\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= activation function = softmax ============\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_9 ( (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 5s 6ms/step - loss: 0.6836 - binary_accuracy: 0.6064 - val_loss: 0.6531 - val_binary_accuracy: 0.7588\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.5693 - binary_accuracy: 0.8032 - val_loss: 0.4863 - val_binary_accuracy: 0.8358\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4112 - binary_accuracy: 0.8601 - val_loss: 0.3713 - val_binary_accuracy: 0.8646\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3184 - binary_accuracy: 0.8846 - val_loss: 0.3232 - val_binary_accuracy: 0.8726\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2690 - binary_accuracy: 0.9018 - val_loss: 0.3058 - val_binary_accuracy: 0.8746\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2377 - binary_accuracy: 0.9146 - val_loss: 0.2994 - val_binary_accuracy: 0.8764\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2141 - binary_accuracy: 0.9244 - val_loss: 0.2984 - val_binary_accuracy: 0.8786\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1973 - binary_accuracy: 0.9337 - val_loss: 0.2994 - val_binary_accuracy: 0.8796\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1789 - binary_accuracy: 0.9412 - val_loss: 0.3028 - val_binary_accuracy: 0.8796\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1654 - binary_accuracy: 0.9474 - val_loss: 0.3075 - val_binary_accuracy: 0.8814\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3301 - binary_accuracy: 0.8719\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.330 - Accuracy: 0.872\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n",
            "========= activation function = sigmoid ============\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_10  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.6430 - binary_accuracy: 0.6623 - val_loss: 0.5406 - val_binary_accuracy: 0.7862\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.4226 - binary_accuracy: 0.8392 - val_loss: 0.3592 - val_binary_accuracy: 0.8566\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3049 - binary_accuracy: 0.8799 - val_loss: 0.3125 - val_binary_accuracy: 0.8724\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2556 - binary_accuracy: 0.9010 - val_loss: 0.2966 - val_binary_accuracy: 0.8764\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2234 - binary_accuracy: 0.9158 - val_loss: 0.2910 - val_binary_accuracy: 0.8798\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.1984 - binary_accuracy: 0.9258 - val_loss: 0.2919 - val_binary_accuracy: 0.8806\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1777 - binary_accuracy: 0.9360 - val_loss: 0.2968 - val_binary_accuracy: 0.8812\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1595 - binary_accuracy: 0.9437 - val_loss: 0.3053 - val_binary_accuracy: 0.8818\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1438 - binary_accuracy: 0.9500 - val_loss: 0.3163 - val_binary_accuracy: 0.8798\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1299 - binary_accuracy: 0.9578 - val_loss: 0.3308 - val_binary_accuracy: 0.8808\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3699 - binary_accuracy: 0.8652\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.370 - Accuracy: 0.865\n",
            "accuracy score: 0.500\n",
            "precision score: 0.250\n",
            "recall score: 0.500\n",
            "F1 score: 0.333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67     12500\n",
            "           1       0.00      0.00      0.00     12500\n",
            "\n",
            "    accuracy                           0.50     25000\n",
            "   macro avg       0.25      0.50      0.33     25000\n",
            "weighted avg       0.25      0.50      0.33     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOBe7jHOHLQ_"
      },
      "source": [
        "### With different Batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dPOERiaH501",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1483ae5d-50f6-4017-8e4e-63f086ed2e1f"
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 64\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('aclImdb/test',\n",
        "                                                       batch_size = batch_size)\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(raw_train))\n",
        "\n",
        "## print an instance with vectorized review and label for observing\n",
        "print ('REVIEW:', text_batch[0])\n",
        "print('LABEL:', raw_train.class_names[label_batch[0]] )\n",
        "\n",
        "\n",
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropout =  0.1\n",
        "activation =  'softmax'\n",
        "\n",
        "print (\"======== activation function = {}, dropout = {}, batch size = {} ============\".format(activation, dropout, batch_size ))\n",
        "model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim, name=\"embedding\"),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.GlobalAveragePooling1D(),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.Dense(32, activation= activation),\n",
        "                            layers.Dense(1)])\n",
        "print(model.summary())\n",
        "\n",
        "# configure the model uisng optimizer and loss function\n",
        "model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "              optimizer = 'adam',\n",
        "              metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "# training the model\n",
        "epochs = 10\n",
        "history = model.fit(train,\n",
        "                    validation_data = val,\n",
        "                    epochs = epochs)\n",
        "# testing the model\n",
        "pred_label = (model.predict(test) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "loss, accuracy = model.evaluate(test)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "REVIEW: tf.Tensor(b\"First of all, I liked very much the central idea of locating the '' intruders'', Others in the fragile Self, on various levels - mainly subconscious but sometimes more allegorical. In fact the intruders are omnipresent throughout the film : in the Swiss-French border where the pretagonist leads secluded life; in the his recurring daydream and nightmare; inside his ailing body after heart transplantation.... In the last half of the film, he becomes intruder himself, returning in ancient french colony in the hope of atoning for the past. <br /><br />The overall tone is bitter rather than pathetic, full of regrets and guilts, sense of failure being more or less dominant. This is a quite grim picture of an old age, ostensibly self-dependent but hopelessly void and lonely inside. The directer composes the images more to convey passing sensations of anxiety and desire than any explicit meanings. Some of them are mesmerizing, not devoid of humor though, kind of absurdist play only somnambulist can visualize.\", shape=(), dtype=string)\n",
            "LABEL: pos\n",
            "======== activation function = softmax, dropout = 0.1, batch size = 64 ============\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160016    \n",
            "_________________________________________________________________\n",
            "dropout_54 (Dropout)         (None, None, 16)          0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_27  (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dropout_55 (Dropout)         (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 160,593\n",
            "Trainable params: 160,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.6854 - binary_accuracy: 0.5987 - val_loss: 0.6583 - val_binary_accuracy: 0.7522\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.5723 - binary_accuracy: 0.7990 - val_loss: 0.4835 - val_binary_accuracy: 0.8342\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.4073 - binary_accuracy: 0.8595 - val_loss: 0.3669 - val_binary_accuracy: 0.8622\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.3172 - binary_accuracy: 0.8848 - val_loss: 0.3238 - val_binary_accuracy: 0.8714\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.2707 - binary_accuracy: 0.9025 - val_loss: 0.3075 - val_binary_accuracy: 0.8754\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2388 - binary_accuracy: 0.9160 - val_loss: 0.3003 - val_binary_accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 4s 7ms/step - loss: 0.2168 - binary_accuracy: 0.9252 - val_loss: 0.2994 - val_binary_accuracy: 0.8792\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1982 - binary_accuracy: 0.9344 - val_loss: 0.3002 - val_binary_accuracy: 0.8800\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1818 - binary_accuracy: 0.9422 - val_loss: 0.3041 - val_binary_accuracy: 0.8790\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 4s 6ms/step - loss: 0.1673 - binary_accuracy: 0.9478 - val_loss: 0.3083 - val_binary_accuracy: 0.8804\n",
            "782/782 [==============================] - 1s 1ms/step - loss: 0.3304 - binary_accuracy: 0.8716\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.330 - Accuracy: 0.872\n",
            "accuracy score: 0.870\n",
            "precision score: 0.894\n",
            "recall score: 0.840\n",
            "F1 score: 0.866\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.90      0.87     12500\n",
            "           1       0.89      0.84      0.87     12500\n",
            "\n",
            "    accuracy                           0.87     25000\n",
            "   macro avg       0.87      0.87      0.87     25000\n",
            "weighted avg       0.87      0.87      0.87     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.87028, 0.8943511970690977, 0.83976, 0.8661963114246812)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7OsTdtjWfge"
      },
      "source": [
        "### With different training algorithm\n",
        "Here we mostly focus on adapting learning rate method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnIwxcEVW4CC"
      },
      "source": [
        "# configure the model uisng optimizer and loss function\n",
        "optimizers = ['adagrad', 'rmsprop', 'adam']\n",
        "\n",
        "print (\"======== activation function = {}, dropout = {}, batch size = {} ============\".format(activation, dropout, batch_size ))\n",
        "for opt in optimizers:\n",
        "  print( '========== optimizer = %s' %opt)\n",
        "  model.compile(loss = losses.BinaryCrossentropy(from_logits = True),\n",
        "                optimizer = opt,\n",
        "                metrics = tf.metrics.BinaryAccuracy(threshold = 0.0 )) ## Why threshold = 0.0??\n",
        "  # training the model\n",
        "  epochs = 10\n",
        "  history = model.fit(train,\n",
        "                      validation_data = val,\n",
        "                      epochs = epochs)\n",
        "  # testing the model\n",
        "  pred_label = (model.predict(test) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  loss, accuracy = model.evaluate(test)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln0waE00a6eE"
      },
      "source": [
        "## Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LsKSP4Sa-kC"
      },
      "source": [
        "weights = model.get_layer('embedding').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im8CyYCyWuOI"
      },
      "source": [
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def Find_similar_w (word, n):\n",
        "  all_cos_sim = {}\n",
        "  idx = vocab.index(word)\n",
        "  weight = weights[idx]\n",
        "  for i in range(len(weights)-1):\n",
        "    cosine_sim = cosine_similarity(weight.reshape(1, -1), weights[i].reshape(1, -1))\n",
        "    all_cos_sim[vocab[i]] = cosine_sim\n",
        "  # Sorting the dictionary in descending order\n",
        "  sorted_cos = {k:v for k, v in sorted(all_cos_sim.items(), key = lambda item: item[1], reverse=True)}\n",
        "  print (\"Top {} most similar with '{}' \\n\".format(n, word))\n",
        "  for k, v in list(sorted_cos.items())[:n]:\n",
        "    print ('{} =====> {}'. format(k,v))\n",
        "  return  sorted_cos\n",
        "most_similar_w = Find_similar_w (word = 'boring', n = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiijE5K_bARq"
      },
      "source": [
        "## Comparing with a Logistic Regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKdXFowRwer9"
      },
      "source": [
        "# loading the ds\n",
        "def Getdata(dir):\n",
        "  review, label = [], []\n",
        "  for folder in glob.glob (dir+'/*'):\n",
        "    for file in glob.glob(folder+'/*'): \n",
        "      fo = open(file)\n",
        "      doc = fo.read()\n",
        "      review.append (doc)\n",
        "      if 'pos' in file:\n",
        "        label.append(1)\n",
        "      elif 'neg' in file:\n",
        "        label.append(0)\n",
        "  df = pd.DataFrame(zip(review,label), columns = ['review', 'label'])\n",
        "  return df\n",
        "  \n",
        "train_df = Getdata(train_dir)\n",
        "test_df = Getdata(test_dir)\n",
        "# Spliting the dataset for training and testing\n",
        "X_train, X_val, y_train, y_val = train_test_split (train_df['review'],train_df['label'], train_size = 0.8, random_state = 42, shuffle = True)\n",
        "X_test, y_test = test_df['review'], test_df['label']\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_val, y_val: ', X_val.shape, y_val.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhfG0yG8meEX"
      },
      "source": [
        "\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred)\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred)\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred)\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hALCMWMSmLhv"
      },
      "source": [
        "### With Countvectorizer text presentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9BcQ-UebIcI"
      },
      "source": [
        "\n",
        "# Vectorizing the documents\n",
        "vectorizer = CountVectorizer(binary = True)\n",
        "X_train_count = vectorizer.fit_transform(X_train.to_list())\n",
        "X_val_count = vectorizer.transform(X_val.to_list())\n",
        "X_test_count = vectorizer.transform(X_test.to_list())\n",
        "print ('Shapes of X_train, y_train: ', X_train_count.shape, y_train.shape)\n",
        "print ('Shapes of X_val, y_val: ', X_val_count.shape, y_val.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test_count.shape, y_test.shape)\n",
        "\n",
        "# Sklearn Logistic Regression Model\n",
        "sk_lr_1 = LogisticRegression(solver='lbfgs', max_iter=500).fit(X_train_count, y_train )\n",
        "y_predict = sk_lr_1.predict(X_test_count)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance with Countvectorizer: \\non validation set:')\n",
        "printing_eval_scores (y_val, sk_lr_1.predict(X_val_count))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('on test set:')\n",
        "printing_eval_scores (y_test, y_predict, report = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_ex3J6rmVKu"
      },
      "source": [
        "### With tf-idf text presentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av3pjC83mUbt"
      },
      "source": [
        "# Vectorizing the documents\n",
        "tfidf = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf.fit_transform(X_train.to_list())\n",
        "X_val_tfidf = tfidf.transform(X_val.to_list())\n",
        "X_test_tfidf = tfidf.transform(X_test.to_list())\n",
        "print ('Shapes of X_train, y_train: ', X_train_tfidf.shape, y_train.shape)\n",
        "print ('Shapes of X_val, y_val: ', X_val_tfidf.shape, y_val.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test_tfidf.shape, y_test.shape)\n",
        "\n",
        "# Sklearn Logistic Regression Model\n",
        "sk_lr_2 = LogisticRegression(solver='lbfgs', max_iter=500).fit(X_train_tfidf, y_train )\n",
        "y_predict = sk_lr_2.predict(X_test_tfidf)\n",
        "\n",
        "# Model performing\n",
        "## on training set\n",
        "print('Model performance with tfidf: \\non validation set:')\n",
        "printing_eval_scores (y_val, sk_lr_2.predict(X_val_tfidf))\n",
        "\n",
        "## on test set\n",
        "print('\\n===========================')\n",
        "print('on test set:')\n",
        "printing_eval_scores (y_test, y_predict, report = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUMJOCJYERVd"
      },
      "source": [
        "# Part 2: Multiclass classification - Stackoverflow DS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WThVxknkGiXc"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xxae0yIEyQW"
      },
      "source": [
        "url_2 = 'http://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
        "train_dir = tf.keras.utils.get_file ('train',\n",
        "                                url_2,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "test_dir = tf.keras.utils.get_file ('test',\n",
        "                                url_2,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "\n",
        "print(os.listdir(train_dir))\n",
        "print(os.listdir(test_dir))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_BzBYOENa8D"
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('test',\n",
        "                                                       batch_size = batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YKsqlUKNsmz"
      },
      "source": [
        "## Text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPCScxOwNwQr"
      },
      "source": [
        "def custom_preprocessing (text):\n",
        "  lowercase = tf.strings.lower (text)\n",
        "  stripped_html = tf.strings.regex_replace (lowercase,'<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), \n",
        "                                  '')\n",
        "  \n",
        "max_features = 10000\n",
        "sequence_length = 250\n",
        "\n",
        "vectorize_layer = layers.TextVectorization(standardize = custom_preprocessing,\n",
        "                                           max_tokens = max_features,\n",
        "                                           output_mode = 'int',\n",
        "                                           output_sequence_length = sequence_length)\n",
        "# Extracting features for vectorizing using training set\n",
        "train_text = raw_train.map (lambda x, y: x)\n",
        "vectorize_layer.adapt(train_text)\n",
        "\n",
        "# Defining a function for fitting vectorizer function/layer to vectorize text (review)\n",
        "def fitting_vectorizer (text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorize_layer (text), label\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(raw_train))\n",
        "\n",
        "## print an instance with vectorized review and label for observing\n",
        "print ('text:', text_batch[0])\n",
        "print('label:', raw_train.class_names[label_batch[0]] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJnvsj58OXds"
      },
      "source": [
        "train = raw_train.map(fitting_vectorizer)\n",
        "val = raw_val.map(fitting_vectorizer)\n",
        "test = raw_test.map(fitting_vectorizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8TSwV8VOdBD"
      },
      "source": [
        "# Configure the dataset for performance\n",
        "autotune = tf.data.AUTOTUNE\n",
        "train = train.cache().prefetch (buffer_size = autotune)\n",
        "val = val.cache().prefetch (buffer_size = autotune)\n",
        "test = test.cache().prefetch (buffer_size = autotune)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0PwGsDTTdnO"
      },
      "source": [
        "for i, j in test:\n",
        "  print(j)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFknSi_VOfab"
      },
      "source": [
        "## Building a neural network multiclass classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRYKhiR6YU4-"
      },
      "source": [
        "# Defining an evaluation metric function\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred, average='macro')\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred, average='macro')\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred , average='macro')\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXgAJWxAOmPU"
      },
      "source": [
        "# Creating the model\n",
        "embedding_dim = 16\n",
        "dropout =  0.1\n",
        "activation = 'relu'\n",
        "\n",
        "print (\"======== activation function = {}, dropout = {}, batch size = {} ============\".format(activation, dropout, batch_size ))\n",
        "model = tf.keras.Sequential([layers.Embedding(max_features + 1,embedding_dim, name=\"embedding_2\"),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.GlobalAveragePooling1D(),\n",
        "                            layers.Dropout(dropout),\n",
        "                            layers.Dense(32, activation= activation),\n",
        "                            layers.Dense(4)])\n",
        "print(model.summary())\n",
        "\n",
        "# configure the model uisng optimizer and loss function\n",
        "model.compile(loss = losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "              optimizer = 'adam',\n",
        "              metrics = 'accuracy') \n",
        "# training the model\n",
        "epochs = 10\n",
        "history = model.fit(train,\n",
        "                    validation_data = val,\n",
        "                    epochs = epochs)\n",
        "# testing the model\n",
        "pred_label = tf.argmax(model.predict(test),1)\n",
        "true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "loss, accuracy = model.evaluate(test)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(loss, accuracy))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}