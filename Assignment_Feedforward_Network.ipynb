{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Feedforward-Network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPo3iJ82rlvzf82Tyr56p6K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment_Feedforward_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybsamp8T__sG",
        "outputId": "2cb16230-54dc-4e5d-a836-1997ca6fa046"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import preprocessing\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEecDn_cAPUR"
      },
      "source": [
        "# Part 1: IMDB sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I37czSdvAJGh"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOTrU1EcAaJW",
        "outputId": "b28e8fe7-4ddc-4511-e654-2d7ea659917a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "url = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "data = tf.keras.utils.get_file ('aclImdb_v1',\n",
        "                                url,\n",
        "                                untar = True,\n",
        "                                cache_dir = '.',\n",
        "                                cache_subdir = '')\n",
        "data_dir = os.path.join (os.path.dirname(data), 'aclImdb')\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84131840/84125825 [==============================] - 3s 0us/step\n",
            "84140032/84125825 [==============================] - 3s 0us/step\n",
            "['imdb.vocab', 'test', 'README', 'imdbEr.txt', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl4s0XGxECq4",
        "outputId": "03c2f025-42dd-4867-8709-b319b3b12cab"
      },
      "source": [
        "train_dir = os.path.join (data_dir, 'train')\n",
        "print(os.listdir(train_dir))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['neg', 'urls_neg.txt', 'urls_pos.txt', 'unsup', 'pos', 'urls_unsup.txt', 'unsupBow.feat', 'labeledBow.feat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5fHSce2Rk-7",
        "outputId": "10cb20de-02a2-4204-ee96-54b0847dabbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Loading data from the directory\n",
        "batch_size = 32\n",
        "seed = 42\n",
        "raw_train = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                        batch_size =batch_size,\n",
        "                                                        validation_split = 0.2,\n",
        "                                                        subset = 'training',\n",
        "                                                        seed = seed)\n",
        "raw_val = tf.keras.utils.text_dataset_from_directory ('aclImdb/train',\n",
        "                                                      batch_size = batch_size,\n",
        "                                                      validation_split = 0.2,\n",
        "                                                      subset = 'validation',\n",
        "                                                      seed = seed)\n",
        "raw_test = tf.keras.utils.text_dataset_from_directory ('aclImdb/test',\n",
        "                                                       batch_size = batch_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 75000 files belonging to 3 classes.\n",
            "Using 60000 files for training.\n",
            "Found 75000 files belonging to 3 classes.\n",
            "Using 15000 files for validation.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuL_ipXkaAyv"
      },
      "source": [
        "# Text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KVgg_ZWaFtU"
      },
      "source": [
        "def custom_preprocessing (text):\n",
        "  lowercase = tf.strings.lower (text)\n",
        "  stripped_html = tf.strings.regrex_replace (lowercase,'<br />', ' ')\n",
        "  return tf/strings.regrex_replace(stripped_html,\n",
        "                                   '')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}