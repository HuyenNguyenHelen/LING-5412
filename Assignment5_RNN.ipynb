{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5_RNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOz54olf8TIBBtgvxd7sF8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment5_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH1MLrmUyHKE"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLtFRj7_akl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bdd3230-2af3-4471-972b-004d992c7c5f"
      },
      "source": [
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYaW1wJqzwev"
      },
      "source": [
        "# Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW6Tc5GAz2dG",
        "outputId": "35d7274c-fccf-4e50-b7e2-7292e1a40c5d"
      },
      "source": [
        "dataset, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)\n",
        "train_dataset, test_dataset = dataset['train'], dataset['test']\n",
        "\n",
        "train_dataset.element_spec"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tN5HMZHaHc-"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "# data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen= maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWUJmFLu5Ehl",
        "outputId": "2f265763-1999-4aac-a620-975ca90e3ec2"
      },
      "source": [
        "info"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='imdb_reviews',\n",
              "    version=1.0.0,\n",
              "    description='Large Movie Review Dataset.\n",
              "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
              "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "    features=FeaturesDict({\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "        'text': Text(shape=(), dtype=tf.string),\n",
              "    }),\n",
              "    total_num_examples=100000,\n",
              "    splits={\n",
              "        'test': 25000,\n",
              "        'train': 25000,\n",
              "        'unsupervised': 50000,\n",
              "    },\n",
              "    supervised_keys=('text', 'label'),\n",
              "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "      month     = {June},\n",
              "      year      = {2011},\n",
              "      address   = {Portland, Oregon, USA},\n",
              "      publisher = {Association for Computational Linguistics},\n",
              "      pages     = {142--150},\n",
              "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "    }\"\"\",\n",
              "    redistribution_info=,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n5pIYyEYsgN"
      },
      "source": [
        "# Shuffling the dataset\n",
        "buffer_size = 10000\n",
        "batch_size = 64\n",
        "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size) #.prefetch (tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size) #.prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw1JaB5g6Y4F"
      },
      "source": [
        "# Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5uDkzuD-ZMG"
      },
      "source": [
        "## Building the LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXAqyl7gHzmS"
      },
      "source": [
        "# Defining an evaluation metric function\n",
        "def printing_eval_scores (y_true, y_pred, report=''):\n",
        "  accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
        "  precision = sklearn.metrics.precision_score(y_true, y_pred, average='binary')\n",
        "  recall = sklearn.metrics.recall_score(y_true, y_pred, average='binary')\n",
        "  f1 = sklearn.metrics.f1_score(y_true, y_pred , average='binary')\n",
        "  print('accuracy score: {:.3f}'.format(accuracy))\n",
        "  print('precision score: {:.3f}'.format(precision))\n",
        "  print('recall score: {:.3f}'.format(recall))\n",
        "  print('F1 score: {:.3f}'.format(f1))\n",
        "  if report is True:\n",
        "    print(classification_report(y_true, y_pred))\n",
        "  else:\n",
        "    pass\n",
        "  return accuracy, precision, recall, f1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNH5dRsqgOCt"
      },
      "source": [
        "### With different embedding sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tBy-8US6XxQ"
      },
      "source": [
        "## Representing the  text\n",
        "vocab_size = 10000\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=vocab_size)\n",
        "encoder.adapt(train_dataset.map(lambda x,y: x))\n",
        "\n",
        "# Store vocabulary\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:20]\n",
        "\n",
        "# Defining a function for fitting vectorizer function/layer to vectorize text (review)\n",
        "def fitting_vectorizer (text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return encoder (text), label\n",
        "\n",
        "# storing text batch and label batch\n",
        "text_batch, label_batch = next(iter(train_dataset))\n",
        "\n",
        "# ## print an instance with vectorized review and label for observing\n",
        "# print ('REVIEW:', text_batch[0])\n",
        "# print('LABEL:', raw_train.class_names[label_batch[0]] )\n",
        "\n",
        "train = train_dataset.map(fitting_vectorizer)\n",
        "test = test_dataset.map(fitting_vectorizer)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8B652f3XCI3",
        "outputId": "fc9cdbfd-d87c-490e-caf8-4dfa0152d907",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for k,v in train.take(1):\n",
        "  print(k)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[   4   53   50 ...    0    0    0]\n",
            " [ 149    9   67 ...    0    0    0]\n",
            " [  11   18   14 ...    0    0    0]\n",
            " ...\n",
            " [  11 9750   18 ...    0    0    0]\n",
            " [   2  882    5 ...    0    0    0]\n",
            " [  51   23   26 ...    0    0    0]], shape=(64, 819), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH0TtCkH5Xkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ffeb3a0-f197-4964-86c4-4878e2fa8560"
      },
      "source": [
        "# Creating the model\n",
        "embedding_sizes = [32,64,128]\n",
        "for size in embedding_sizes:\n",
        "  print (\"\\n========= embedding vectors'size= %s ============\" %size)\n",
        "  model = tf.keras.Sequential([encoder,\n",
        "                              tf.keras.layers.Embedding(\n",
        "                                  input_dim = len(encoder.get_vocabulary()),\n",
        "                                  output_dim = size,\n",
        "                                  mask_zero = True),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "  print(model.summary())\n",
        "  # Compile the model for training\n",
        "  model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                metrics = ['accuracy'])\n",
        "  # Training the model\n",
        "  history = model.fit (train_dataset,\n",
        "                      epochs = 10, \n",
        "                      validation_data = test_dataset,\n",
        "                      validation_steps = 30)\n",
        "  # testing the model\n",
        "  ### pred_label = tf.argmax(model.predict(test),1)\n",
        "  pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test], axis=0)\n",
        "\n",
        "  test_loss, test_acc = model.evaluate (test_dataset)\n",
        "  # print('Test loss: ', test_loss)\n",
        "  # print('Test acurracy: ', test_acc)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 109s 251ms/step - loss: 0.6309 - accuracy: 0.6450 - val_loss: 0.4827 - val_accuracy: 0.7969\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 94s 238ms/step - loss: 0.3926 - accuracy: 0.8348 - val_loss: 0.4405 - val_accuracy: 0.8016\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.3033 - accuracy: 0.8807 - val_loss: 0.3374 - val_accuracy: 0.8708\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 95s 239ms/step - loss: 0.2338 - accuracy: 0.9110 - val_loss: 0.3155 - val_accuracy: 0.8708\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 92s 233ms/step - loss: 0.1947 - accuracy: 0.9294 - val_loss: 0.3460 - val_accuracy: 0.8776\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 93s 234ms/step - loss: 0.1676 - accuracy: 0.9414 - val_loss: 0.3469 - val_accuracy: 0.8734\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.1411 - accuracy: 0.9526 - val_loss: 0.3368 - val_accuracy: 0.8755\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.1228 - accuracy: 0.9600 - val_loss: 0.3893 - val_accuracy: 0.8708\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 93s 237ms/step - loss: 0.1082 - accuracy: 0.9653 - val_loss: 0.3901 - val_accuracy: 0.8719\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.0935 - accuracy: 0.9727 - val_loss: 0.4231 - val_accuracy: 0.8703\n",
            "391/391 [==============================] - 49s 124ms/step - loss: 0.4096 - accuracy: 0.8652\n",
            "Test loss:  0.4095645844936371\n",
            "Test acurracy:  0.8651599884033203\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 108s 249ms/step - loss: 0.5886 - accuracy: 0.6764 - val_loss: 0.4114 - val_accuracy: 0.8297\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.2981 - accuracy: 0.8820 - val_loss: 0.3738 - val_accuracy: 0.8458\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.2180 - accuracy: 0.9168 - val_loss: 0.3047 - val_accuracy: 0.8797\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 95s 240ms/step - loss: 0.1769 - accuracy: 0.9352 - val_loss: 0.3190 - val_accuracy: 0.8807\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 94s 239ms/step - loss: 0.1461 - accuracy: 0.9496 - val_loss: 0.3580 - val_accuracy: 0.8766\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 94s 239ms/step - loss: 0.1216 - accuracy: 0.9583 - val_loss: 0.4192 - val_accuracy: 0.8724\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.1076 - accuracy: 0.9647 - val_loss: 0.4267 - val_accuracy: 0.8641\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.0911 - accuracy: 0.9724 - val_loss: 0.4758 - val_accuracy: 0.8557\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.0883 - accuracy: 0.9722 - val_loss: 0.4287 - val_accuracy: 0.8552\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.0726 - accuracy: 0.9790 - val_loss: 0.4927 - val_accuracy: 0.8526\n",
            "391/391 [==============================] - 48s 122ms/step - loss: 0.4873 - accuracy: 0.8572\n",
            "Test loss:  0.4872962236404419\n",
            "Test acurracy:  0.8571599721908569\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 108s 251ms/step - loss: 0.5648 - accuracy: 0.7047 - val_loss: 0.3737 - val_accuracy: 0.8479\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 96s 242ms/step - loss: 0.2858 - accuracy: 0.8881 - val_loss: 0.3024 - val_accuracy: 0.8781\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 95s 241ms/step - loss: 0.2061 - accuracy: 0.9232 - val_loss: 0.2948 - val_accuracy: 0.8833\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 96s 242ms/step - loss: 0.1650 - accuracy: 0.9405 - val_loss: 0.3260 - val_accuracy: 0.8760\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 95s 241ms/step - loss: 0.1339 - accuracy: 0.9559 - val_loss: 0.3356 - val_accuracy: 0.8818\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 95s 240ms/step - loss: 0.1153 - accuracy: 0.9636 - val_loss: 0.3872 - val_accuracy: 0.8641\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 95s 240ms/step - loss: 0.0974 - accuracy: 0.9696 - val_loss: 0.4019 - val_accuracy: 0.8698\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 95s 241ms/step - loss: 0.0806 - accuracy: 0.9773 - val_loss: 0.4272 - val_accuracy: 0.8672\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 94s 239ms/step - loss: 0.0691 - accuracy: 0.9808 - val_loss: 0.4887 - val_accuracy: 0.8510\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 94s 239ms/step - loss: 0.0644 - accuracy: 0.9828 - val_loss: 0.5319 - val_accuracy: 0.8542\n",
            "391/391 [==============================] - 49s 126ms/step - loss: 0.5303 - accuracy: 0.8560\n",
            "Test loss:  0.5302598476409912\n",
            "Test acurracy:  0.8559600114822388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CYT3-JSJAG4"
      },
      "source": [
        "### With different vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "XxxVqkyaJFer",
        "outputId": "771f8106-b748-468a-a77d-2b8e3eaea8e4"
      },
      "source": [
        "vocab_sizes = [5000, 7000, 10000]\n",
        "for size in vocab_sizes:\n",
        "  print (\"\\n========= vocabulary size = %s ============\" %size)\n",
        "  encoder = tf.keras.layers.TextVectorization(max_tokens=size)\n",
        "  encoder.adapt(train_dataset.map(lambda x,y: x))\n",
        "  # Store vocabulary\n",
        "  vocab = np.array(encoder.get_vocabulary())\n",
        "\n",
        "  model = tf.keras.Sequential([encoder,\n",
        "                              tf.keras.layers.Embedding(\n",
        "                                  input_dim = len(encoder.get_vocabulary()),\n",
        "                                  output_dim = 32,\n",
        "                                  mask_zero = True),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "                              tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "  print(model.summary())\n",
        "  # Compile the model for training\n",
        "  model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "                optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                metrics = ['accuracy'])\n",
        "  # Training the model\n",
        "  history = model.fit (train_dataset,\n",
        "                      epochs = 10, \n",
        "                      validation_data = test_dataset,\n",
        "                      validation_steps = 30)\n",
        "  # testing the model\n",
        "  ### pred_label = tf.argmax(model.predict(test),1)\n",
        "  pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "  test_loss, test_acc = model.evaluate (test_dataset)\n",
        "  # print('Test loss: ', test_loss)\n",
        "  print('Test acurracy: ', test_acc)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========= vocabulary size = 5000 ============\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 32)          160000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              49664     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,825\n",
            "Trainable params: 213,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 107s 247ms/step - loss: 0.6601 - accuracy: 0.5976 - val_loss: 0.5872 - val_accuracy: 0.7302\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.5656 - accuracy: 0.7126 - val_loss: 0.4870 - val_accuracy: 0.7969\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.3888 - accuracy: 0.8472 - val_loss: 0.3598 - val_accuracy: 0.8510\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 92s 233ms/step - loss: 0.2986 - accuracy: 0.8794 - val_loss: 0.3354 - val_accuracy: 0.8542\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.2613 - accuracy: 0.8982 - val_loss: 0.3115 - val_accuracy: 0.8708\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.2374 - accuracy: 0.9111 - val_loss: 0.3076 - val_accuracy: 0.8755\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.2169 - accuracy: 0.9201 - val_loss: 0.3013 - val_accuracy: 0.8786\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.2036 - accuracy: 0.9270 - val_loss: 0.3003 - val_accuracy: 0.8792\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 91s 230ms/step - loss: 0.1865 - accuracy: 0.9334 - val_loss: 0.3156 - val_accuracy: 0.8661\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 93s 237ms/step - loss: 0.1792 - accuracy: 0.9361 - val_loss: 0.3298 - val_accuracy: 0.8760\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-6e852167d4a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# testing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m### pred_label = tf.argmax(model.predict(test),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m   \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m   \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttViIdaICVC2"
      },
      "source": [
        "### With different optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeQy7iEUCaZG",
        "outputId": "bd4de441-02c1-4043-f2f8-b6569de4693b"
      },
      "source": [
        "# configure the model uisng optimizer and loss function\n",
        "optimizers = ['adagrad', 'rmsprop', 'adam']\n",
        "\n",
        "print(model.summary())\n",
        "for opt in optimizers:\n",
        "  print( '\\n========== optimizer = %s' %opt)\n",
        "  # Compile the model for training\n",
        "  model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "                optimizer = opt,\n",
        "                metrics = ['accuracy'])\n",
        "  # Training the model\n",
        "  history = model.fit (train_dataset,\n",
        "                      epochs = 10, \n",
        "                      validation_data = test_dataset,\n",
        "                      validation_steps = 30)\n",
        "  # testing the model\n",
        "  ### pred_label = tf.argmax(model.predict(test),1)\n",
        "  pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "  true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "  test_loss, test_acc = model.evaluate (test_dataset)\n",
        "  # print('Test loss: ', test_loss)\n",
        "  print('Test acurracy: ', test_acc)\n",
        "  print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "  printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 32)          160000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              49664     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,825\n",
            "Trainable params: 213,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "========== optimizer = adagrad\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 105s 245ms/step - loss: 0.1638 - accuracy: 0.9444 - val_loss: 0.3378 - val_accuracy: 0.8776\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.1568 - accuracy: 0.9477 - val_loss: 0.3186 - val_accuracy: 0.8823\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.1545 - accuracy: 0.9482 - val_loss: 0.3371 - val_accuracy: 0.8781\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 92s 233ms/step - loss: 0.1530 - accuracy: 0.9496 - val_loss: 0.3281 - val_accuracy: 0.8745\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.1519 - accuracy: 0.9494 - val_loss: 0.3413 - val_accuracy: 0.8745\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.1506 - accuracy: 0.9502 - val_loss: 0.3347 - val_accuracy: 0.8781\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.1503 - accuracy: 0.9509 - val_loss: 0.3363 - val_accuracy: 0.8724\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.1486 - accuracy: 0.9516 - val_loss: 0.3527 - val_accuracy: 0.8734\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.1480 - accuracy: 0.9517 - val_loss: 0.3477 - val_accuracy: 0.8755\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 91s 229ms/step - loss: 0.1475 - accuracy: 0.9526 - val_loss: 0.3387 - val_accuracy: 0.8781\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.3258 - accuracy: 0.8775\n",
            "Test acurracy:  0.8775200247764587\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.326 - Accuracy: 0.878\n",
            "accuracy score: 0.878\n",
            "precision score: 0.883\n",
            "recall score: 0.870\n",
            "F1 score: 0.877\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.88     12500\n",
            "           1       0.88      0.87      0.88     12500\n",
            "\n",
            "    accuracy                           0.88     25000\n",
            "   macro avg       0.88      0.88      0.88     25000\n",
            "weighted avg       0.88      0.88      0.88     25000\n",
            "\n",
            "\n",
            "========== optimizer = rmsprop\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 106s 247ms/step - loss: 0.3176 - accuracy: 0.8691 - val_loss: 0.3257 - val_accuracy: 0.8615\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 92s 234ms/step - loss: 0.2457 - accuracy: 0.9041 - val_loss: 0.3064 - val_accuracy: 0.8729\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 95s 240ms/step - loss: 0.2137 - accuracy: 0.9158 - val_loss: 0.3233 - val_accuracy: 0.8604\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.1888 - accuracy: 0.9279 - val_loss: 0.3578 - val_accuracy: 0.8771\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.1652 - accuracy: 0.9373 - val_loss: 0.3558 - val_accuracy: 0.8734\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 93s 236ms/step - loss: 0.1448 - accuracy: 0.9472 - val_loss: 0.4141 - val_accuracy: 0.8505\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 93s 235ms/step - loss: 0.1252 - accuracy: 0.9548 - val_loss: 0.4920 - val_accuracy: 0.8526\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.1050 - accuracy: 0.9640 - val_loss: 0.4635 - val_accuracy: 0.8505\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 92s 232ms/step - loss: 0.0825 - accuracy: 0.9719 - val_loss: 0.5052 - val_accuracy: 0.8599\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 92s 233ms/step - loss: 0.0674 - accuracy: 0.9769 - val_loss: 0.5612 - val_accuracy: 0.8510\n",
            "391/391 [==============================] - 48s 122ms/step - loss: 0.5264 - accuracy: 0.8555\n",
            "Test acurracy:  0.8554800152778625\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.526 - Accuracy: 0.855\n",
            "accuracy score: 0.855\n",
            "precision score: 0.849\n",
            "recall score: 0.865\n",
            "F1 score: 0.857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85     12500\n",
            "           1       0.85      0.87      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.86      0.86      0.86     25000\n",
            "weighted avg       0.86      0.86      0.86     25000\n",
            "\n",
            "\n",
            "========== optimizer = adam\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 104s 244ms/step - loss: 0.0585 - accuracy: 0.9800 - val_loss: 0.6076 - val_accuracy: 0.8286\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 94s 237ms/step - loss: 0.0323 - accuracy: 0.9886 - val_loss: 0.7733 - val_accuracy: 0.8453\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 92s 233ms/step - loss: 0.0295 - accuracy: 0.9895 - val_loss: 0.7509 - val_accuracy: 0.8516\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 91s 232ms/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.8455 - val_accuracy: 0.8500\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 91s 230ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.9761 - val_accuracy: 0.8359\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 91s 230ms/step - loss: 0.0155 - accuracy: 0.9943 - val_loss: 1.0173 - val_accuracy: 0.8495\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 94s 237ms/step - loss: 0.0195 - accuracy: 0.9932 - val_loss: 0.9098 - val_accuracy: 0.8323\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 93s 237ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.9077 - val_accuracy: 0.8359\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 91s 230ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 1.1079 - val_accuracy: 0.8479\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 91s 231ms/step - loss: 0.0131 - accuracy: 0.9952 - val_loss: 1.0697 - val_accuracy: 0.8339\n",
            "391/391 [==============================] - 47s 121ms/step - loss: 0.9642 - accuracy: 0.8403\n",
            "Test acurracy:  0.8403199911117554\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.964 - Accuracy: 0.840\n",
            "accuracy score: 0.840\n",
            "precision score: 0.812\n",
            "recall score: 0.885\n",
            "F1 score: 0.847\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.83     12500\n",
            "           1       0.81      0.89      0.85     12500\n",
            "\n",
            "    accuracy                           0.84     25000\n",
            "   macro avg       0.84      0.84      0.84     25000\n",
            "weighted avg       0.84      0.84      0.84     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CZLUQDQFeYq"
      },
      "source": [
        "### Replacing with LSTM with GRU "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRvMetfCF8Ir",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cadb3524-af72-4c3a-da4b-27eb703fc379"
      },
      "source": [
        "model = tf.keras.Sequential([encoder,\n",
        "                              tf.keras.layers.Embedding(\n",
        "                                  input_dim = len(encoder.get_vocabulary()),\n",
        "                                  output_dim = 32,\n",
        "                                  mask_zero = True),\n",
        "                              tf.keras.layers.GRU(64,\n",
        "                                                  activation = 'tanh',\n",
        "                                                  recurrent_activation = 'sigmoid',\n",
        "                                                  recurrent_dropout = 0.0,\n",
        "                                                  use_bias = True),\n",
        "                              tf.keras.layers.Dense(32, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "print(model.summary())\n",
        "# Compile the model for training\n",
        "print( 'Training GRU model...')\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "              optimizer = 'adagrad',\n",
        "              metrics = ['accuracy'])\n",
        "# Training the model\n",
        "history = model.fit (train_dataset,\n",
        "                    epochs = 10, \n",
        "                    validation_data = test_dataset,\n",
        "                    validation_steps = 30)\n",
        "# testing the model\n",
        "### pred_label = tf.argmax(model.predict(test),1)\n",
        "pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate (test_dataset)\n",
        "print('Test acurracy: ', test_acc)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 32)          320000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                18816     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 340,929\n",
            "Trainable params: 340,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Training GRU model...\n",
            "Epoch 1/10\n",
            "391/391 [==============================] - 76s 167ms/step - loss: 0.6931 - accuracy: 0.4962 - val_loss: 0.6931 - val_accuracy: 0.5063\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 64s 162ms/step - loss: 0.6930 - accuracy: 0.5146 - val_loss: 0.6930 - val_accuracy: 0.5141\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 64s 163ms/step - loss: 0.6930 - accuracy: 0.5200 - val_loss: 0.6929 - val_accuracy: 0.5203\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 64s 162ms/step - loss: 0.6929 - accuracy: 0.5220 - val_loss: 0.6929 - val_accuracy: 0.5271\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 64s 162ms/step - loss: 0.6929 - accuracy: 0.5299 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 64s 161ms/step - loss: 0.6929 - accuracy: 0.5285 - val_loss: 0.6929 - val_accuracy: 0.5333\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 64s 161ms/step - loss: 0.6928 - accuracy: 0.5316 - val_loss: 0.6928 - val_accuracy: 0.5385\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 64s 161ms/step - loss: 0.6928 - accuracy: 0.5328 - val_loss: 0.6928 - val_accuracy: 0.5391\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 64s 161ms/step - loss: 0.6928 - accuracy: 0.5351 - val_loss: 0.6928 - val_accuracy: 0.5401\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 64s 161ms/step - loss: 0.6928 - accuracy: 0.5330 - val_loss: 0.6928 - val_accuracy: 0.5380\n",
            "391/391 [==============================] - 27s 68ms/step - loss: 0.6928 - accuracy: 0.5362\n",
            "Test acurracy:  0.5361599922180176\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.693 - Accuracy: 0.536\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-7c70b8458b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test acurracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mprinting_eval_scores\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrue_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'printing_eval_scores' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7dIYKgTuFNb"
      },
      "source": [
        "# Stacking 2 bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRFiFjk2g-SX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "outputId": "b8954ff2-f742-45b3-992d-4f687ee7a3cf"
      },
      "source": [
        "# Creating the model\n",
        "model = tf.keras.Sequential([encoder,\n",
        "                             tf.keras.layers.Embedding(\n",
        "                                 input_dim = len(encoder.get_vocabulary()),\n",
        "                                 output_dim = 64,\n",
        "                                 mask_zero = True),\n",
        "                            tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences = True),\n",
        "                                                          backward_layer = tf.keras.layers.LSTM(64, return_sequences = True, go_backwards = True),\n",
        "                                                          merge_mode = 'concat'),\n",
        "                            tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                            tf.keras.layers.Dense(1, activation = 'sigmoid')])\n",
        "\n",
        "\n",
        "# Compile the model for training\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit (train_dataset,\n",
        "                    epochs = 10, \n",
        "                    validation_data = test_dataset,\n",
        "                    validation_steps = 30)\n",
        "# testing the model\n",
        "### pred_label = tf.argmax(model.predict(test),1)\n",
        "pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate (test_dataset)\n",
        "print('Test acurracy: ', test_acc)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-56e326faa985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m history = model.fit (train_dataset,\n\u001b[1;32m     21\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     validation_data = test_dataset)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;31m# testing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m### pred_label = tf.argmax(model.predict(test),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, 1) vs (None,)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGV57v7igjIk"
      },
      "source": [
        "### With an average of all hidden states to fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFq1eXq9xcVV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "ecea4ca6-bb7d-4a7f-f962-f41f02470257"
      },
      "source": [
        "# Creating the model\n",
        "model = tf.keras.Sequential([encoder,\n",
        "                              tf.keras.layers.Embedding(\n",
        "                                  input_dim = len(encoder.get_vocabulary()),\n",
        "                                  output_dim = 64,\n",
        "                                  mask_zero = True),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences = True)),\n",
        "                             tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                              tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "\n",
        "# Compile the model for training\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit (train_dataset,\n",
        "                    epochs = 5, \n",
        "                    validation_data = test_dataset,\n",
        "                    validation_steps = 30)\n",
        "# testing the model\n",
        "### pred_label = tf.argmax(model.predict(test),1)\n",
        "pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate (test_dataset)\n",
        "print('Test acurracy: ', test_acc)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text_vectorization_2_input'), name='text_vectorization_2_input', description=\"created by layer 'text_vectorization_2_input'\"), but it was called on an input with incompatible shape (None, 500).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None,) for input KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.string, name='text_vectorization_2_input'), name='text_vectorization_2_input', description=\"created by layer 'text_vectorization_2_input'\"), but it was called on an input with incompatible shape (None, 500).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-adc29d8bfda4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0;31m#validation_data = test_dataset,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                     validation_steps = 30)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# testing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m### pred_label = tf.argmax(model.predict(test),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"text_vectorization_2\" (type TextVectorization).\n    \n    Can not squeeze dim[1], expected a dimension of 1, got 500 for '{{node sequential_2/text_vectorization_2/Squeeze}} = Squeeze[T=DT_STRING, squeeze_dims=[-1]](sequential_2/text_vectorization_2/StaticRegexReplace)' with input shapes: [?,500].\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 500), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD9ruwjy9tUg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "935a943a-5fae-485b-ef19-77347566469a"
      },
      "source": [
        "\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fe870d13528f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuwIH3R-Eov0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbbf842-6736-437c-8d79-9e955520b0e5"
      },
      "source": [
        "# Creating the model\n",
        "model = tf.keras.Sequential([encoder,\n",
        "                              tf.keras.layers.Embedding(\n",
        "                                  input_dim = len(encoder.get_vocabulary()),\n",
        "                                  output_dim = 64,\n",
        "                                  mask_zero = True),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences = True)),\n",
        "                            # tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1)),\n",
        "                             tf.keras.layers.GlobalAveragePooling1D(),\n",
        "                              tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "\n",
        "print(model.summary())\n",
        "# Compile the model for training\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit (train_dataset,\n",
        "                    epochs = 5, \n",
        "                    validation_data = test_dataset,\n",
        "                    validation_steps = 30)\n",
        "# testing the model\n",
        "### pred_label = tf.argmax(model.predict(test),1)\n",
        "pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate (test_dataset)\n",
        "print('Test acurracy: ', test_acc)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, None)             0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 64)          640000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        66048     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 706,177\n",
            "Trainable params: 706,177\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "391/391 [==============================] - 115s 254ms/step - loss: 0.5581 - accuracy: 0.7124 - val_loss: 0.4538 - val_accuracy: 0.8089\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 96s 242ms/step - loss: 0.3577 - accuracy: 0.8614 - val_loss: 0.3735 - val_accuracy: 0.8505\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 95s 241ms/step - loss: 0.2844 - accuracy: 0.8932 - val_loss: 0.3580 - val_accuracy: 0.8615\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 95s 240ms/step - loss: 0.2696 - accuracy: 0.9014 - val_loss: 0.4632 - val_accuracy: 0.8229\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 94s 237ms/step - loss: 0.2519 - accuracy: 0.9061 - val_loss: 0.3596 - val_accuracy: 0.8536\n",
            "391/391 [==============================] - 51s 130ms/step - loss: 0.3459 - accuracy: 0.8576\n",
            "Test acurracy:  0.8576400279998779\n",
            "\n",
            "Testing performance:\n",
            " Loss: 0.346 - Accuracy: 0.858\n",
            "accuracy score: 0.858\n",
            "precision score: 0.862\n",
            "recall score: 0.852\n",
            "F1 score: 0.857\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.86      0.86     12500\n",
            "           1       0.86      0.85      0.86     12500\n",
            "\n",
            "    accuracy                           0.86     25000\n",
            "   macro avg       0.86      0.86      0.86     25000\n",
            "weighted avg       0.86      0.86      0.86     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.85764, 0.8620717583218596, 0.85152, 0.8567633919587878)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5K-7fI-GguP"
      },
      "source": [
        "## With attention layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0Ddy95nl_WP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba341a19-0663-473c-a66a-9857107a3809"
      },
      "source": [
        "print(encoder.get_weights())\n",
        "print(encoder.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[array([b'the', b'and', b'a', ..., b'hi', b'hawaii', b'hardships'],\n",
            "      dtype=object)]\n",
            "['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i', 'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but', 'film', 'on', 'not', 'you', 'are', 'his', 'have', 'he', 'be', 'one', 'its', 'at', 'all', 'by', 'an', 'they', 'from', 'who', 'so', 'like', 'her', 'just', 'or', 'about', 'has', 'if', 'out', 'some', 'there', 'what', 'good', 'when', 'more', 'very', 'even', 'she', 'my', 'no', 'up', 'would', 'which', 'only', 'time', 'really', 'story', 'their', 'were', 'had', 'see', 'can', 'me', 'than', 'we', 'much', 'well', 'been', 'get', 'will', 'into', 'also', 'because', 'other', 'do', 'people', 'bad', 'great', 'first', 'how', 'most', 'him', 'dont', 'made', 'then', 'movies', 'make', 'films', 'could', 'way', 'them', 'any', 'too', 'after', 'characters', 'think', 'watch', 'two', 'many', 'being', 'seen', 'character', 'never', 'little', 'acting', 'where', 'plot', 'best', 'love', 'did', 'know', 'life', 'show', 'does', 'ever', 'your', 'still', 'better', 'over', 'off', 'these', 'end', 'say', 'while', 'here', 'man', 'why', 'scene', 'such', 'scenes', 'go', 'should', 'something', 'through', 'im', 'back', 'those', 'doesnt', 'real', 'watching', 'years', 'though', 'now', 'thing', 'actors', 'didnt', 'another', 'new', 'before', 'actually', 'nothing', 'makes', 'find', 'work', 'funny', 'look', 'few', 'old', 'going', 'same', 'every', 'lot', 'us', 'part', 'director', 'again', 'thats', 'cant', 'quite', 'cast', 'want', 'pretty', 'things', 'seems', 'young', 'got', 'around', 'fact', 'however', 'down', 'world', 'take', 'enough', 'both', 'give', 'between', 'may', 'ive', 'big', 'horror', 'original', 'thought', 'own', 'without', 'gets', 'always', 'series', 'right', 'long', 'isnt', 'saw', 'come', 'almost', 'times', 'least', 'theres', 'role', 'point', 'action', 'must', 'interesting', 'whole', 'comedy', 'bit', 'family', 'music', 'done', 'script', 'last', 'might', 'hes', 'anything', 'guy', 'since', 'feel', 'minutes', 'far', 'probably', 'performance', 'am', 'kind', 'rather', 'worst', 'yet', 'away', 'sure', 'tv', 'making', 'woman', 'girl', 'each', 'found', 'fun', 'played', 'having', 'anyone', 'our', 'although', 'believe', 'comes', 'trying', 'course', 'especially', 'goes', 'day', 'looks', 'hard', 'shows', 'put', 'different', 'wasnt', 'place', 'maybe', 'book', 'once', 'set', 'main', 'reason', 'money', 'worth', 'sense', 'everything', 'looking', 'true', 'ending', 'someone', 'watched', 'plays', 'job', '2', 'actor', 'seem', 'three', 'said', 'takes', 'screen', 'dvd', 'together', 'play', 'instead', 'john', 'during', 'beautiful', 'later', '10', 'effects', 'himself', 'everyone', 'version', 'left', 'seeing', 'special', 'audience', 'night', 'excellent', 'house', 'american', 'idea', 'simply', 'nice', 'wife', 'shot', 'youre', 'read', 'high', 'black', 'less', 'completely', 'second', 'kids', 'help', 'else', 'poor', 'fan', 'war', 'star', 'used', 'given', 'year', 'try', 'father', 'death', 'friends', 'need', 'use', 'rest', 'enjoy', 'home', 'men', 'performances', 'short', 'mind', 'classic', 'until', 'either', 'truly', 'along', 'hollywood', 'boring', 'half', 'dead', 'wrong', 'tell', 'production', 'women', 'line', 'remember', 'couple', 'came', 'next', 'recommend', 'start', 'perhaps', 'full', 'let', 'understand', 'wonderful', 'stupid', 'getting', 'others', 'mean', 'moments', 'playing', 'awful', 'keep', 'episode', 'terrible', 'camera', 'small', 'definitely', 'gives', 'often', 'stars', 'doing', 'sex', 'video', 'early', 'perfect', 'become', 'finally', 'name', 'felt', 'school', 'human', 'supposed', 'face', 'couldnt', 'liked', 'lines', 'dialogue', 'piece', 'person', 'itself', 'lost', 'absolutely', 'top', 'yes', 'case', 'against', 'entire', 'went', 'certainly', 'written', 'live', 'title', 'waste', 'shes', 'sort', 'head', 'budget', 'hope', 'problem', 'style', 'several', 'overall', 'picture', 'loved', 'evil', 'mr', 'worse', 'id', 'fans', 'becomes', 'entertaining', '3', 'cinema', 'boy', 'beginning', 'seemed', 'white', 'based', 'already', 'despite', 'care', 'oh', 'wanted', 'example', 'dark', '\\x96', 'lives', 'guys', 'unfortunately', 'killer', 'throughout', 'mother', 'direction', 'final', 'friend', 'turn', 'totally', 'fine', 'wont', '1', 'wants', 'children', 'amazing', 'sound', 'laugh', 'girls', 'drama', 'youll', 'guess', 'lead', 'tries', 'low', 'called', 'humor', 'writing', 'under', 'michael', 'works', 'history', 'turns', 'able', 'enjoyed', 'theyre', 'behind', 'past', 'quality', 'days', 'gave', 'favorite', 'starts', 'son', 'kill', 'game', 'act', 'sometimes', 'side', 'viewer', 'town', 'horrible', 'parts', 'car', 'actress', 'soon', 'child', 'ones', 'eyes', 'expect', 'obviously', 'flick', 'themselves', 'directed', 'thinking', 'heart', 'art', 'brilliant', 'stories', 'ill', 'decent', 'highly', 'run', 'feeling', 'myself', 'genre', 'late', 'blood', 'stuff', 'fight', 'says', 'close', 'took', 'city', 'except', 'cannot', 'heard', 'hand', 'leave', 'killed', 'kid', 'matter', 'police', 'hell', 'moment', 'wouldnt', 'extremely', 'strong', 'roles', 'happens', 'particularly', 'lack', 'hour', 'involved', 'happened', 'obvious', 'attempt', 'james', 'told', 'living', 'chance', 'violence', 'wonder', 'including', 'etc', 'complete', 'save', 'voice', 'coming', 'murder', 'anyway', 'group', 'daughter', 'looked', 'age', 'please', 'type', 'itbr', 'alone', 'experience', 'simple', 'none', 'god', 'number', 'score', 'exactly', 'slow', 'shown', 'happen', 'ok', 'ago', 'lets', 'interest', 'whose', 'taken', 'brother', 'usually', 'serious', 'david', 'across', 'stop', 'cinematography', 'somewhat', 'running', 'hours', 'annoying', 'sad', 'opening', 'song', 'known', 'ends', 'musical', 'usual', 'possible', 'finds', 'career', 'wish', 'hit', 'yourself', 'released', 'started', 'huge', 'gore', 'relationship', 'seriously', 'scary', 'jokes', 'change', 'saying', 'order', 'crap', 'mostly', 'shots', 'reality', 'ridiculous', 'cut', 'today', 'robert', 'english', 'taking', 'major', 'episodes', 'hilarious', 'novel', 'cool', 'female', 'body', 'talking', 'opinion', '4', 'call', 'apparently', 'directors', 'strange', 'due', 'basically', '5', 'important', 'hero', 'supporting', 'clearly', 'power', 'knows', 'documentary', 'knew', 'happy', 'events', 'view', 'turned', 'husband', 'songs', 'talent', 'level', 'arent', 'king', 'british', 'room', 'easily', 'tells', 'single', 'local', 'rating', 'attention', 'word', 'moviebr', 'bring', 'words', 'problems', 'cheap', 'whats', 'modern', 'silly', 'television', 'beyond', 'sequence', 'whether', 'disappointed', 'light', 'jack', 'falls', 'sets', 'four', 'future', 'five', 'similar', 'paul', 'miss', 'country', 'needs', 'appears', 'romantic', 'giving', 'upon', 'earth', 'viewers', 'comic', 'richard', 'predictable', 'george', 'talk', 'entertainment', 'within', 'review', 'havent', 'feels', 'nearly', 'mention', 'message', 'enjoyable', 'animation', 'bunch', 'filmbr', 'theater', 'lots', 'lady', 'storyline', 'rock', 'add', 'actual', 'using', 'moving', 'points', 'above', 'middle', 'surprised', 'named', 'theme', 'mystery', 'herself', 'ten', 'dull', 'among', 'begins', 'comments', 'writer', 'ways', 'typical', 'fantastic', 'stay', 'showing', 'sequel', 'york', 'elements', 'easy', 'certain', 'thriller', 'team', 'tried', 'fall', 'effort', 'clear', 'near', 'avoid', 'release', 'hate', 'french', 'tale', 'famous', 'sorry', 'somehow', 'parents', 'means', 'straight', 'leads', 'peter', 'red', 'kept', 'working', 'buy', 'greatest', 'dialog', 'doubt', 'soundtrack', 'form', 'class', 'season', 'editing', 'sister', 'general', 'brought', 'weak', 'tom', 'filmed', 'figure', 'feature', 'oscar', 'hear', 'gone', 'whos', 'particular', 'material', 'check', 'viewing', 'learn', 'realistic', 'imagine', 'eventually', 'youve', 'eye', 'move', 'fast', 'atmosphere', 'reviews', 'decided', 'sequences', 'possibly', 'period', 'forget', 'lame', 'deal', 'third', 'premise', 'lee', 'follow', 'de', 'became', 'space', 'dance', 'wait', 'stand', 'indeed', 'japanese', 'zombie', 'sit', 'difficult', 'poorly', 'sexual', 'expected', 'die', 'whatever', 'writers', 'surprise', 'nor', 'crime', 'nature', 'rent', 'average', '80s', 'suspense', 'leaves', 'subject', 'okay', 'stage', 'killing', 'truth', 'believable', 'screenplay', 'needed', 'filmmakers', 'reading', 'note', 'meets', 'meet', 'dr', 'question', 'begin', 'boys', 'joe', 'romance', 'street', 'realize', 'forced', 'otherwise', 'emotional', 'memorable', 'unless', 'write', 'superb', 'shame', 'older', 'minute', 'interested', 'earlier', 'keeps', 'baby', 'weird', 'situation', 'disney', 'whom', 'footage', 'features', 'dramatic', 'credits', 'beauty', 'towards', 'dog', 'badly', 'ask', 'total', 'previous', 'hot', 'sounds', 'crazy', 'brings', 'comment', 'male', 'plenty', 'personal', 'worked', 'incredibly', 'plus', 'directing', 'society', 'quickly', 'perfectly', 'cheesy', 'admit', 'result', 'unique', 'deep', 'return', 'america', 'laughs', 'free', 'creepy', 'development', 'leading', 'appear', 'meant', 'hardly', 'open', 'brothers', '20', 'imdb', 'hands', 'b', 'apart', 'mark', 'various', 'casting', 'remake', 'effect', 'create', 'setting', 'christmas', 'potential', 'mess', 'bill', 'battle', 'background', 'scifi', 'monster', 'forward', 'powerful', 'portrayed', 'dream', 'inside', 'outside', '70s', 'fairly', 'business', 'la', 'manages', 'ideas', 'expecting', 'jane', 'fails', 'deserves', 'present', 'political', 'missing', 'attempts', 'twist', 'secret', 'fire', 'dumb', 'unlike', 'fighting', 'fantasy', 'pay', 'air', 'joke', 'gay', 'ben', 'william', 'recently', 'rich', 'front', 'nudity', 'married', 'further', 'masterpiece', 'reasons', 'copy', 'match', 'box', 'sadly', 'agree', 'acted', 'break', 'telling', 'talented', 'plain', 'western', 'success', 'cute', 'pure', 'villain', 'missed', 'incredible', 'odd', 'girlfriend', 'doctor', 'crew', 'following', 'caught', 'decides', 'cop', 'social', 'large', 'considering', 'waiting', 'sees', 'mentioned', 'members', 'uses', 'flat', 'popular', 'hold', 'ended', 'slightly', 'wasted', 'public', 'suddenly', 'pace', 'neither', 'compared', 'wrote', 'sweet', 'spent', 'kills', 'entirely', 'rate', 'intelligent', 'created', 'familiar', 'office', 'audiences', 'ultimately', 'cause', 'tension', 'scott', 'convincing', 'clever', 'bored', 'visual', 'party', 'escape', 'era', 'moves', 'cartoon', 'basic', 'credit', 'biggest', 'mary', 'list', 'revenge', 'laughing', 'fear', 'successful', 'recent', 'consider', 'spirit', 'island', 'trouble', 'spend', 'violent', 'positive', 'gun', 'choice', 'dancing', 'cover', 'books', 'appreciate', 'zombies', 'water', 'speak', 'science', 'former', 'died', 'cold', 'singing', 'filled', 'concept', 'younger', 'portrayal', '12', 'produced', 'value', 'solid', 'adult', 'state', 'exciting', 'common', 'bizarre', '8', 'werent', 'amount', 'walk', 'focus', 'animated', 'showed', 'language', 'effective', 'band', 'amusing', 'german', 'italian', 'producers', 'fit', 'follows', '7', 'van', 'runs', 'considered', 'impressive', 'impossible', 'decide', 'chemistry', 'cat', 'tone', 'won', 'pointless', 'company', '15', 'store', 'depth', 'barely', 'win', 'somewhere', 'control', 'studio', 'situations', 'prison', 'mad', 'sick', 'leaving', 'college', 'project', 'respect', 'force', 'changed', 'recommended', 'hair', 'surprisingly', 'aside', 'tony', 'starring', 'awesome', 'trip', 'century', 'longer', 'likes', 'generally', 'failed', 'shooting', 'planet', 'charming', 'slasher', 'involving', 'questions', 'honest', 'trash', 'thanks', 'immediately', 'literally', 'images', 'disturbing', 'accent', 'steve', 'spoilers', '30', 'values', 'utterly', 'bought', 'south', 'ghost', 'fake', 'touch', 'pictures', 'magic', 'jim', 'natural', 'conclusion', 'west', 'glad', 'sitting', 'ability', 'pathetic', 'honestly', 'frank', 'aspect', 'adaptation', 'computer', 'adventure', 'explain', 'normal', 'fair', 'culture', 'appearance', 'stick', 'personally', 'cult', 'camp', 'knowing', 'alive', 'tough', 'added', 'remains', 'rare', 'dad', 'catch', 'thinks', 'meaning', 'yeah', 'detective', 'sam', 'appeal', 'silent', 'humour', 'army', 'genius', 'beautifully', 'terms', 'managed', 'attack', 'walking', 'thank', 'taste', 'sexy', 'military', 'equally', 'standard', 'soldiers', 'smith', 'garbage', 'twists', 'subtle', 'london', 'harry', 'dreams', 'loves', 'journey', 'comedies', '100', 'pick', 'nowhere', 'terrific', 'touching', 'purpose', 'naked', 'complex', 'woods', 'nobody', 'likely', 'wild', 'channel', 'surely', 'mood', 'lovely', 'excuse', 'plan', 'master', 'fully', 'thus', 'narrative', 'chase', 'road', 'contains', 'cinematic', 'themes', 'fiction', 'constantly', 'central', 'unbelievable', 'outstanding', 'issues', 'youd', 'week', 'slowly', 'self', 'brain', 'painful', 'innocent', 'chris', 'batman', 'thrown', 'presented', 'pass', 'disappointing', 'presence', 'historical', 'marriage', 'date', 'christopher', 'animals', 'stunning', 'mysterious', 'laughable', 'charles', 'impression', 'hoping', 'besides', 'shoot', 'places', 'minor', 'costumes', 'club', 'mistake', 'critics', 'bottom', 'stands', 'makers', 'edge', 'details', 'sent', 'photography', 'indian', 'stewart', 'soul', 'justice', 'charm', 'makeup', 'door', 'aspects', '9', 'ride', 'law', 'heavy', 'finish', 'brief', 'boss', 'vampire', 'mainly', 'government', 'exception', 'feelings', 'climax', 'throw', 'suppose', 'support', 'manner', 'festival', 'color', 'train', 'scenery', 'pieces', 'paris', 'opportunity', 'hey', 'gang', 'expectations', 'element', 'cry', 'names', 'loud', 'filming', 'charlie', 'acts', 'victims', 'rated', 'bother', 'track', 'puts', 'fascinating', '6', 'smart', 'serial', 'falling', 'changes', 'award', 'intended', 'emotions', 'drawn', 'available', 'tired', 'victim', 'suggest', 'henry', 'speaking', 'include', 'church', 'disappointment', 'blue', 'twice', 'hasnt', 'likable', 'emotion', 'confused', 'building', 'hotel', 'followed', 'wow', 'compelling', 'students', 'motion', 'green', 'giant', 'appeared', 'image', 'everybody', 'dies', 'developed', 'ahead', 'pain', 'mans', 'laughed', 'bruce', 'lacks', 'kelly', 'gorgeous', 'approach', 'share', 'impact', 'difference', 'supposedly', 'offer', 'million', 'hurt', 'forever', 'fellow', 'fresh', 'bed', 'wondering', 'trailer', 'moral', 'merely', 'proves', 'jerry', 'happening', 'confusing', 'shock', 'helps', 'funniest', 'finding', 'relationships', 'putting', 'notice', 'grade', 'drive', 'billy', 'bar', 'answer', 'adults', 'system', 'random', 'student', 'producer', 'mix', 'key', 'creative', 'spoiler', 'numbers', 'mediocre', 'delivers', 'christian', 'zero', 'opera', 'noir', 'murders', 'lighting', 'jones', 'damn', 'provides', 'born', 'paid', 'absolute', 'thoroughly', 'summer', 'timebr', 'negative', 'lived', 'drug', 'content', 'addition', 'seemingly', 'reminded', 'ms', 'impressed', 'fell', 'event', 'becoming', 'alien', 'tragedy', 'park', 'offers', 'land', 'gem', 'flying', 'flicks', 'childhood', 'boyfriend', 'lover', 'imagination', 'hospital', 'attractive', 'stuck', 'lose', 'williams', 'race', 'holes', 'flaws', 'extreme', 'al', 'tragic', 'ii', 'ugly', 'six', 'rented', 'page', 'nasty', 'hidden', 'arthur', 'americans', 'shouldnt', 'martin', 'held', 'agent', '90', 'spot', 'adds', 'standards', 'rape', 'intense', 'folks', 'alan', 'ray', 'pull', 'faces', 'detail', 'beat', 'asks', 'artistic', 'afraid', 'turning', 'therefore', 'seconds', 'filmmaker', 'super', 'step', 'porn', 'games', 'latter', 'industry', 'davis', 'collection', 'states', 'shocking', 'forgotten', 'favourite', 'describe', 'affair', 'picked', 'onto', 'angry', 'teenage', 'seven', 'redeeming', 'ready', 'led', 'brian', 'actresses', 'mom', 'dirty', 'design', 'count', 'deliver', 'area', 'wooden', 'soldier', 'information', 'compare', 'queen', 'carry', 'allowed', 'thin', 'struggle', 'lord', 'willing', 'stephen', 'news', 'inspired', 'includes', 'chinese', 'allen', 'personality', 'moved', 'location', 'jason', 'apartment', 'helped', 'ground', 'fashion', 'desperate', 'deeply', 'cliché', 'animal', 'wonderfully', 'martial', 'intelligence', 'bond', 'wars', 'quick', 'listen', 'castle', 'uncle', 'professional', 'member', 'grace', 'don', 'direct', 'criminal', 'trust', 'scientist', 'rarely', 'food', 'cops', 'captain', 'began', 'todays', 'creature', 'clothes', 'cgi', 'humans', 'worthy', 'phone', 'mental', 'introduced', 'double', 'wearing', 'theatre', 'necessary', 'independent', 'comedic', 'realized', 'plane', 'fox', 'anymore', 'allow', 'unusual', 'treat', 'technical', 'tears', 'superior', 'drugs', 'commentary', 'apparent', 'physical', 'energy', 'dying', 'wall', 'provide', 'tim', 'sky', 'ship', 'normally', 'epic', 'desire', 'continue', 'nightmare', 'danny', 'stone', 'sight', 'remarkable', 'mouth', 'douglas', 'arts', 'filmmaking', 'accident', 'scared', 'returns', 'powers', 'limited', 'station', 'ring', 'reminds', 'holds', 'heroes', 'bloody', 'accept', 'witch', 'suspect', 'search', 'pleasure', 'engaging', '60s', 'wedding', 'warning', 'surprising', 'intriguing', 'brutal', 'actions', 'wanting', 'teacher', 'machine', 'hated', 'build', 'according', 'whatsoever', 'russian', 'fred', 'disaster', 'asked', 'academy', 'unnecessary', 'sleep', 'skip', 'pacing', 'grand', 'clichés', 'johnny', 'finished', 'constant', 'vision', 'bits', 'andy', 'religious', 'nicely', 'joan', 'ie', 'extra', 'anybody', 'suicide', 'sat', 'process', 'originally', 'legend', 'heres', 'artist', 'passion', 'lies', 'growing', 'ed', 'absurd', 'roll', 'monsters', 'blame', 'anywhere', 'toward', 'suit', 'media', 'lovers', 'killers', 'joy', 'gotten', 'ladies', 'faith', 'explanation', 'dangerous', 'watchable', 'players', 'met', 'instance', 'eddie', 'deserve', 'unknown', 'memory', 'kevin', 'jeff', 'dick', 'winning', 'whilst', 'villains', 'somebody', 'quiet', 'higher', 'hadnt', 'torture', 'starting', 'smile', 'nick', 'capture', 'accurate', '40', 'pilot', 'jump', 'heads', 'cars', 'superman', 'hopes', 'heaven', 'creating', 'jr', 'guns', 'featuring', 'fail', 'exist', 'dressed', 'community', 'adam', 'river', 'responsible', 'teen', 'friendship', 'fights', 'worlds', 'vs', 'tarzan', 'saved', 'record', 'pulled', 'prince', 'england', 'moon', 'months', 'keeping', 'jesus', 'european', 'understanding', 'terribly', 'taylor', 'reviewers', 'lowbudget', 'jean', 'treated', 'mixed', 'manage', 'kinda', 'explained', 'whenever', 'radio', 'numerous', 'memories', 'knowledge', 'hits', 'finest', 'thembr', 'loving', 'judge', 'delightful', 'private', 'price', 'pop', 'player', 'peoples', 'officer', 'lacking', 'jackson', 'issue', 'gene', 'fat', '50', 'weve', 'unfunny', 'bland', 'vhs', 'sucks', 'psychological', 'prove', 'mike', 'forces', 'eat', 'discover', 'deserved', 'screaming', 'pretentious', 'loose', 'japan', 'horse', 'floor', 'witty', 'streets', 'sign', 'regular', 'ordinary', 'loss', 'included', 'field', 'spanish', 'opposite', 'heroine', 'empty', 'drunk', 'driving', 'broken', 'saving', 'portray', 'loses', 'humanity', 'dated', 'cage', 'cable', 'skills', 'opens', 'noticed', 'naturally', 'conflict', 'bright', 'cuts', 'c', 'bigger', 'aware', 'talents', 'locations', 'discovered', 'calls', 'breaks', 'wind', 'visually', 'partner', 'international', 'essentially', 'deals', 'dealing', 'continues', 'blonde', 'youth', 'werewolf', 'visit', 'theyve', 'soap', 'morning', 'jimmy', 'humorous', 'fate', 'captured', 'scream', 'morgan', 'mine', 'magnificent', 'length', 'golden', 'curious', 'ball', '1010', 'traditional', 'realism', 'plots', 'miles', 'kate', 'gold', 'gags', 'current', 'connection', 'concerned', 'shallow', 'results', 'received', 'occasionally', 'nonsense', 'genuine', 'debut', 'sing', 'sean', 'satire', 'rubbish', 'perspective', 'murdered', 'frankly', 'allows', 'advice', 'versions', 'genuinely', 'below', 'anthony', 'national', 'learned', 'gary', 'bob', 'washington', 'behavior', 'proved', 'mrs', 'lesson', 'kong', 'grew', 'blind', 'bank', '90s', '1950s', 'welles', 'stock', 'segment', 'santa', 'rob', 'revealed', 'mission', 'fathers', 'corny', 'context', 'vampires', 'underrated', 'unable', 'ultimate', 'sudden', 'sheer', 'keaton', 'cameo', 'visuals', 'unexpected', 'shop', 'meanwhile', 'formula', 'ford', 'favor', 'develop', 'albert', 'thisbr', 'steal', 'owner', 'jennifer', 'himbr', 'finale', 'survive', 'study', 'remembered', 'references', 'reach', 'luck', 'harris', 'efforts', 'ann', 'ages', 'window', 'village', 'singer', 'logic', 'identity', 'gonna', 'eric', 'decade', 'cross', 'brilliantly', 'sea', 'program', 'passed', 'ice', 'discovers', 'awkward', 'wise', 'utter', 'strength', 'spectacular', 'desert', 'crappy', 'steven', 'standing', 'majority', 'grant', 'gangster', 'dan', 'candy', 'types', 'stereotypes', 'sisters', 'sake', 'leader', 'flashbacks', 'existence', 'delivered', 'board', 'awards', 'creates', 'bet', 'robin', 'relate', 'reaction', 'ran', 'lucky', 'lake', 'insane', 'caused', 'trek', 'sucked', 'pair', 'painfully', 'meeting', 'gratuitous', 'graphic', 'foreign', 'dreadful', 'daughters', 'speed', 'relief', 'practically', 'pleasant', 'edited', 'devil', 'travel', 'fault', 'families', 'emotionally', 'boat', 'technology', 'nevertheless', 'endless', 'author', 'twenty', 'thomas', 'site', 'simon', 'reviewer', 'overly', 'native', 'decision', 'comparison', 'seasons', 'portrays', 'freedom', 'failure', 'described', 'combination', 'barbara', 'assume', 'anime', 'ancient', 'aka', 'test', 'rules', 'proper', 'president', 'feet', 'attitude', 'wide', 'vehicle', 'treatment', 'parody', 'hearing', 'brown', 'stopped', 'sell', 'range', 'portraying', 'howard', 'foot', 'eating', 'choose', 'buddy', 'bear', 'asking', 'uk', 'marry', 'luke', 'learns', 'laughter', 'hitler', 'halloween', 'executed', 'drew', 'chosen', 'capable', 'believes', 'tape', 'lynch', 'largely', 'involves', 'gory', 'fill', 'excited', 'evening', 'daniel', 'commercial', 'anna', 'allbr', 'wood', 'religion', 'recall', 'produce', 'grow', 'classics', 'broadway', 'wit', 'theatrical', 'product', 'model', 'victor', 'unrealistic', 'theaters', 'sheriff', 'parker', 'kick', 'haunting', 'entertained', 'contrived', 'center', '50s', 'suffering', 'strongly', 'storybr', 'ruined', 'round', 'rise', 'levels', 'depressing', 'clue', 'sequels', 'rescue', 'r', 'joseph', 'irritating', 'freddy', 'extras', 'd', 'contrast', 'built', 'appealing', 'woody', 'rose', 'onebr', 'heck', 'handsome', 'costs', 'claim', 'sympathetic', 'sports', 'shakespeare', 'research', 'matt', 'losing', 'individual', 'destroy', '11', 'talks', 'protagonist', 'generation', 'evidence', 'embarrassing', 'disgusting', 'clean', 'captures', 'vote', 'thatbr', 'tend', 'post', 'patrick', 'matters', 'hill', 'facts', 'dry', 'chief', 'chick', 'appropriate', 'hunter', 'hanging', 'fame', 'canadian', 'alex', 'voices', 'virtually', 'naive', 'hopefully', 'grown', 'football', 'exploitation', 'bringing', 'asian', 'walks', 'training', 'scare', 'roy', 'relatively', 'obsessed', 'jackie', 'horribly', 'haunted', 'costume', 'cares', 'thoughts', 'steals', 'spoil', 'saturday', 'safe', 'promise', 'priest', 'pity', 'mask', 'lousy', 'louis', 'france', 'fits', 'convinced', 'bomb', 'walter', 'teenagers', 'insult', 'frame', 'cost', 'correct', 'till', 'teenager', 'ryan', 'oliver', 'mebr', 'dogs', 'crowd', 'creatures', 'wellbr', 'send', 'satisfying', 'initial', 'halfway', 'fly', 'excitement', 'dubbed', 'depicted', 'winner', 'united', 's', 'remain', 'gordon', 'europe', 'cinderella', 'cash', 'angel', 'amateurish', '1970s', 'tiny', 'texas', 'tedious', 'nancy', 'lower', 'influence', 'holding', 'hide', 'germany', 'contemporary', 'anne', 'weekend', 'unlikely', 'unfortunate', 'substance', 'soft', 'psycho', 'nominated', 'lewis', 'cowboy', 'circumstances', 'asleep', 'viewed', 'touches', 'presents', 'marie', 'lawyer', 'flesh', 'continuity', 'closer', 'bodies', 'baseball', 'witness', 'serves', 'provided', 'max', 'f', 'drag', 'danger', 'australian', '810', 'trilogy', 'suffers', 'shocked', 'reporter', 'handled', 'fool', 'cartoons', 'brave', 'amateur', 'weeks', 'wayne', 'surreal', 'structure', 'source', 'sons', 'ruin', 'roger', 'repeated', 'refreshing', 'fare', 'category', 'supernatural', 'seat', 'politics', 'plans', 'offensive', 'latest', 'hunt', 'fu', 'display', 'deaths', 'chose', 'africa', 'accidentally', 'welcome', 'warm', 'surprises', 'studios', 'sinatra', 'robot', 'promising', 'pile', 'north', 'market', 'angles', 'target', 'speaks', 'realizes', 'qualities', 'previously', 'overthetop', 'colors', 'claims', 'bugs', 'harsh', 'granted', 'experiences', 'edward', 'deadly', 'convince', 'adventures', 'accents', 'storytelling', 'factor', 'designed', 'covered', 'artists', 'wouldve', 'whoever', 'veteran', 'universal', 'speech', 'skin', 'service', 'rental', 'recognize', 'movement', 'lesbian', 'hall', 'draw', 'believed', 'victoria', 'routine', 'professor', 'mainstream', 'highlight', 'degree', 'uninteresting', 'rain', 'propaganda', 'occasional', 'mistakes', 'kim', 'hat', 'enter', 'columbo', 'walked', 'twisted', 'technically', 'sympathy', 'struggling', 'peace', 'outbr', 'minds', 'magical', 'guilty', 'directly', 'aliens', 'nude', 'massive', 'kinds', 'invisible', 'friday', 'focused', 'explains', 'downright', 'combined', 'breaking', 'teens', 'section', 'print', 'princess', 'paper', 'inner', 'committed', '710', 'remotely', 'offered', 'narration', 'j', 'gritty', 'donald', 'ass', 'suspenseful', 'spends', 'sorts', 'prime', 'multiple', 'moore', 'irish', 'featured', 'experienced', 'enemy', 'atrocious', 'universe', 'treasure', 'sharp', 'reveal', 'regret', 'lonely', 'legendary', 'insight', 'frightening', 'express', 'execution', 'variety', 'security', 'reputation', 'performed', 'hong', 'forgettable', 'figured', 'exact', 'dollars', 'anger', '25', 'waybr', 'surface', 'stolen', 'rings', 'prior', 'path', 'passing', 'herebr', 'forest', 'figures', 'fictional', 'false', 'dozen', 'crash', 'bothered', 'birth', 'abuse', 'abandoned', '1980s', 'theory', 'subtitles', 'spy', 'pulls', 'powell', 'hired', 'ghosts', 'fairy', 'eight', 'darkness', 'crying', 'conversation', '13', 'von', 'statement', 'russell', 'reveals', 'required', 'paint', 'paced', 'melodrama', 'isbr', 'erotic', 'emma', 'cutting', 'core', 'anderson', 'wilson', 'urban', 'trapped', 'terror', 'stays', 'stayed', 'significant', 'mountain', 'hed', 'gas', 'effectively', 'drop', 'demons', 'blow', 'worthwhile', 'slapstick', 'paying', 'grim', 'crude', '14', 'rights', 'proud', 'mgm', 'mere', 'listening', 'jon', 'focuses', 'dean', 'clark', 'buying', 'wear', 'spite', 'sir', 'quest', 'necessarily', 'lights', 'bmovie', 'beach', 'african', 'account', 'unconvincing', 'scale', 'jobs', 'heavily', 'grave', 'forth', 'titanic', 'sunday', 'scares', 'network', 'julia', 'facial', 'everywhere', 'destroyed', 'department', 'delivery', 'cruel', 'clichéd', 'childrens', 'caine', 'bus', 'andor', 'amazed', 'afternoon', '1930s', 'vietnam', 'scenario', 'san', 'murphy', 'metal', 'matrix', 'imagery', 'driven', 'desperately', 'closing', 'changing', 'alright', 'thankfully', 'sounded', 'skill', 'sensitive', 'rule', 'ron', 'reminiscent', 'position', 'placed', 'mothers', 'midnight', 'mature', 'junk', 'idiot', 'forgot', 'flashback', 'favorites', 'faithful', 'fabulous', 'device', 'code', 'blockbuster', 'belief', 'alice', 'suffer', 'stereotypical', 'revolution', 'pitt', 'novels', 'mexican', 'interview', 'ignore', 'extraordinary', 'driver', 'campy', 'aint', '110', 'views', 'summary', 'sleeping', 'settings', 'seek', 'musicals', 'lifetime', 'happiness', 'greater', 'examples', 'dude', 'deeper', 'california', 'beloved', 'angle', 'amazingly', 'understood', 'sarah', 'renting', 'prefer', 'pacino', 'notorious', 'initially', 'inept', 'helping', 'fourth', 'dennis', 'criminals', 'court', 'burns', 'blah', 'beast', 'achieve', 'teeth', 'susan', 'sitcom', 'rolling', 'regarding', 'pregnant', 'lifebr', 'learning', 'league', 'depiction', 'breathtaking', 'brad', 'bourne', 'rip', 'raw', 'mexico', 'lisa', 'larry', 'jungle', 'endbr', 'couldve', 'convey', 'complicated', 'china', 'bore', 'table', 'quirky', 'purely', 'picks', 'kung', 'indie', 'format', 'entertain', 'encounter', 'cultural', 'starred', 'rough', 'rachel', 'prepared', 'ned', 'murderer', 'mildly', 'julie', 'freeman', 'expert', 'dragon', 'disbelief', 'description', 'decades', 'critical', 'calling', 'cabin', 'writerdirector', 'via', 'underground', 'touched', 'throws', 'throwing', 'status', 'serve', 'productions', 'notable', 'leslie', 'join', 'funnier', 'friendly', 'drinking', 'appreciated', 'subplot', 'onbr', 'introduction', 'flight', 'expression', 'everyday', 'dress', 'carries', 'basis', 'arms', 'answers', 'adding', 'task', 'strangely', 'raised', 'protect', 'honor', 'criticism', 'comical', 'bollywood', 'blown', 'base', 'againbr', 'wears', 'suck', 'succeeds', 'racist', 'kiss', 'intellectual', 'fallen', 'extent', 'caring', 'brooks', 'amongst', 'usa', 'truck', 'ted', 'sword', 'shadow', 'regard', 'raise', 'originality', 'inspiration', 'hoffman', 'foster', 'environment', 'claire', 'causes', 'carrying', 'carried', 'attempting', 'x', 'weapons', 'socalled', 'ripoff', 'protagonists', 'praise', 'michelle', 'maria', 'johnson', 'jessica', 'handle', 'enjoying', 'embarrassed', 'choices', 'charge', 'challenge', 'cell', 'cases', 'angels', '410', 'tales', 'spoof', 'sinister', 'sidney', 'shut', 'rogers', 'related', 'ludicrous', 'lazy', 'warned', 'turkey', 'southern', 'replaced', 'obnoxious', 'needless', 'lugosi', 'locked', 'ironic', 'gruesome', 'experiment', 'elizabeth', 'determined', 'breath', 'wins', 'westerns', 'sun', 'sleazy', 'screening', 'properly', 'pet', 'nowadays', 'lie', 'interpretation', 'escapes', 'daily', 'burt', 'aunt', 'trick', 'tradition', 'remote', 'obsession', 'jail', 'hardy', 'graphics', 'clips', 'chilling', 'blair', 'bbc', 'attacked', 'wave', 'warner', 'u', 'tight', 'stanley', 'served', 'scripts', 'remind', 'reference', 'laura', 'jumps', 'interviews', 'exists', 'essential', 'arrives', 'alas', 'stops', 'st', 'sold', 'punch', 'navy', 'marvelous', 'india', 'hitchcock', 'fortunately', 'contain', 'busy', 'timing', 'successfully', 'oddly', 'nonexistent', 'hills', 'goofy', 'goodbr', 'frequently', 'established', 'dollar', 'ashamed', '310', 'term', 'sum', 'stylish', 'rival', 'revolves', 'refuses', 'ratings', 'oscars', 'o', 'jewish', 'inspector', 'flawed', 'drives', 'balance', 'authentic', 'warn', 'upset', 'struggles', 'risk', 'nation', 'mirror', 'mindless', 'mentally', 'manager', 'legs', 'horrific', 'hence', 'guard', 'flow', 'che', 'andrews', 'tree', 'titles', 'sides', 'shower', 'riding', 'retarded', 'philip', 'par', 'overcome', 'hood', 'greatly', 'delight', 'comedian', 'bette', 'toy', 'tense', 'suspects', 'stomach', 'spoken', 'roberts', 'poignant', 'nonetheless', 'mob', 'mansion', 'lesser', 'lane', 'intentions', 'intensity', 'gods', 'cynical', 'bridge', 'attacks', 'albeit', 'wishes', 'topic', 'thousands', 'presentation', 'madness', 'lion', 'lessons', 'jay', 'husbands', 'fbi', 'expressions', 'cooper', 'controversial', 'buck', 'bitter', 'wealthy', 'wasting', 'vacation', 'thrilling', 'suffered', 'stupidity', 'stranger', 'seeking', 'personalities', 'opened', 'medical', 'lucy', 'glimpse', 'demon', 'confusion', 'chan', 'adapted', 'storm', 'scientists', 'pride', 'nazi', 'internet', 'hundreds', 'holmes', 'guessing', 'eg', 'dubbing', 'dinner', 'bound', '30s', 'whereas', 'uncomfortable', 'tracy', 'thief', 'text', 'shorts', 'shines', 'separate', 'perform', 'patient', 'mass', 'infamous', 'hint', 'happily', 'gross', 'dislike', 'courage', 'contact', 'broke', 'advantage', 'trite', 'sings', 'reed', 'performers', 'noble', 'miscast', 'miller', 'countries', 'corner', 'chases', 'chair', 'trial', 'suggests', 'shape', 'rocks', 'physically', 'mouse', 'millions', 'letting', 'innocence', 'horses', 'helen', 'elvis', 'east', 'credible', 'credibility', 'atmospheric', '910', '2006', '1960s', 'womans', 'tied', 'therebr', 'technique', 'sin', 'sexuality', 'reunion', 'racism', 'hundred', 'hole', 'glass', 'cook', 'consists', 'youbr', 'troubled', 'steps', 'portrait', 'pool', 'lying', 'lovable', 'gripping', 'grey', 'ensemble', 'develops', 'curse', 'crisis', 'cameos', 'badbr', '2000', 'torn', 'stretch', 'screenwriter', 'saves', 'ralph', 'oneliners', 'noted', 'meaningful', 'idiotic', 'holiday', 'hanks', 'concert', 'catholic', 'bo', 'bettie', 'bears', 'wwii', 'weapon', 'vincent', 'unforgettable', 'sentimental', 'searching', 'proof', 'plastic', 'neat', 'kurt', 'gain', 'exceptional', 'enjoyment', 'drink', 'accepted', 'toobr', 'thrillers', 'shed', 'imaginative', 'host', 'hiding', 'herbr', 'franchise', 'fish', 'entry', 'dig', 'dialogs', 'connected', 'belongs', 'attraction', 'spots', 'solve', 'sends', 'sandler', 'nine', 'lincoln', 'hoped', 'concerns', 'christ', 'card', 'annoyed', 'andrew', 'aired', 'worry', 'widmark', 'virgin', 'succeed', 'quote', 'object', 'n', 'lucas', 'jake', 'italy', 'guts', 'flaw', 'endearing', 'closely', 'assistant', 'arm', 'achieved', 'striking', 'repeat', 'redemption', 'profound', 'irony', 'homeless', 'hearts', 'ha', 'fortune', 'equal', 'encounters', 'eerie', 'dealt', 'crimes', 'cousin', 'colorful', 'checking', 'battles', 'bag', 'appearances', 'aged', 'videos', 'tune', 'tribute', 'tour', 'teach', 'sutherland', 'stanwyck', 'segments', 'persons', 'pat', 'oil', 'nights', 'nelson', 'neighborhood', 'mst3k', 'library', 'h', 'factory', 'dragged', 'dentist', 'covers', 'complaint', '1st', 'stan', 'snow', 'slight', 'pointed', 'ourselves', 'miniseries', 'hunting', 'hooked', 'hang', 'hamlet', 'essence', 'dear', 'cube', 'civil', 'bucks', 'believing', 'bat', 'thousand', 'surrounding', 'strikes', 'split', 'shoots', 'seagal', 'rush', 'pitch', 'pack', 'moviesbr', 'laid', 'knife', 'incoherent', 'health', 'glory', 'expensive', 'dare', 'countless', 'cheese', 'charisma', 'branagh', 'baker', 'appearing', '18', 'zone', 'workers', 'theyd', 'surrounded', 'stood', 'stealing', 'spending', 'matthau', 'massacre', 'lloyd', 'jeremy', 'dorothy', 'dancer', 'condition', 'competent', 'chasing', 'charismatic', 'chances', 'catherine', 'briefly', 'attempted', 'unintentionally', 'tons', 'terrifying', 'stunts', 'stronger', 'specific', 'shall', 'rushed', 'rochester', 'ripped', 'intention', 'horrendous', 'grows', 'fx', 'elsewhere', 'denzel', 'curtis', 'crafted', 'colour', 'birthday', 'attached', 'aforementioned', 'wing', 'wanna', 'trade', 'sullivan', 'sexually', 'setup', 'reactions', 'messages', 'individuals', 'hip', 'easier', 'betterbr', 'associated', 'admittedly', '80', 'university', 'tricks', 'requires', 'perfection', 'noise', 'month', 'magazine', 'le', 'guilt', 'gag', 'forgive', 'creators', 'burning', 'beating', 'arnold', '2001', 'wake', 'typically', 'stunt', 'stated', 'spike', 'silver', 'revelation', 'per', 'nose', 'luckily', 'increasingly', 'identify', 'homage', 'guest', 'goal', 'gift', 'dropped', 'drags', 'corrupt', '17', 'vague', 'strictly', 'represents', 'overrated', 'neck', 'kings', 'importance', 'ian', 'gotta', 'gothic', 'fired', 'faced', 'exercise', 'dramas', 'dawn', 'chuck', 'cats', 'cardboard', 'boredom', 'allowing', 'winter', 'walls', 'virus', 'techniques', 't', 'reynolds', 'ps', 'performing', 'painting', 'mild', 'medium', 'loser', 'killings', 'kidnapped', 'kicks', 'kane', 'instantly', 'importantly', 'hype', 'fitting', 'fifteen', 'enters', 'contract', 'commit', 'chaplin', 'camerawork', 'barry', 'sophisticated', 'row', 'relevant', 'pushed', 'presumably', 'jesse', 'horrors', 'handful', 'godfather', 'disagree', 'carefully', 'brando', 'boll', 'bobby', 'basement', '24', 'wonders', 'weight', 'thumbs', 'shining', 'sally', 'reallife', 'realise', 'pleased', 'plague', 'pie', 'partly', 'packed', 'nuclear', 'notch', 'letter', 'flash', 'eva', 'doors', 'brand', '45', 'wondered', 'tremendous', 'toilet', 'talked', 'superhero', 'silence', 'returning', 'resolution', 'pleasantly', 'overlooked', 'occurs', 'mustsee', 'marks', 'korean', 'hudson', 'hitting', 'heat', 'frustrated', 'executive', 'destruction', 'derek', 'continued', 'comics', 'buried', 'britain', 'admire', 'acceptable', 'worthless', 'superbly', 'strip', 'secretary', 'prevent', 'persona', 'listed', 'lab', 'jamie', 'inevitable', 'iii', 'fears', 'evident', 'competition', 'canada', 'bride', 'breasts', 'arrested', 'subplots', 'strike', 'stiff', 'spell', 'shy', 'relative', 'regardless', 'projects', 'press', 'picking', 'opposed', 'masters', 'larger', 'investigation', 'flawless', 'fatal', 'estate', 'doc', 'digital', 'citizen', 'carol', 'bush', 'bullets', 'boxing', 'bible', 'beings', 'attracted', 'accused', 'walken', 'struck', 'splendid', 'spiritual', 'someones', 'root', 'revealing', 'planning', 'outrageous', 'nazis', 'menacing', 'mafia', 'los', 'kudos', 'karloff', 'jumping', 'highlights', 'glover', 'directorial', 'closeups', 'burn', 'appalling', 'afterwards', '40s', '3d', 'useless', 'union', 'uninspired', 'thrills', 'suits', 'subsequent', 'spooky', 'sole', 'slightest', 'savage', 'remaining', 'precious', 'notes', 'logical', 'lacked', 'ironically', 'inspiring', 'hire', 'guide', 'genres', 'flynn', 'dvds', 'cup', 'conspiracy', 'characterization', 'brilliance', 'ambitious', '911', '2005', 'wes', 'watches', 'ward', 'twin', 'streisand', 'spoiled', 'souls', 'repetitive', 'repeatedly', 'reasonably', 'raped', 'pulling', 'photographed', 'notably', 'neighbor', 'morality', 'melodramatic', 'ken', 'installment', 'heston', 'francisco', 'elderly', 'documentaries', 'dire', 'depression', 'curiosity', 'creation', 'convoluted', 'clues', 'blob', 'aimed', 'accomplished', 'worldbr', 'wicked', 'wannabe', 'timothy', 'ticket', 'theyll', 'territory', 'tea', 'smooth', 'shortly', 'screams', 'samurai', 'rid', 'response', 'push', 'providing', 'poverty', 'overdone', 'minimal', 'loosely', 'jerk', 'intrigued', 'insulting', 'generous', 'forbidden', 'duke', 'drunken', 'draws', 'cox', 'con', 'cia', 'cared', 'border', 'bleak', 'achievement', 'timeless', 'spring', 'shadows', 'ritter', 'reduced', 'psychiatrist', 'non', 'neil', 'mile', 'mid', 'mel', 'jealous', 'hatred', 'gradually', 'futuristic', 'funnybr', 'filmsbr', 'failing', 'explore', 'emily', 'elvira', 'distant', 'definite', 'davies', 'darker', 'corpse', 'adams', '20th', 'wells', 'thirty', 'tall', 'sticks', 'shell', 'reasonable', 'piano', 'outcome', 'obscure', 'meat', 'manhattan', 'laurel', 'intent', 'goldberg', 'carpenter', 'captivating', 'blows', 'unbelievably', 'trap', 'spielberg', 'rap', 'pushing', 'nurse', 'motivation', 'mitchell', 'misses', 'knock', 'indians', 'improved', 'ignored', 'grandmother', 'gentle', 'elaborate', 'doctors', 'discussion', 'burton', 'beaten', 'argument', 'alike', 'ad', 'absence', 'turner', 'tunes', 'tortured', 'stole', 'spin', 'resembles', 'psychotic', 'norman', 'miserably', 'liberal', 'huh', 'fisher', 'farce', 'explicit', 'et', 'em', 'disease', 'dave', 'cruise', 'cried', 'contrary', 'connect', 'concerning', 'childish', 'cameras', 'brazil', 'beer', 'alexander', 'worried', 'waters', 'warrior', 'vicious', 'throat', 'threat', 'temple', 'string', 'sloppy', 'shoes', 'shark', 'returned', 'reached', 'ranks', 'purple', 'monkey', 'lou', 'kenneth', 'horrid', 'hardcore', 'glenn', 'fancy', 'extended', 'exaggerated', 'eve', 'displays', 'diamond', 'danes', 'currently', 'craig', 'complain', 'cole', 'builds', 'blend', 'affected', 'wreck', 'website', 'upbr', 'threw', 'swedish', 'sunshine', 'subjects', 'spoilersbr', 'spirits', 'sacrifice', 'prom', 'pretend', 'panic', 'ought', 'matthew', 'idiots', 'houses', 'hollow', 'fay', 'enjoys', 'distance', 'demands', 'dancers', 'consequences', 'charactersbr', 'carter', 'arrive', 'alltime', 'warren', 'triumph', 'smoking', 'robots', 'ridiculously', 'restaurant', 'receive', 'poster', 'photographer', 'overacting', 'hysterical', 'harder', 'fever', 'farm', 'eyre', 'drivel', 'drawing', 'broad', 'blank', 'beats', 'argue', 'smoke', 'size', 'scripted', 'progress', 'officers', 'movements', 'modesty', 'landscape', 'jet', 'groups', 'greek', 'dynamic', 'duo', 'conversations', 'burned', 'australia', 'annie', 'upper', 'trio', 'styles', 'staying', 'selling', 'scientific', 'ruth', 'recognized', 'popcorn', 'murderous', 'load', 'ireland', 'involvement', 'investigate', 'incident', 'hugh', 'holy', 'heroic', 'exposed', 'engaged', 'empire', 'dignity', 'devoted', 'daring', 'cusack', 'commercials', 'comfortable', 'carrey', 'buddies', 'broadcast', 'brains', 'anyways', 'vivid', 'translation', 'titled', 'threatening', 'symbolism', 'swear', 'superficial', 'selfish', 'secrets', 'rural', 'producing', 'proceedings', 'orders', 'offering', 'occur', 'newspaper', 'mountains', 'machines', 'lily', 'kitchen', 'journalist', 'joey', 'existed', 'escaped', 'dinosaurs', 'differences', 'critic', 'couples', 'choreography', 'cagney', 'brosnan', 'bands', 'astaire', 'areas', 'aging', '210', 'winters', 'uneven', 'tame', 'relies', 'rage', 'margaret', 'lips', 'innovative', 'gray', 'grab', 'explaining', 'ex', 'discovery', 'detailed', 'deliberately', 'clint', 'block', 'bite', 'bathroom', 'apes', '60', '2nd', '16', 'workbr', 'wealth', 'versus', 'unpleasant', 'twelve', 'timesbr', 'thugs', 'stiller', 'staff', 'soviet', 'signs', 'removed', 'possibility', 'perry', 'occurred', 'nearby', 'mildred', 'merit', 'mate', 'lighthearted', 'juvenile', 'intrigue', 'ingredients', 'implausible', 'imagined', 'hollywoods', 'folk', 'focusing', 'felix', 'editor', 'dialogues', 'dawson', 'causing', 'birds', 'bell', 'audio', '2004', 'web', 'watchbr', 'undoubtedly', 'travels', 'sidekick', 'showbr', 'sadness', 'sadistic', 'resemblance', 'primary', 'population', 'pays', 'overwhelming', 'onscreen', 'nightmares', 'meaningless', 'maker', 'lawrence', 'kirk', 'generic', 'furthermore', 'disturbed', 'defeat', 'damage', 'craft', 'conventional', 'combat', 'chain', 'catches', 'adequate', 'abilities', 'abc', '2003', 'w', 'unbearable', 'trees', 'ships', 'remarkably', 'pulp', 'primarily', 'portion', 'passes', 'narrator', 'lifestyle', 'karen', 'hurts', 'headed', 'flies', 'falk', 'explosion', 'eccentric', 'discuss', 'devoid', 'composed', 'clumsy', 'clothing', 'bin', 'banned', 'atlantis', 'altogether', '0', 'yesterday', 'winds', 'unintentional', 'thrill', 'surviving', 'spare', 'settle', 'secondly', 'react', 'official', 'maggie', 'liking', 'leg', 'jeffrey', 'itll', 'hitman', 'highest', 'hates', 'glorious', 'giallo', 'g', 'financial', 'explored', 'exotic', 'enormous', 'dracula', 'dozens', 'cuba', 'chaos', 'cameron', 'backdrop', 'antics', 'afford', '2002', 'urge', 'survival', 'smaller', 'shine', 'scheme', 'roman', 'represent', 'reaches', 'morebr', 'models', 'mixture', 'mickey', 'kapoor', 'gandhi', 'fond', 'doomed', 'disjointed', 'decisions', 'consistently', 'carl', 'blatant', 'bird', 'beneath', '1990s', 'wallace', 'walker', 'uwe', 'ups', 'unwatchable', 'slap', 'rank', 'rambo', 'props', 'paulie', 'outer', 'odds', 'notion', 'notbr', 'neighbors', 'mistaken', 'judging', 'hints', 'fighter', 'errors', 'edie', 'dutch', 'distracting', 'disc', 'describes', 'coherent', 'clown', 'cheating', 'cary', 'careers', 'brady', 'bold', 'vast', 'trailers', 'tommy', 'thick', 'tear', 'tap', 'survivors', 'subtlety', 'sport', 'specifically', 'senseless', 'sellers', 'scenebr', 'richards', 'possessed', 'offended', 'monkeys', 'kennedy', 'instant', 'influenced', 'impress', 'ideal', 'hideous', 'heartwarming', 'hal', 'garden', 'gangsters', 'freak', 'florida', 'everyones', 'enterprise', 'drops', 'directs', 'diane', 'dating', 'dances', 'contained', 'butt', 'brooklyn', 'blew', 'bedroom', 'april', 'amy', 'ah', 'advance', '3rd', 'wolf', 'whale', 'weakest', 'voight', 'toys', 'topless', 'ties', 'stellar', 'soccer', 'simplistic', 'seenbr', 'screenbr', 'revolutionary', 'relations', 'rebel', 'practice', 'peters', 'performer', 'montage', 'matches', 'loads', 'linda', 'lasted', 'jazz', 'introduces', 'guessed', 'frustration', 'explosions', 'etcbr', 'ego', 'desperation', 'depressed', 'dedicated', 'commented', 'classes', 'celluloid', 'blake', 'benefit', 'adorable', 'todd', 'tender', 'suited', 'succeeded', 'staged', 'shelf', 'seventies', 'satan', 'saga', 'ruthless', 'rooms', 'rick', 'principal', 'politically', 'philosophy', 'passionate', 'occasion', 'mysteries', 'miserable', 'method', 'loyal', 'leonard', 'justify', 'involve', 'immensely', 'illogical', 'honesty', 'holly', 'hammer', 'forms', 'flop', 'emphasis', 'eastwood', 'doll', 'developing', 'crush', 'countryside', 'coffee', 'claimed', 'circle', 'bare', 'backgrounds', 'awake', 'arrogant', 'wrestling', 'wasbr', 'unfolds', 'traveling', 'trashy', 'transformation', 'tracks', 'thoughtful', 'tad', 'synopsis', 'stress', 'solely', 'similarities', 'severe', 'recorded', 'realizing', 'planned', 'outfit', 'motives', 'melting', 'measure', 'lust', 'link', 'kicked', 'jonathan', 'interaction', 'hank', 'funeral', 'endure', 'endings', 'disappeared', 'disappear', 'destiny', 'considerable', 'command', 'chorus', 'bone', 'blues', 'wore', 'treats', 'stereotype', 'shirley', 'quotes', 'photos', 'orson', 'menace', 'lemmon', 'isolated', 'hbo', 'harvey', 'hamilton', 'ginger', 'facing', 'ease', 'displayed', 'dickens', 'cure', 'corruption', 'consistent', 'comparing', 'companion', 'chased', 'cards', 'avoided', 'authority', 'angeles', 'aid', 'agrees', 'yellow', 'waited', 'tongue', 'taught', 'switch', 'swimming', 'surfing', 'sits', 'similarly', 'scenesbr', 'satisfied', 'riveting', 'represented', 'report', 'purchase', 'preview', 'possibilities', 'moody', 'madefortv', 'lyrics', 'kidding', 'inventive', 'helicopter', 'grasp', 'goodness', 'formulaic', 'enemies', 'ellen', 'eighties', 'e', 'donna', 'dolls', 'colonel', 'celebrity', 'buffs', 'bonus', 'amanda', 'wished', 'widow', 'voiceover', 'vegas', 'user', 'terrorist', 'solo', 'snl', 'relation', 'prostitute', 'promised', 'onedimensional', 'nervous', 'myers', 'mario', 'march', 'judy', 'improve', 'hunters', 'handed', 'embarrassment', 'ears', 'duty', 'divorce', 'delivering', 'defend', 'combine', 'cliff', 'charlotte', 'cg', 'carrie', 'behave', 'akshay', '1999', 'wives', 'waves', 'valuable', 'unsettling', 'unhappy', 'transfer', 'suitable', 'reads', 'philosophical', 'parent', 'pages', 'oz', 'l', 'ignorant', 'horrifying', 'hook', 'godzilla', 'global', 'fix', 'crack', 'closet', 'closest', 'chess', 'buildings', 'blond', '1996', '1980', 'virginia', 'tonight', 'thru', 'stooges', 'stinker', 'snake', 'scottish', 'scores', 'sappy', 'reflect', 'reaching', 'painted', 'online', 'nicholson', 'motivations', 'maintain', 'lately', 'kingdom', 'inbr', 'inane', 'humble', 'hart', 'faster', 'engage', 'elegant', 'education', 'diana', 'destroying', 'corporate', 'buff', 'blacks', 'bebr', 'artificial', 'agents', 'affect', 'yelling', 'wet', 'wed', 'useful', 'understandable', 'tiresome', 'terry', 'stinks', 'stevens', 'staring', 'splatter', 'slave', 'shake', 'sentence', 'seed', 'secretly', 'scope', 'scarecrow', 'safety', 'rotten', 'rex', 'remarks', 'racial', 'questionable', 'pretending', 'potentially', 'plant', 'museum', 'miracle', 'miike', 'letters', 'lees', 'germans', 'fooled', 'earned', 'disappoint', 'conflicts', 'concern', 'coach', 'cleverly', 'centers', 'bullet', 'armed', 'airport', 'airplane', 'access', 'abysmal', 'wandering', 'trained', 'survived', 'slick', 'sandra', 'rocket', 'purchased', 'provoking', 'poetic', 'nostalgic', 'nicholas', 'mall', 'm', 'lay', 'jumped', 'iron', 'intentionally', 'inferior', 'hung', 'gadget', 'francis', 'firstly', 'finger', 'faults', 'exploration', 'elephant', 'dub', 'disneys', 'dinosaur', 'depicts', 'communist', 'civilization', 'campbell', 'brutally', 'blunt', 'blade', 'amounts', 'americas', 'alongside', 'alcoholic', 'advise', 'womens', 'wizard', 'willis', 'vulnerable', 'understated', 'troops', 'tie', 'sub', 'streep', 'stilted', 'steel', 'spoke', 'showcase', 'september', 'robbery', 'rising', 'rendition', 'raising', 'punk', 'proceeds', 'porno', 'pokemon', 'plight', 'patients', 'nomination', 'namely', 'mini', 'lengthy', 'lena', 'joined', 'illegal', 'guarantee', 'grinch', 'greedy', 'fonda', 'floating', 'ethan', 'edgar', 'convincingly', 'confidence', 'channels', 'beliefs', 'bath', 'arrived', 'arguably', 'advanced', 'abusive', '2007', 'wrapped', 'witches', 'visits', 'transition', 'spread', 'species', 'resort', 'relatives', 'pig', 'peoplebr', 'nonstop', 'morris', 'madonna', 'homosexual', 'gundam', 'fascinated', 'familys', 'downhill', 'dimensional', 'designs', 'construction', 'cinematographer', 'chicago', 'carradine', 'careful', 'cake', 'bottle', 'beatty', 'balls', 'ballet', 'attitudes', 'ape', 'agreed', 'advertising', 'accompanied', '70', '3000', '1940s', 'wound', 'worker', 'taxi', 'sue', 'simplicity', 'signed', 'shirt', 'satisfy', 'ruby', 'recognition', 'pops', 'parallel', 'nyc', 'niro', 'molly', 'macy', 'lowest', 'lit', 'limits', 'likewise', 'li', 'latin', 'junior', 'june', 'jenny', 'intimate', 'hopper', 'heartbreaking', 'frequent', 'foul', 'devils', 'demented', 'damon', 'copies', 'complexity', 'compelled', 'classical', 'cities', 'christians', 'cave', 'catchy', 'capturing', 'berlin', 'aids', '1972', 'ya', 'vengeance', 'v', 'tends', 'schools', 'robinson', 'prisoner', 'prequel', 'phantom', 'paltrow', 'opinions', 'olivier', 'nostalgia', 'nonsensical', 'mundane', 'mars', 'manipulative', 'losers', 'lone', 'khan', 'inappropriate', 'illness', 'hilariously', 'grandfather', 'gerard', 'georges', 'exceptionally', 'equivalent', 'eager', 'dreary', 'descent', 'der', 'del', 'daddy', 'crucial', 'chicks', 'cheated', 'challenging', 'bang', 'bakshi', 'babe', 'alternate', '1990', 'writes', 'witnesses', 'wishing', 'widely', 'wellknown', 'twilight', 'tomatoes', 'suspicious', 'shelley', 'seeks', 'scooby', 'restored', 'remakes', 'raymond', 'rat', 'pursuit', 'prisoners', 'poetry', 'pearl', 'overlook', 'ocean', 'muchbr', 'montana', 'misery', 'lol', 'lively', 'leo', 'incomprehensible', 'homer', 'excessive', 'edition', 'eaten', 'domestic', 'demand', 'cinemas', 'choreographed', 'chooses', 'chest', 'capital', 'boot', 'awe', 'appreciation', 'amitabh', '1968', 'wisdom', 'vaguely', 'suspend', 'square', 'smiling', 'sincere', 'simmons', 'seriesbr', 'royal', 'robbins', 'resources', 'progresses', 'prize', 'plotbr', 'plausible', 'performs', 'paranoia', 'opportunities', 'nations', 'methods', 'messed', 'masterful', 'mann', 'literature', 'legal', 'laws', 'landscapes', 'kicking', 'justin', 'invasion', 'introduce', 'incompetent', 'franco', 'experiments', 'enthusiasm', 'elm', 'doubts', 'desired', 'dalton', 'da', 'crocodile', 'constructed', 'conservative', 'calm', 'bumbling', 'brenda', 'blowing', 'belong', 'bela', 'basketball', 'awfully', 'wacky', 'viewings', 'trademark', 'tag', 'suffice', 'richardson', 'responsibility', 'resist', 'resident', 'recording', 'randomly', 'promises', 'polished', 'petty', 'nuts', 'mummy', 'mentions', 'mechanical', 'mayor', 'masterpieces', 'louise', 'loaded', 'kay', 'generations', 'feed', 'eitherbr', 'earl', 'distinct', 'creativity', 'craven', 'climactic', 'cd', 'borrowed', 'bacall', 'assigned', 'assault', 'arrival', '1983', 'wounded', 'witnessed', 'wholly', 'wendy', 'waitress', 'visible', 'unoriginal', 'underlying', 'unaware', 'troubles', 'terrorists', 'teachers', 'strangers', 'stones', 'stargate', 'standout', 'stale', 'spirited', 'solution', 'sneak', 'slaughter', 'sink', 'simpson', 'showdown', 'scrooge', 'ruins', 'receives', 'rangers', 'punishment', 'polanski', 'poem', 'pit', 'parties', 'operation', 'omen', 'marty', 'map', 'jaws', 'inevitably', 'improvement', 'icon', 'heights', 'greed', 'gifted', 'fury', 'fields', 'expressed', 'dust', 'dolph', 'creep', 'conceived', 'betty', 'attorney', 'attend', 'assumed', 'ashley', '–', 'willie', 'whoopi', 'warriors', 'warmth', 'unit', 'testament', 'teaching', 'straightforward', 'rats', 'randy', 'rabbit', 'quit', 'property', 'pot', 'overlong', 'offbr', 'muslim', 'mighty', 'mentioning', 'lumet', 'laughably', 'keith', 'iraq', 'iran', 'instinct', 'historically', 'gabriel', 'females', 'educational', 'edgy', 'contest', 'closed', 'chapter', 'businessman', 'bergman', 'angela', 'alfred', 'activities', 'acid', 'aboutbr', '1973', 'wouldbe', 'withbr', 'voiced', 'verhoeven', 'twins', 'tooth', 'tiger', 'swim', 'survivor', 'supported', 'stunned', 'spain', 'sid', 'rolled', 'rocky', 'popularity', 'pink', 'pamela', 'moronic', 'mistress', 'minutesbr', 'minimum', 'middleaged', 'meryl', 'merits', 'kubrick', 'irrelevant', 'imitation', 'household', 'hello', 'greg', 'grabs', 'garbo', 'funbr', 'fashioned', 'exposure', 'equipment', 'domino', 'depicting', 'christy', 'catching', 'button', 'bull', 'boom', 'alert', '13th', 'valley', 'uplifting', 'unseen', 'unreal', 'unpredictable', 'tribe', 'timon', 'suggested', 'subjected', 'stretched', 'spock', 'sounding', 'significance', 'shaw', 'shaky', 'seldom', 'rubber', 'romero', 'resulting', 'resemble', 'psychic', 'pressure', 'pierce', 'phony', 'noone', 'masses', 'marketing', 'loyalty', 'kyle', 'invented', 'integrity', 'heartfelt', 'fulci', 'fought', 'feelgood', 'exchange', 'eugene', 'empathy', 'doom', 'disliked', 'directions', 'despair', 'definition', 'daybr', 'cringe', 'confrontation', 'compassion', 'championship', 'cannibal', 'butler', 'bud', 'bay', 'astonishing', 'analysis', 'ambiguous', 'accuracy', '35', 'wrongbr', 'wretched', 'wifes', 'watson', 'unexpectedly', 'trail', 'stumbled', 'sopranos', 'simultaneously', 'roots', 'retired', 'remained', 'reflection', 'ramones', 'peak', 'patience', 'pants', 'palace', 'package', 'otherbr', 'othello', 'orleans', 'ollie', 'nicole', 'monk', 'metaphor', 'landing', 'lackluster', 'josh', 'interests', 'inability', 'immediate', 'hopeless', 'grayson', 'gather', 'furious', 'firm', 'fascination', 'expedition', 'drake', 'distribution', 'defined', 'defense', 'darren', 'costar', 'confess', 'comfort', 'cliche', 'checked', 'biography', 'austin', 'album', 'adaptations', '1984', 'victory', 'unfair', 'underneath', 'travesty', 'technicolor', 'sums', 'spacey', 'sixties', 'shanghai', 'roth', 'roommate', 'require', 'refused', 'reel', 'rave', 'raises', 'primitive', 'presenting', 'phil', 'pan', 'objective', 'newly', 'nail', 'marion', 'mankind', 'legacy', 'kissing', 'israel', 'hears', 'frightened', 'farrell', 'eastern', 'dixon', 'difficulties', 'dee', 'deceased', 'daniels', 'dana', 'creator', 'conditions', 'composer', 'companies', 'closeup', 'clip', 'claus', 'blast', 'antwone', 'alec', 'actingbr', 'abraham', 'yearsbr', 'wakes', 'vulgar', 'ustinov', 'unlikable', 'teaches', 'tastes', 'subpar', 'stark', 'specially', 'softcore', 'sissy', 'sharon', 'screens', 'scotland', 'rises', 'respected', 'replace', 'remade', 'reid', 'rates', 'raines', 'quietly', 'precisely', 'photo', 'passable', 'pal', 'owen', 'musicians', 'milk', 'maniac', 'maid', 'lundgren', 'karl', 'julian', 'joins', 'joel', 'interactions', 'glasses', 'gentleman', 'gender', 'frustrating', 'flair', 'fido', 'favour', 'experimental', 'dreck', 'discovering', 'dimension', 'desires', 'deranged', 'connery', 'comedians', 'coast', 'christianity', 'buffalo', 'barrymore', 'andre', 'abused', '1971', '1933', 'yard', 'widescreen', 'warming', 'wang', 'walsh', 'thingbr', 'tank', 'sunny', 'stuart', 'rude', 'rely', 'relax', 'reeves', 'nowbr', 'ninja', 'nerd', 'nathan', 'muddled', 'matched', 'literary', 'lands', 'inexplicably', 'hyde', 'griffith', 'graham', 'framed', 'examination', 'encourage', 'electric', 'dysfunctional', 'dresses', 'dose', 'correctly', 'characterbr', 'casts', 'carell', 'brutality', 'behaviour', 'awhile', 'audiencebr', 'assassin', 'aspiring', 'appropriately', 'amused', 'alcohol', 'adopted', 'wrap', 'wildly', 'visiting', 'tracking', 'tomorrow', 'teams', 'tacky', 'shouldve', 'shoddy', 'shared', 'sentinel', 'sentiment', 'sabrina', 'ross', 'roof', 'rifle', 'referred', 'purposes', 'provocative', 'preston', 'preposterous', 'prepare', 'premiere', 'positively', 'phrase', 'pg13', 'paradise', 'parade', 'ordered', 'musician', 'mode', 'masks', 'marshall', 'macarthur', 'lock', 'les', 'knocked', 'invites', 'hopkins', 'generated', 'frankenstein', 'fingers', 'filling', 'fest', 'femme', 'exposition', 'emperor', 'downey', 'credited', 'choppy', 'chicken', 'charged', 'bunny', 'bernard', 'automatically', 'amusement', 'alternative', 'additional', 'absent', '75', '1993', '1987', 'yearold', 'vice', 'vance', 'unfold', 'uncut', 'tube', 'translated', 'topnotch', 'swing', 'sung', 'spark', 'senses', 'rooney', 'romp', 'respective', 'releases', 'reign', 'region', 'refer', 'realised', 'posters', 'poison', 'murdering', 'moreover', 'morbid', 'mclaglen', 'madebr', 'loneliness', 'leon', 'ladder', 'items', 'insurance', 'hopelessly', 'hawke', 'hackneyed', 'greatness', 'glowing', 'fantasies', 'demise', 'deaf', 'counts', 'complaining', 'citizens', 'cattle', 'biko', 'beverly', 'babies', 'alicia', 'accomplish', 'youngest', 'wellwritten', 'weakness', 'trend', 'thoughtprovoking', 'skull', 'singers', 'silliness', 'shoulders', 'shares', 'russia', 'regarded', 'realm', 'pun', 'pitiful', 'objects', 'nephew', 'naughty', 'mtv', 'misleading', 'lush', 'laurence', 'kansas', 'invited', 'infected', 'indication', 'imaginable', 'ignorance', 'harm', 'handling', 'guests', 'grotesque', 'gambling', 'function', 'forty', 'fi', 'fed', 'eternal', 'ensues', 'deserted', 'costars', 'corpses', 'complaints', 'challenges', 'celebration', 'caricatures', 'bridget', 'bargain', 'alison', 'admirable', 'accepts', 'absurdity', 'abrupt', '19th', '1995', 'towns', 'threatens', 'suspension', 'skits', 'severely', 'servant', 'secondary', 'sci', 'respectively', 'reflects', 'recycled', 'recommendation', 'receiving', 'puppet', 'promote', 'pro', 'prey', 'phillips', 'partners', 'palance', 'owners', 'oldest', 'noises', 'nod', 'nicolas', 'muppets', 'minded', 'jews', 'insipid', 'iconic', 'ho', 'hk', 'hitlers', 'grief', 'evidently', 'drove', 'din', 'devices', 'depending', 'crystal', 'cruelty', 'cope', 'conveys', 'coincidence', 'chills', 'chainsaw', 'canyon', 'beside', 'asylum', 'affection', 'address', 'active', '1997', '1986', 'wilderness', 'weaknesses', 'visited', 'venture', 'underworld', 'understands', 'tyler', 'togetherbr', 'tasteless', 'sympathize', 'strongest', 'stores', 'standup', 'squad', 'shades', 'rita', 'reluctant', 'records', 'priceless', 'prejudice', 'posted', 'portrayals', 'policeman', 'paramount', 'outing', 'outfits', 'occasions', 'obligatory', 'nolan', 'minus', 'mill', 'mccoy', 'malone', 'lois', 'lifted', 'kumar', 'investigating', 'industrial', 'hughes', 'heros', 'heading', 'hammy', 'freaks', 'el', 'edit', 'disappears', 'deniro', 'damme', 'cue', 'crawford', 'conviction', 'conventions', 'conscience', 'comparisons', 'buster', 'burst', 'belushi', 'baldwin', 'authors', 'aim', 'affairs', 'acclaimed', 'acceptance', '73', '1970', '1936', 'wwe', 'trivia', 'tobr', 'thread', 'terrified', 'suitably', 'studying', 'steady', 'stages', 'spinal', 'sketch', 'shakespeares', 'selection', 'renaissance', 'rejected', 'redeem', 'psychology', 'programs', 'profanity', 'previews', 'predict', 'pointbr', 'phenomenon', 'penny', 'patricia', 'murray', 'muppet', 'morally', 'misguided', 'locals', 'labor', 'kolchak', 'interestingly', 'hers', 'heist', 'hapless', 'guaranteed', 'gregory', 'frankie', 'fog', 'fishing', 'filler', 'fiancé', 'explores', 'entitled', 'emerges', 'elses', 'ear', 'difficulty', 'designer', 'demonstrates', 'dates', 'darn', 'cassidy', 'caliber', 'bros', 'billed', 'attract', 'anywaybr', 'ants', '2008', '1989', '1979', '1978', 'zombi', 'worn', 'vital', 'visions', 'vibrant', 'vein', 'unexplained', 'tripe', 'soup', 'sooner', 'someday', 'snakes', 'slimy', 'sht', 'shouting', 'sending', 'rome', 'representation', 'reader', 'ratso', 'prominent', 'physics', 'pg', 'palma', 'orange', 'option', 'michaels', 'marvel', 'marries', 'iv', 'insists', 'inconsistent', 'hippie', 'harold', 'harmless', 'guitar', 'gems', 'forcing', 'flashy', 'filth', 'feminist', 'eats', 'dud', 'discussing', 'diehard', 'despicable', 'deleted', 'cream', 'conclude', 'communicate', 'commander', 'clock', 'claustrophobic', 'clarke', 'cancer', 'betrayal', 'beatles', 'basinger', 'banal', 'assuming', 'anticipation', 'agenda', 'winchester', 'welldone', 'vader', 'unrelated', 'transformed', 'tierney', 'tempted', 'studies', 'springer', 'sox', 'slice', 'sirk', 'shootout', 'route', 'rod', 'rhythm', 'pounds', 'placebr', 'mentality', 'martha', 'lindsay', 'kungfu', 'knight', 'kitty', 'jacksons', 'ingenious', 'immature', 'housewife', 'flowers', 'europa', 'downbr', 'depends', 'delicate', 'danish', 'crazed', 'considerably', 'clueless', 'clan', 'claiming', 'circus', 'champion', 'casual', 'cannon', 'bread', 'blatantly', 'bike', 'biased', 'befriends', 'wings', 'wellmade', 'voted', 'towers', 'tail', 'symbolic', 'stumbles', 'soso', 'smiles', 'shortcomings', 'schlock', 'sassy', 'rukh', 'rolebr', 'riot', 'repeating', 'remove', 'recognizable', 'quinn', 'pete', 'paxton', 'mirrors', 'millionaire', 'melody', 'meg', 'marlon', 'limit', 'lifeless', 'legends', 'kathryn', 'iq', 'inhabitants', 'inexplicable', 'hokey', 'historic', 'height', 'grudge', 'grainy', 'glamorous', 'gina', 'gear', 'fuller', 'foxx', 'fontaine', 'fluff', 'fifty', 'exploring', 'ethnic', 'dukes', 'dressing', 'detectives', 'defeated', 'coupled', 'connections', 'co', 'charlton', 'challenged', 'carla', 'campaign', 'boston', 'bend', 'awaybr', 'audrey', 'altman', 'allens', 'agency', 'adolescent', 'addicted', 'vocal', 'uniformly', 'tunnel', 'trials', 'ton', 'thompson', 'swept', 'surgery', 'static', 'stairs', 'sorely', 'shopping', 'serving', 'screwed', 'screenwriters', 'satirical', 'rapist', 'praised', 'partially', 'parsons', 'paintings', 'outright', 'offbeat', 'novak', 'nemesis', 'minority', 'las', 'keen', 'item', 'institution', 'independence', 'incidentally', 'hangs', 'handles', 'freddys', 'firing', 'feeding', 'familybr', 'exceptions', 'esther', 'employed', 'drivein', 'disgusted', 'disguise', 'deserving', 'departure', 'coup', 'couch', 'controlled', 'continually', 'computers', 'chuckle', 'childs', 'charms', 'boyle', 'bars', 'backs', 'assassination', 'ambition', 'ace', '23', 'wax', 'toronto', 'token', 'tip', 'thrilled', 'threatened', 'sugar', 'shoulder', 'ripping', 'preferred', 'preachy', 'posey', 'pacific', 'outdated', 'northern', 'newer', 'neurotic', 'natives', 'nails', 'messy', 'mercy', 'melissa', 'macho', 'kidman', 'inspire', 'insightful', 'hilarity', 'hearted', 'hack', 'girlfriends', 'gate', 'garner', 'firmly', 'feat', 'farfetched', 'elite', 'earn', 'dylan', 'duck', 'disastrous', 'dirt', 'destroys', 'debate', 'curly', 'commenting', 'colin', 'cheer', 'centre', 'cassavetes', 'camcorder', 'bully', 'bridges', 'brendan', 'boxer', 'bowl', 'bondage', 'bogus', 'bates', 'bacon', 'artwork', 'artsy', 'arthouse', 'accurately', '4th', '1988', '1981', 'yeti', 'windows', 'wheres', 'vile', 'vain', 'unlikeable', 'uma', 'triangle', 'traffic', 'topics', 'suggestion', 'subtly', 'strings', 'steele', 'stalker', 'speeches', 'somethingbr', 'sleeps', 'sincerely', 'sharing', 'shaking', 'rooting', 'refuse', 'readers', 'predecessor', 'organized', 'obtain', 'norm', 'neatly', 'mutual', 'mayhem', 'males', 'liners', 'leigh', 'layers', 'kline', 'info', 'hides', 'healthy', 'harrison', 'guinness', 'gillian', 'fist', 'fade', 'excess', 'evolution', 'entered', 'engrossing', 'endingbr', 'election', 'duration', 'dudley', 'doo', 'donebr', 'disorder', 'destined', 'describing', 'demonic', 'containing', 'concepts', 'completed', 'chavez', 'centered', 'cartoonish', 'brooding', 'boringbr', 'boasts', 'bent', 'audition', 'anton', '22', '1976', '1969', '1000', 'woo', 'wig', 'weather', 'weaker', 'wanders', 'vastly', 'undead', 'triple', 'ta', 'stopping', 'stack', 'sometime', 'sobr', 'skit', 'seedy', 'saint', 'rope', 'reruns', 'rendered', 'relentless', 'refers', 'raj', 'quaid', 'punches', 'profession', 'politician', 'pole', 'originals', 'nope', 'newman', 'mesmerizing', 'masterfully', 'mannerisms', 'loretta', 'lifes', 'leaders', 'jess', 'injured', 'hungry', 'hugely', 'hires', 'helpless', 'helpful', 'hartley', 'guards', 'genie', 'gal', 'frances', 'exquisite', 'elevator', 'des', 'deny', 'dazzling', 'damaged', 'critique', 'christine', 'carmen', 'bulk', 'boris', 'beware', 'authorities', 'applaud', 'anyones', 'affects', 'advertised', '1945', 'wendigo', 'users', 'unsuspecting', 'tower', 'tops', 'thunderbirds', 'tenant', 'tarantino', 'stunningly', 'strengths', 'statue', 'startling', 'stare', 'stallone', 'shorter', 'scoop', 'scariest', 'rides', 'restrained', 'residents', 'realities', 'randolph', 'racing', 'publicity', 'proving', 'preparing', 'passengers', 'owes', 'nut', 'nina', 'myth', 'motive', 'mixing', 'min', 'lukas', 'luis', 'lift', 'lauren', 'lasts', 'lasting', 'knowbr', 'knightley', 'jared', 'itselfbr', 'internal', 'ingrid', 'hulk', 'goodbye', 'gained', 'fifties', 'fastpaced', 'exploits', 'excellently', 'error', 'emerge', 'duvall', 'dropping', 'detract', 'demanding', 'crashes', 'contempt', 'conrad', 'cliches', 'chronicles', 'choosing', 'cbs', 'carey', 'candidate', 'btw', 'breed', 'bow', 'behold', 'backwards', 'alvin', 'alley', 'akin', 'activity', '\\x85', 'zizek', 'youthful', 'wardrobe', 'votes', 'vanessa', 'valentine', 'tokyo', 'timberlake', 'tara', 'suburban', 'storys', 'spree', 'soylent', 'sniper', 'sleaze', 'sinking', 'servants', 'screw', 'referring', 'rapidly', 'radical', 'puerto', 'promptly', 'poker', 'origins', 'origin', 'nolte', 'netflix', 'net', 'mutant', 'modest', 'misfortune', 'minister', 'miami', 'mail', 'macabre', 'lovebr', 'located', 'limitations', 'label', 'kent', 'justified', 'jordan', 'joker', 'jaw', 'insults', 'insights', 'inaccurate', 'highway', 'heels', 'grounds', 'globe', 'gimmick', 'giants', 'gere', 'galaxy', 'forbr', 'fools', 'fifth', 'factors', 'expertly', 'everbr', 'errol', 'entering', 'elsebr', 'eleven', 'dubious', 'dj', 'disguised', 'disappointedbr', 'didbr', 'deliverance', 'cracking', 'convinces', 'contribution', 'continuing', 'confronted', 'confront', 'compete', 'cerebral', 'casino', 'buys', 'bronson', 'breakfast', 'bitch', 'belt', 'banter', 'bachelor', 'authenticity', 'attenborough', 'ariel', 'approaches', 'antonio', 'anil', 'alexandre', 'abruptly', '21st', '1991', '1939', 'wander', 'walt', 'vividly', 'unsure', 'underwater', 'undeniably', 'tossed', 'tormented', 'toni', 'supply', 'sticking', 'sf', 'salvation', 'salt', 'rookie', 'ronald', 'reward', 'repulsive', 'repressed', 'regards', 'rampage', 'puppets', 'principals', 'phillip', 'perception', 'pale', 'painter', 'owns', 'ol', 'monty', 'mol', 'mitch', 'lowkey', 'lend', 'landed', 'jarring', 'interact', 'insanity', 'inherent', 'homicide', 'homes', 'heavyhanded', 'growth', 'greatbr', 'grateful', 'formed', 'fords', 'expects', 'eventual', 'endlessly', 'differently', 'derivative', 'depths', 'definitive', 'dandy', 'crapbr', 'convicted', 'confident', 'conan', 'comedybr', 'colours', 'cents', 'braveheart', 'bmovies', 'bitten', 'biblical', 'austen', 'approaching', 'altered', 'accessible', '1977', 'yokai', 'witchcraft', 'wisely', 'vehicles', 'unattractive', 'terminator', 'survives', 'stranded', 'spies', 'siblings', 'sg1', 'separated', 'sensible', 'scriptbr', 'sale', 'runner', 'reviewing', 'published', 'pray', 'polly', 'pickup', 'photographs', 'peck', 'overblown', 'outline', 'nominations', 'natalie', 'moe', 'mobile', 'mice', 'meandering', 'mathieu', 'marc', 'letdown', 'juliet', 'jules', 'judd', 'jedi', 'irene', 'incapable', 'imo', 'immortal', 'identical', 'heavens', 'hats', 'handheld', 'ham', 'gunga', 'goodlooking', 'godawful', 'glued', 'gates', 'frames', 'flimsy', 'flashes', 'fatale', 'exterior', 'exploit', 'exit', 'evelyn', 'eternity', 'energetic', 'ebert', 'dragons', 'dobr', 'dismal', 'devastating', 'depict', 'decidedly', 'damned', 'cries', 'conveyed', 'concentrate', 'cemetery', 'caricature', 'buzz', 'bruno', 'bravo', 'beforebr', 'barrel', 'assured', 'angst', 'ally', 'adore', 'zane', 'wtf', 'wonderland', 'wagner', 'volume', 'unimaginative', 'uniform', 'thoughbr', 'tapes', 'swallow', 'subway', 'sublime', 'stalking', 'sophie', 'soderbergh', 'simpsons', 'severed', 'scarface', 'rivers', 'respectable', 'reports', 'reminder', 'reliable', 'quantum', 'psychopath', 'promoted', 'principle', 'pleasing', 'playboy', 'performancebr', 'penn', 'pc', 'payoff', 'pattern', 'papers', 'owned', 'overbr', 'oldfashioned', 'niece', 'mermaid', 'longest', 'lester', 'lance', 'judgment', 'janes', 'intricate', 'inspirational', 'improbable', 'implied', 'homosexuality', 'hindi', 'harriet', 'fragile', 'filthy', 'farmer', 'expose', 'excruciatingly', 'entirety', 'enthusiastic', 'ensure', 'enhanced', 'dread', 'downs', 'divine', 'disgrace', 'disabled', 'demonstrate', 'delicious', 'cypher', 'cushing', 'cultures', 'crossing', 'crisp', 'crippled', 'creek', 'contribute', 'cons', 'combines', 'colleagues', 'cliffhanger', 'cleaning', 'clara', 'chopped', 'characteristics', 'cecil', 'butcher', 'butch', 'bug', 'bsg', 'bones', 'bloom', 'beowulf', 'arguing', 'arab', 'appeals', 'antonioni', 'africanamerican', 'addict', 'accounts', 'absorbing', '300', '1985', '1950', 'youtube', 'whiny', 'whining', 'victorian', 'vanilla', 'ultimatum', 'tremendously', 'tendency', 'switched', 'steam', 'sidewalk', 'sergeant', 'sentimentality', 'senior', 'seeming', 'scratch', 'salman', 'revolt', 'reeve', 'rainy', 'quentin', 'pursue', 'possess', 'popping', 'pirate', 'pickford', 'paula', 'parallels', 'packs', 'p', 'ominous', 'ohara', 'ny', 'noticeable', 'nightclub', 'nerves', 'morals', 'mitchum', 'missile', 'miranda', 'mindbr', 'lighter', 'lex', 'leather', 'kidnapping', 'jodie', 'jacket', 'immense', 'holocaust', 'hippies', 'habit', 'fairbanks', 'experiencing', 'estranged', 'escaping', 'embrace', 'email', 'dustin', 'drinks', 'divorced', 'distract', 'deer', 'decline', 'cyborg', 'collect', 'christina', 'budgets', 'boyer', 'bills', 'attacking', 'astounding', 'assembled', 'anyhow', 'answered', 'amrita', 'aided', 'affleck', '95', '28', '1994', '1974', '1920s', 'yours', 'wounds', 'wire', 'wilder', 'werewolves', 'wellacted', 'voyage', 'virtual', 'vince', 'updated', 'unsatisfying', 'turmoil', 'truman', 'toby', 'theories', 'sydney', 'sucker', 'subtext', 'stewarts', 'stardom', 'spectacle', 'spaghetti', 'sought', 'seymour', 'selected', 'sand', 'rounded', 'reviewed', 'resulted', 'resolved', 'rescued', 'remembering', 'rebellious', 'precode', 'postwar', 'pin', 'peculiar', 'peaceful', 'messing', 'manbr', 'magician', 'longtime', 'longing', 'lola', 'logan', 'literal', 'liam', 'lavish', 'kurosawa', 'knocks', 'juliette', 'jill', 'jaded', 'isolation', 'havoc', 'hackman', 'grass', 'goldblum', 'glaring', 'ghetto', 'garland', 'gable', 'forgiven', 'foolish', 'followup', 'fills', 'expectation', 'exorcist', 'earnest', 'disgust', 'dilemma', 'denis', 'demonstrated', 'deliberate', 'daysbr', 'dashing', 'dame', 'crown', 'crashing', 'corporation', 'copied', 'conveniently', 'contestants', 'collective', 'classy', 'clash', 'christie', 'chill', 'cheaply', 'casper', 'begging', 'bach', 'avoiding', 'asia', 'approached', 'amazon', 'alleged', 'aiming', 'adrian', '21', '200', '19', '\\x97', 'yep', 'worms', 'whites', 'wartime', 'verdict', 'vega', 'traits', 'trains', 'tourist', 'tonys', 'thieves', 'thelma', 'taped', 'swearing', 'suspected', 'spit', 'spencer', 'span', 'snuff', 'slip', 'slaves', 'slapped', 'skilled', 'settled', 'serials', 'scotts', 'samantha', 'rowlands', 'romeo', 'ritchie', 'relentlessly', 'rehash', 'rear', 'quarter', 'q', 'potter', 'poses', 'pocket', 'plotting', 'planets', 'pad', 'odyssey', 'mystical', 'mum', 'morons', 'melvyn', 'liveaction', 'liu', 'lightning', 'laurie', 'kellys', 'keatons', 'karate', 'judged', 'jobbr', 'jealousy', 'indiana', 'hayworth', 'goods', 'gentlemen', 'gamera', 'feast', 'executives', 'excuses', 'establish', 'erika', 'enhance', 'dump', 'dramatically', 'diverse', 'delighted', 'define', 'debt', 'dealer', 'contributed', 'commits', 'coat', 'climb', 'cinemabr', 'cher', 'celebrated', 'canceled', 'bw', 'burke', 'borders', 'bombs', 'bittersweet', 'aussie', 'arriving', 'arc', 'admired', 'addiction', 'acquired', 'achieves', 'accepting', '1959', 'yawn', 'worsebr', 'wiped', 'vintage', 'vanity', 'underwear', 'ultra', 'uh', 'tool', 'tax', 'taboo', 'suggesting', 'strict', 'stella', 'spice', 'slugs', 'shepherd', 'serum', 'seebr', 'seductive', 'seasoned', 'sarcastic', 'romances', 'ritual', 'rewarding', 'remembers', 'redundant', 'readily', 'races', 'pumbaa', 'psychologist', 'preminger', 'predictably', 'posing', 'populated', 'planes', 'pirates', 'phenomenal', 'pedestrian', 'pause', 'overboard', 'novelty', 'nbc', 'moron', 'mason', 'lunch', 'loy', 'likeable', 'legitimate', 'leap', 'korea', 'jersey', 'introducing', 'intentional', 'insist', 'inmates', 'informed', 'incorrect', 'immigrant', 'horny', 'hepburn', 'headache', 'gypo', 'guinea', 'graveyard', 'furniture', 'frontier', 'freaky', 'fluid', 'flavor', 'explosive', 'exploding', 'expense', 'drab', 'delightfully', 'deliciously', 'defies', 'dads', 'cuban', 'covering', 'courtroom', 'cookie', 'comprehend', 'commitment', 'cohen', 'circles', 'cheek', 'cape', 'bye', 'breakdown', 'brainless', 'bounty', 'bestbr', 'basket', 'backbr', 'axe', 'attending', 'amidst', '1944', 'wine', 'wider', 'watchingbr', 'wastes', 'unsympathetic', 'trace', 'tongueincheek', 'tolerable', 'thirties', 'symbol', 'stylized', 'stroke', 'stephanie', 'steer', 'slide', 'sixth', 'shockingly', 'sgt', 'sells', 'screwball', 'robbers', 'ricky', 'respects', 'redneck', 'ranch', 'pushes', 'produces', 'pound', 'possession', 'possesses', 'politicians', 'polish', 'poe', 'pixar', 'pilots', 'phase', 'passage', 'parking', 'pans', 'otto', 'nuances', 'newcomer', 'mysteriously', 'mouths', 'mortal', 'mins', 'medieval', 'meantime', 'lucille', 'lethal', 'lends', 'lean', 'kinnear', 'jacques', 'ira', 'instincts', 'hybrid', 'gwyneth', 'groundbreaking', 'gilbert', 'gielgud', 'franklin', 'foundation', 'firstrate', 'festivals', 'experiencebr', 'europeans', 'establishing', 'encountered', 'embarrassingly', 'einstein', 'dominated', 'deciding', 'debbie', 'deanna', 'daylewis', 'crosby', 'counter', 'corbett', 'consist', 'consideration', 'clive', 'cliched', 'clerk', 'cigarette', 'charlies', 'caron', 'carnage', 'cal', 'branaghs', 'beg', 'barbra', 'bachchan', 'awakening', 'attended', 'arrest', 'arranged', 'apply', 'anytime', 'anxious', 'additionally', 'actorsbr', '10br', 'xfiles', 'viewpoint', 'unusually', 'unanswered', 'tickets', 'tactics', 'stating', 'stabbed', 'sparks', 'sources', 'session', 'scorsese', 'scored', 'sarandon', 'salesman', 'routines', 'roughly', 'rider', 'reverse', 'rejects', 'rational', 'queens', 'pursued', 'psyche', 'porter', 'pfeiffer', 'penelope', 'ordeal', 'optimistic', 'olivia', 'obstacles', 'obsessive', 'noteworthy', 'neglected', 'narrow', 'mute', 'motions', 'misunderstood', 'milo', 'mens', 'marilyn', 'longoria', 'laterbr', 'kubricks', 'keys', 'kazan', 'kathy', 'jury', 'july', 'jewel', 'invite', 'invention', 'informative', 'indifferent', 'indicate', 'incidents', 'huston', 'horrified', 'hop', 'herbert', 'hateful', 'haines', 'gloria', 'freaking', 'forgetting', 'flock', 'flickbr', 'feminine', 'feeble', 'exploited', 'explodes', 'excruciating', 'en', 'dumped', 'dumbest', 'duel', 'document', 'distress', 'distracted', 'diary', 'denise', 'degrees', 'deathbr', 'daisy', 'controlling', 'compliment', 'clone', 'cindy', 'casablanca', 'busey', 'brides', 'breathing', 'blandings', 'begs', 'arty', 'armstrong', 'anticipated', 'anthology', 'aftermath', 'adaption', 'abandon', '99', '1975', '1953', 'whore', 'warns', 'void', 'veterans', 'verbal', 'varied', 'upcoming', 'uncanny', 'un', 'tvs', 'turd', 'translate', 'thurman', 'targets', 'sundance', 'stations', 'spiderman', 'sickening', 'sensebr', 'sanders', 'rosemarys', 'rightbr', 'relevance', 'regularly', 'rambling', 'puzzle', 'pros', 'products', 'pointing', 'pathos', 'participants', 'ofbr', 'niven', 'mythology', 'murky', 'moss', 'mormon', 'monologue', 'minnelli', 'meal', 'mcqueen', 'martian', 'mama', 'jenna', 'iranian', 'intensely', 'instances', 'inaccuracies', 'historybr', 'hannah', 'grandma', 'grabbed', 'goals', 'generate', 'gangs', 'fright', 'freeze', 'frantic', 'flower', 'fishburne', 'eagerly', 'distraction', 'depictions', 'debra', 'daylight', 'darth', 'cunningham', 'corn', 'corman', 'corey', 'cooking', 'convention', 'combs', 'columbia', 'ches', 'centuries', 'cannes', 'biopic', 'belly', 'arquette', 'arguments', 'angie', 'agony', 'aggressive', 'afterward', '34', '1998', '1940', 'zorro', 'z', 'widowed', 'whybr', 'upside', 'update', 'tuned', 'traps', 'tomei', 'tcm', 'swinging', 'suspicion', 'sunrise', 'statements', 'starters', 'starsbr', 'stance', 'spine', 'sondra', 'shifts', 'shift', 'services', 'seats', 'sang', 'rounds', 'rosario', 'resembling', 'replies', 'releasing', 'relating', 'realization', 'realistically', 'predator', 'policy', 'plodding', 'phones', 'paths', 'parks', 'paints', 'overbearing', 'nerve', 'naschy', 'motorcycle', 'midst', 'mates', 'masterson', 'manners', 'lurking', 'lowe', 'lip', 'lions', 'lionel', 'launch', 'laputa', 'kidnap', 'juan', 'jose', 'jolie', 'intro', 'interestingbr', 'inclusion', 'ignoring', 'hyped', 'hoot', 'herman', 'heath', 'harlow', 'hadley', 'grip', 'gooding', 'glimpses', 'glance', 'gallery', 'funding', 'forties', 'followers', 'flames', 'fanatic', 'exclusively', 'evans', 'enigmatic', 'enchanted', 'employee', 'economic', 'dumber', 'dismiss', 'discussed', 'dillinger', 'deputy', 'deed', 'curiously', 'criticize', 'controversy', 'coffin', 'click', 'claude', 'carpenters', 'bogart', 'blamed', 'berkeley', 'begun', 'august', 'ambitions', 'ambiguity', 'admitted', '85', '1982', '1948', 'wong', 'warden', 'uniforms', 'troma', 'syndrome', 'sweden', 'surroundings', 'substantial', 'stuffbr', 'stream', 'stiles', 'sterling', 'stereotyped', 'stardust', 'stalked', 'snowman', 'snipes', 'smash', 'sly', 'skinny', 'sketches', 'shore', 'shepard', 'sentences', 'selfindulgent', 'scripting', 'scenarios', 'scarecrows', 'saloon', 'safely', 'rupert', 'ruining', 'rewarded', 'reunite', 'reiser', 'reflected', 'qualify', 'popped', 'platform', 'periods', 'pains', 'ownbr', 'omar', 'offscreen', 'october', 'necessity', 'narrated', 'murderers', 'moneybr', 'moms', 'miyazaki', 'meteor', 'maureen', 'maintains', 'mabel', 'linked', 'lastly', 'kris', 'kathleen', 'imaginary', 'ignores', 'idol', 'hinted', 'hines', 'haunt', 'goldie', 'gloomy', 'gigantic', 'gestures', 'gap', 'frontal', 'frog', 'fried', 'foremost', 'foil', 'fleshed', 'factual', 'extensive', 'envy', 'enoughbr', 'educated', 'edith', 'dynamics', 'dreamy', 'dominic', 'cycle', 'county', 'consequently', 'consequence', 'comeback', 'cheadle', 'chamber', 'capacity', 'campus', 'bosses', 'biker', 'battlestar', 'backed', 'avid', 'assignment', 'apt', 'applies', 'applied', 'angelina', 'ample', 'alot', 'abortion', '1934', 'witnessing', 'wheel', 'wayans', 'valid', 'unstable', 'unfolding', 'ugh', 'trier', 'tones', 'tho', 'therapy', 'soprano', 'smell', 'slim', 'sins', 'sights', 'sheets', 'shaggy', 'sebastian', 'schneider', 'schedule', 'sammo', 'sailor', 'russ', 'rodriguez', 'robertson', 'rips', 'revolving', 'revival', 'reunited', 'resume', 'resistance', 'replacement', 'repeats', 're', 'protest', 'precise', 'pose', 'pornography', 'phantasm', 'pegg', 'paranoid', 'observe', 'nuanced', 'muslims', 'moviemaking', 'moviegoers', 'momentum', 'momentsbr', 'mick', 'medicine', 'marisa', 'knights', 'kells', 'jacks', 'israeli', 'islands', 'investigator', 'invested', 'intact', 'insomnia', 'homicidal', 'gus', 'graduate', 'georgia', 'genrebr', 'gaps', 'frozen', 'entrance', 'eli', 'du', 'diner', 'denouement', 'delirious', 'daytime', 'collins', 'clunky', 'clay', 'characterizations', 'characterisation', 'chamberlain', 'castbr', 'carlos', 'cap', 'cab', 'bubble', 'brooke', 'breast', 'bonnie', 'blockbusters', 'bleed', 'blaise', 'biting', 'bikini', 'benefits', 'beckinsale', 'bats', 'bait', 'awfulbr', 'assure', 'arrow', 'array', 'arkin', 'anita', 'alliance', 'acknowledge', '1992', '101', 'weekly', 'waking', 'vivian', 'villainous', 'unhinged', 'tomb', 'tire', 'throughbr', 'thereby', 'talky', 'supreme', 'sufficient', 'studied', 'stern', 'stadium', 'spider', 'sour', 'sonny', 'skeptical', 'sitcoms', 'similarity', 'silverman', 'shotgun', 'shocks', 'sherlock', 'sheen', 'sensibility', 'seduce', 'sarcasm', 'rolls', 'rightly', 'retelling', 'reserved', 'relying', 'rebels', 'realises', 'raging', 'questioning', 'prophecy', 'playwright', 'pivotal', 'parrot', 'offend', 'networks', 'needing', 'mustve', 'moviei', 'marked', 'lynchs', 'lopez', 'lil', 'landmark', 'laboratory', 'jude', 'joking', 'johns', 'johansson', 'interrupted', 'inadvertently', 'hysterically', 'hooker', 'hayes', 'geisha', 'gathering', 'fuzzy', 'fundamental', 'fortunate', 'fleet', 'famed', 'ernie', 'entertainingbr', 'enchanting', 'displaying', 'detroit', 'deemed', 'customers', 'crushed', 'cow', 'commanding', 'colored', 'collette', 'coke', 'clooney', 'childlike', 'chiba', 'cheers', 'boundaries', 'bias', 'bc', 'bauer', 'balanced', 'babes', 'artistry', 'admits', 'abound', '1967', 'ww2', 'worldwide', 'washed', 'wash', 'visitor', 'vignettes', 'vargas', 'usbr', 'upstairs', 'unnatural', 'unfamiliar', 'understandably', 'unclear', 'truths', 'trivial', 'trauma', 'sweat', 'sunset', 'substitute', 'subsequently', 'subgenre', 'stumble', 'stake', 'spotlight', 'smug', 'shred', 'shameless', 'scheming', 'samuel', 'rice', 'republic', 'reminding', 'reluctantly', 'randall', 'quintessential', 'puppy', 'psychedelic', 'progressed', 'professionals', 'phoenix', 'penned', 'olsen', 'observations', 'northam', 'nauseating', 'myrna', 'maximum', 'mandy', 'madsen', 'madeleine', 'lunatic', 'janet', 'iturbi', 'interviewed', 'interior', 'insert', 'howling', 'hostel', 'hitchcocks', 'harrowing', 'hardened', 'handicapped', 'gackt', 'fuel', 'fruit', 'frombr', 'forgets', 'finishing', 'finishes', 'favourites', 'fassbinder', 'fart', 'evokes', 'epics', 'enduring', 'egyptian', 'drowned', 'doug', 'divided', 'diversity', 'district', 'disco', 'determination', 'despise', 'demille', 'deathtrap', 'criticized', 'coworker', 'courtesy', 'convent', 'controls', 'confined', 'complications', 'comparable', 'commendable', 'chew', 'cheerful', 'charges', 'chaotic', 'celebrities', 'caretaker', 'caprica', 'bust', 'brett', 'boots', 'boogie', 'beckham', 'bakshis', 'baddies', 'awareness', 'arrogance', 'arebr', 'announced', 'ala', 'ajay', 'addressed', 'accompanying', 'accidental', '1943', 'yell', 'wright', 'wholesome', 'whod', 'whimsical', 'verge', 'unnecessarily', 'um', 'travis', 'transparent', 'traditions', 'titular', 'timmy', 'tide', 'thrust', 'thailand', 'testing', 'temper', 'tashan', 'targeted', 'sylvia', 'surround', 'summed', 'spoiling', 'sincerity', 'sholay', 'shannon', 'seth', 'semblance', 'scarlett', 'sanity', 'salvage', 'roses', 'relaxed', 'recover', 'rea', 'python', 'programme', 'perverted', 'participate', 'owl', 'outlandish', 'orchestra', 'olds', 'occult', 'obscurity', 'musicbr', 'monotonous', 'monks', 'misty', 'meadows', 'mccarthy', 'martians', 'magically', 'license', 'lens', 'laying', 'krueger', 'kirsten', 'kindly', 'judges', 'interpretations', 'inserted', 'injury', 'infinitely', 'hunted', 'hostile', 'hostage', 'hiphop', 'himselfbr', 'hawn', 'hallmark', 'gut', 'guardian', 'gorilla', 'galactica', 'flows', 'file', 'fascist', 'fairytale', 'explode', 'entries', 'earliest', 'dynamite', 'distributed', 'destination', 'deeds', 'cutter', 'convenient', 'considers', 'composition', 'colleague', 'cmon', 'chuckles', 'chong', 'characteristic', 'captivated', 'camping', 'cameraman', 'cain', 'burial', 'brent', 'brat', 'bonds', 'bonanza', 'blackandwhite', 'baron', 'backstory', 'aroundbr', 'antagonist', 'annoy', 'affecting', 'adele', '1963', '1951', 'wrestler', 'winners', 'whove', 'wherever', 'wesley', 'walmart', 'vomit', 'variation', 'upbeat', 'understatement', 'underdeveloped', 'unappealing', 'turkish', 'toxic', 'toned', 'thunder', 'taut', 'takashi', 'suzanne', 'sunk', 'stuffed', 'stepmother', 'sporting', 'spoilerbr', 'smiths', 'slashers', 'sho', 'searched', 'se', 'scoobydoo', 'satisfaction', 'sane', 'sales', 'robbed', 'rivals', 'resolve', 'remark', 'recreate', 'raunchy', 'rampant', 'protection', 'preaching', 'portuguese', 'plate', 'pizza', 'pigs', 'philo', 'partbr', 'outrageously', 'othersbr', 'orphan', 'openly', 'observation', 'nun', 'novelist', 'nightmarish', 'motel', 'mister', 'miraculously', 'miikes', 'melancholy', 'marcel', 'manipulation', 'macdonald', 'listened', 'kinski', 'jagger', 'intend', 'inclined', 'incestuous', 'implies', 'hooper', 'herd', 'happenbr', 'gypsy', 'grin', 'ghastly', 'fritz', 'flashing', 'flag', 'finney', 'fetish', 'faded', 'eyesbr', 'exploitative', 'excels', 'engine', 'elsa', 'elliott', 'elephants', 'ealing', 'dwight', 'dvdbr', 'duh', 'drowning', 'drift', 'dragging', 'devotion', 'dangerously', 'dallas', 'dahmer', 'dafoe', 'crosses', 'crossed', 'crooks', 'creasy', 'counting', 'constraints', 'complained', 'compensate', 'communication', 'committing', 'coma', 'cocaine', 'clouds', 'clarity', 'cena', 'cancelled', 'borrow', 'blazing', 'benjamin', 'bearing', 'beard', 'battlefield', 'banks', 'awaiting', 'avoids', 'article', 'almighty', 'aesthetic', 'admission', 'adapt', 'achievements', 'aaron', '010', 'zodiac', 'wheelchair', 'watcher', 'warrant', 'voyager', 'voodoo', 'vcr', 'vapid', 'uneasy', 'unconventional', 'traumatic', 'transport', 'tools', 'tess', 'stabbing', 'ss', 'spontaneous', 'spiral', 'sophia', 'somethings', 'slower', 'sinks', 'shoe', 'sharks', 'shameful', 'shahid', 'shah', 'sexist', 'sergio', 'serbian', 'senator', 'sections', 'seattle', 'screened', 'satanic', 'runaway', 'ruled', 'rolesbr', 'robotic', 'riff', 'restraint', 'rendering', 'remainder', 'reasonbr', 'ram', 'prop', 'progression', 'proceed', 'pretends', 'presidential', 'practical', 'plug', 'permanent', 'peggy', 'palm', 'overtones', 'overshadowed', 'originalbr', 'oblivious', 'nutshell', 'moores', 'mole', 'mock', 'mentor', 'lookalike', 'locke', 'lennon', 'juice', 'joining', 'jj', 'je', 'jan', 'jackman', 'isabelle', 'irritated', 'impending', 'ideabr', 'hometown', 'homebr', 'henchmen', 'gretchen', 'govinda', 'glossy', 'gilliam', 'ghostly', 'gena', 'garfield', 'frat', 'flavia', 'fires', 'fashions', 'fairness', 'facility', 'excellence', 'evoke', 'everett', 'ernest', 'epitome', 'enormously', 'encouraged', 'drivers', 'dreaming', 'distinction', 'desk', 'deepest', 'creations', 'courageous', 'coolest', 'contestant', 'confuse', 'conductor', 'climbing', 'classmates', 'clad', 'circa', 'chloe', 'cheering', 'celebrate', 'cedric', 'carlitos', 'buttons', 'busby', 'burnt', 'betrayed', 'bernsen', 'battling', 'bashing', 'awarded', 'avenge', 'automatic', 'aunts', 'assumes', 'artemisia', 'apple', 'apocalypse', 'advised', 'admiration', 'abundance', 'absorbed', '26', '1932', 'warehouse', 'versionbr', 'val', 'unleashed', 'transforms', 'thingsbr', 'theodore', 'superstar', 'submarine', 'suave', 'stab', 'solved', 'slater', 'sickness', 'sheep', 'shaped', 'selfcentered', 'secure', 'screenplays', 'rourke', 'roller', 'rivalry', 'riders', 'respond', 'reported', 'razor', 'raid', 'qualifies', 'quaint', 'pursuing', 'prologue', 'projected', 'principles', 'priests', 'possiblebr', 'plotline', 'picturebr', 'paz', 'pauline', 'ostensibly', 'organization', 'occupied', 'noting', 'notices', 'ninety', 'myrtle', 'meyer', 'meredith', 'meek', 'masked', 'marijuana', 'magazines', 'macmurray', 'linear', 'lindy', 'labeled', 'jo', 'jar', 'informer', 'incidental', 'incest', 'hum', 'hobgoblins', 'greene', 'goat', 'giovanna', 'gig', 'garage', 'fraud', 'ferrell', 'feinstone', 'failures', 'fades', 'experts', 'espionage', 'employees', 'electronic', 'effortlessly', 'eagle', 'dominate', 'distinctive', 'disregard', 'disappearance', 'diego', 'demeanor', 'defending', 'deadpan', 'dc', 'cursed', 'criticisms', 'convict', 'conveying', 'colony', 'coburn', 'clyde', 'chops', 'choir', 'chip', 'carpet', 'capote', 'caper', 'candle', 'brazilian', 'brashear', 'bout', 'bookbr', 'boobs', 'blondell', 'bimbo', 'bert', 'beforehand', 'beers', 'auto', 'assistance', 'antihero', 'ambiance', '1966', '1958', 'zelah', 'yells', 'worrying', 'woefully', 'weirdness', 'warners', 'warhols', 'vigilante', 'uncertain', 'turtle', 'torment', 'tolerance', 'tits', 'tightly', 'theatres', 'tended', 'tech', 'tackle', 'symbols', 'switching', 'sustain', 'strung', 'starship', 'spoofs', 'socially', 'sober', 'snap', 'slept', 'slavery', 'sites', 'signature', 'sensual', 'sensitivity', 'scriptwriter', 'sandy', 'saints', 'russo', 'revolver', 'responds', 'reject', 'rebellion', 'realbr', 'prostitution', 'prostitutes', 'predecessors', 'prank', 'pornographic', 'pompous', 'playful', 'pierre', 'patty', 'outset', 'ongoing', 'officially', 'offense', 'obrien', 'ninjas', 'nest', 'motivated', 'monroe', 'mira', 'mills', 'middleclass', 'marines', 'manipulated', 'managing', 'malden', 'mae', 'madison', 'lifelong', 'lara', 'lampoon', 'joint', 'jigsaw', 'investment', 'interiors', 'informs', 'inform', 'influential', 'influences', 'ideals', 'idealistic', 'highschool', 'harron', 'grease', 'gershwin', 'geek', 'gandolfini', 'frost', 'framing', 'forgiveness', 'filmography', 'fiend', 'fiancée', 'farmers', 'englund', 'edison', 'edges', 'dunst', 'dreyfuss', 'drawings', 'doyle', 'discipline', 'digging', 'detached', 'davids', 'croc', 'crashed', 'conscious', 'confines', 'combining', 'colman', 'cohesive', 'closure', 'clinic', 'cheech', 'cells', 'burgess', 'budding', 'brandon', 'bodyguard', 'boards', 'bloodbath', 'bless', 'blames', 'bennett', 'bean', 'barney', 'barnes', 'badness', 'associate', 'annoyance', 'ang', 'alonebr', 'ads', 'admirer', 'abomination', '1955', 'waynes', 'vincenzo', 'vet', 'varying', 'unravel', 'troopers', 'travolta', 'transported', 'tramp', 'tolerate', 'throwaway', 'theirs', 'surrender', 'superfluous', 'stupidbr', 'stink', 'standpoint', 'stabs', 'spelling', 'spade', 'spaceship', 'slam', 'shrek', 'shoved', 'shootouts', 'shield', 'seuss', 'seriousness', 'scratching', 'sara', 'sammy', 'sailors', 'sacrifices', 'rewrite', 'replacing', 'reasoning', 'reagan', 'protective', 'programming', 'pressed', 'policemen', 'polar', 'perverse', 'perspectives', 'peril', 'pen', 'peers', 'parodies', 'palmas', 'pairing', 'padding', 'oprah', 'norris', 'nearest', 'mythical', 'mustache', 'morse', 'monica', 'mixes', 'mines', 'midget', 'merry', 'mercifully', 'marrying', 'marine', 'marcus', 'manic', 'maintaining', 'lurid', 'loren', 'lingering', 'liberty', 'lays', 'kareena', 'kalifornia', 'justification', 'jurassic', 'jewelry', 'irving', 'interplay', 'inexperienced', 'inconsistencies', 'imitate', 'imho', 'identified', 'holt', 'happenings', 'hallucinations', 'gruff', 'groove', 'griffiths', 'grating', 'grandpa', 'goodman', 'gino', 'geoffrey', 'gadgets', 'functions', 'forrest', 'fodder', 'flowing', 'fixed', 'facebr', 'fabric', 'existing', 'emphasize', 'egg', 'economy', 'echoes', 'division', 'diving', 'distorted', 'dish', 'directtovideo', 'dim', 'dictator', 'determine', 'dern', 'derived', 'depend', 'damsel', 'cunning', 'crowded', 'cringing', 'cravens', 'cracks', 'coworkers', 'counterparts', 'consciousness', 'connie', 'conclusions', 'concentration', 'collector', 'collapse', 'cody', 'captive', 'cannibals', 'buffy', 'britney', 'breathe', 'boyfriends', 'blessed', 'bites', 'berenger', 'believability', 'beetle', 'awry', 'asset', 'animations', 'anguish', 'amid', 'allan', 'alexandra', 'advances', 'acclaim', '1946', 'yearbr', 'yarn', 'widower', 'weary', 'villa', 'vertigo', 'uptight', 'tsui', 'trigger', 'transplant', 'torturing', 'temptation', 'systems', 'switches', 'surf', 'subtitled', 'structured', 'strained', 'stoned', 'steaming', 'stares', 'staging', 'spelled', 'sorrow', 'slut', 'simons', 'significantly', 'showcases', 'shelter', 'sensibilities', 'sensational', 'seduction', 'sasquatch', 'russians', 'rousing', 'romania', 'representing', 'representative', 'regime', 'reese', 'reckless', 'radiation', 'profoundly', 'portions', 'plagued', 'placement', 'pia', 'paycheck', 'pals', 'paired', 'overwrought', 'outlaw', 'ossessione', 'orlando', 'opposition', 'officials', 'natali', 'muni', 'monologues', 'mobster', 'melbourne', 'mcadams', 'marvin', 'manga', 'mack', 'luxury', 'lords', 'loony', 'longbr', 'locate', 'locale', 'lo', 'linebr', 'lightweight', 'lifts', 'liberties', 'lars', 'kristofferson', 'kidnaps', 'keanu', 'katie', 'k', 'inhabit', 'identities', 'heroines', 'henchman', 'heather', 'heap', 'hartleys', 'hardboiled', 'hanzo', 'hans', 'han', 'hairy', 'haha', 'grossly', 'graces', 'gibson', 'genetic', 'gathered', 'gasp', 'funky', 'foreboding', 'flew', 'fiery', 'federal', 'faye', 'faint', 'examine', 'er', 'entertains', 'engineer', 'elected', 'egypt', 'edmund', 'earns', 'duchovny', 'drummer', 'drastically', 'downfall', 'downbeat', 'dom', 'disappoints', 'depardieu', 'denying', 'dedication', 'deck', 'decency', 'dash', 'darkly', 'czech', 'cradle', 'cowardly', 'coward', 'cousins', 'contributes', 'continuously', 'confronts', 'condemned', 'communism', 'cloak', 'censorship', 'categories', 'cages', 'butchered', 'brush', 'borrows', 'bon', 'benny', 'bastard', 'bartender', 'animators', 'anchors', 'altmans', 'ali', 'airing', 'adultery', 'actionbr', 'abu', 'zu', 'youngsters', 'wielding', 'warbr', 'visconti', 'virtue', 'vaughn', 'uninspiring', 'underused', 'undercover', 'tricked', 'transitions', 'tina', 'threads', 'thereafter', 'tasty', 'taime', 'sykes', 'sweeping', 'surgeon', 'supportive', 'supermarket', 'sucking', 'subdued', 'straighttovideo', 'stirring', 'spotted', 'spells', 'sophistication', 'snowy', 'sleeper', 'sixteen', 'shrill', 'shiny', 'shelves', 'shaun', 'sensation', 'scattered', 'romanian', 'rogue', 'rockets', 'retirement', 'register', 'redford', 'rapes', 'puzzled', 'prolific', 'presume', 'premiered', 'prefers', 'preferably', 'pleasures', 'pepper', 'pecker', 'owe', 'oscarwinning', 'optimism', 'ogre', 'nuns', 'nora', 'nifty', 'myra', 'monday', 'modernday', 'mediocrity', 'maurice', 'massey', 'madman', 'loner', 'liotta', 'lindsey', 'likebr', 'ledger', 'lds', 'lawn', 'latino', 'laser', 'languages', 'knocking', 'knees', 'intelligently', 'intellectually', 'injustice', 'increase', 'imprisoned', 'impressions', 'illustrate', 'il', 'icons', 'hypnotic', 'hurry', 'hunky', 'hugo', 'hmm', 'halfhour', 'golf', 'goldsworthy', 'godard', 'glow', 'glenda', 'gently', 'geniuses', 'fuss', 'freed', 'freaked', 'fierce', 'fewer', 'fence', 'fellini', 'fanning', 'fallon', 'eyed', 'extraordinarily', 'expresses', 'ewoks', 'establishment', 'erabr', 'ensue', 'engagement', 'emmy', 'eh', 'echo', 'ebay', 'drum', 'dreamlike', 'dodgy', 'distinctly', 'developments', 'deservedly', 'della', 'defy', 'dealers', 'crypt', 'crooked', 'cowritten', 'correctness', 'coop', 'consumed', 'conniving', 'confirmed', 'collaboration', 'cockney', 'clutter', 'cloth', 'clockwork', 'client', 'clarence', 'chemical', 'cheesiness', 'chans', 'ceremony', 'ceiling', 'capitalism', 'byron', 'brit', 'bothers', 'booth', 'boost', 'boogeyman', 'bliss', 'bleeding', 'billing', 'belle', 'bart', 'aura', 'atrocity', 'atlantic', 'artistically', 'applause', 'apollo', 'anti', 'alter', 'allies', 'alarm', 'aircraft', 'accomplishment', 'abstract', 'abroad', 'aboard', '20s', 'zhang', 'zany', 'yourselfbr', 'wrongly', 'willingly', 'visceral', 'verhoevens', 'unwilling', 'trusted', 'trendy', 'traveled', 'todaybr', 'thug', 'thereof', 'taker', 'supports', 'succession', 'strain', 'springs', 'slowmotion', 'slips', 'sleepy', 'slaughtered', 'sinatras', 'simpler', 'shout', 'shocker', 'shawn', 'shady', 'sematary', 'scarlet', 'scarier', 'satisfactory', 'roommates', 'romeros', 'rodney', 'robbing', 'roads', 'rhyme', 'retrieve', 'reportedly', 'relates', 'recovering', 'ravishing', 'rapid', 'rant', 'proudly', 'protecting', 'proportions', 'prone', 'promoting', 'predicted', 'predictability', 'preacher', 'potent', 'plummer', 'photograph', 'peterson', 'periodbr', 'perceived', 'overtly', 'operating', 'operate', 'oneill', 'notwithstanding', 'nerdy', 'natasha', 'mutants', 'muscular', 'muriel', 'mud', 'moderately', 'mockery', 'mishmash', 'messbr', 'maturity', 'mastermind', 'manipulate', 'luthor', 'lure', 'lt', 'lorre', 'lists', 'limp', 'legion', 'lawyers', 'launched', 'lansbury', 'knives', 'kilmer', 'kenny', 'judgement', 'joshua', 'imply', 'illusion', 'icy', 'henderson', 'helena', 'heavenly', 'heartless', 'harilal', 'grisly', 'grendel', 'grandparents', 'governments', 'gosh', 'gobr', 'gladiator', 'gi', 'fur', 'fulfilling', 'fulfill', 'friendsbr', 'forsythe', 'forbes', 'fleeting', 'fleeing', 'flamboyant', 'fighters', 'fetched', 'fastforward', 'farrah', 'fagin', 'exgirlfriend', 'encourages', 'electricity', 'elder', 'dunne', 'drain', 'doris', 'denver', 'defining', 'deborah', 'data', 'darius', 'daria', 'cynicism', 'cowrote', 'corbin', 'conflicted', 'comprised', 'cinematographic', 'christensen', 'chevy', 'chandler', 'censors', 'bs', 'brick', 'breakthrough', 'bloke', 'blackmail', 'bitchy', 'bing', 'barton', 'ballroom', 'baddie', 'backdrops', 'autobiography', 'attic', 'attendant', 'astonishingly', 'arnie', 'armor', 'appalled', 'anythingbr', 'anxiety', 'analyze', 'amoral', 'alcoholism', '700', '51', '1964', '1957', '150', 'zabriskie', 'wwi', 'wrath', 'worship', 'wolves', 'wee', 'virginity', 'violently', 'vibe', 'vaudeville', 'ursula', 'urgency', 'upbringing', 'unnerving', 'unlucky', 'unconscious', 'treating', 'tourists', 'tobe', 'throne', 'theo', 'terrorism', 'temporary', 'tasks', 'tango', 'tacked', 'tables', 'swords', 'supremacy', 'superiors', 'stumbling', 'stereotyping', 'steamy', 'sore', 'sibling', 'sheridan', 'shatner', 'shamelessly', 'seventh', 'semi', 'sammi', 'sack', 'rudd', 'rosenstrasse', 'rko', 'ridden', 'richly', 'replay', 'reno', 'relaxing', 'redgrave', 'recurring', 'recreation', 'ratio', 'ranger', 'quirks', 'prolonged', 'prejudices', 'pour', 'poke', 'placing', 'pistol', 'pertwee', 'penguin', 'peaks', 'payne', 'patriotic', 'passions', 'padded', 'overwhelmed', 'overused', 'overacts', 'observed', 'notions', 'neverending', 'needlessly', 'moonstruck', 'miyazakis', 'missions', 'meyers', 'mcdowell', 'mcdermott', 'marx', 'martino', 'mandatory', 'management', 'ma', 'liz', 'liar', 'levy', 'lesbians', 'leaps', 'largest', 'kornbluth', 'jolly', 'jerky', 'jam', 'iti', 'irresponsible', 'irresistible', 'interspersed', 'innuendo', 'inhabited', 'inducing', 'increasing', 'immigrants', 'imitating', 'illustrated', 'honey', 'hilton', 'herrings', 'helmet', 'heir', 'hector', 'hazzard', 'harbor', 'happier', 'hale', 'gusto', 'gravity', 'grady', 'girlbr', 'giggle', 'gays', 'gardens', 'flame', 'fitzgerald', 'fiasco', 'feared', 'farnsworth', 'expressing', 'expand', 'episodebr', 'enthralling', 'elisha', 'ecstasy', 'eastwoods', 'dwarf', 'dukakis', 'doses', 'dodge', 'dive', 'distinguished', 'disasters', 'dillon', 'diaz', 'destructive', 'denial', 'dangers', 'curtain', 'crass', 'countrys', 'counterpart', 'counted', 'coppola', 'continuous', 'confession', 'concentrated', 'compassionate', 'coal', 'clubs', 'climbs', 'climate', 'civilians', 'chop', 'cheung', 'cheat', 'castro', 'cassie', 'burden', 'bullies', 'brunette', 'brilliantbr', 'brennan', 'borderline', 'booker', 'bombed', 'bloodshed', 'bigfoot', 'benoit', 'believablebr', 'behaving', 'behaves', 'azumi', 'aztec', 'auteur', 'attributes', 'athletic', 'astronauts', 'assortment', 'associates', 'archer', 'antichrist', 'anonymous', 'annoyingly', 'aniston', 'alienation', 'alba', 'academic', '98', '27', 'yearning', 'y', 'worm', 'woke', 'whipped', 'whip', 'vulnerability', 'volumes', 'vienna', 'vets', 'versa', 'vera', 'vault', 'valerie', 'unemployed', 'truthful', 'traumatized', 'transformers', 'torch', 'thumb', 'thorn', 'swiss', 'stupidest', 'stripper', 'stretches', 'stalks', 'spitting', 'spinning', 'smarmy', 'sm', 'slew', 'skipping', 'sessions', 'sequelbr', 'segal', 'seal', 'screamed', 'scandal', 'sarne', 'saddest', 'rusty', 'rotting', 'roach', 'restless', 'relied', 'reincarnation', 'regrets', 'recipe', 'rapture', 'purse', 'pub', 'psychiatric', 'prophet', 'profile', 'princes', 'prices', 'pranks', 'practices', 'posh', 'pond', 'poet', 'percent', 'perceive', 'penis', 'penalty', 'paragraph', 'palestinian', 'outs', 'opponents', 'nutty', 'noam', 'nightbr', 'nerds', 'neglect', 'neeson', 'nailed', 'muted', 'montages', 'mindset', 'midway', 'midler', 'melt', 'mechanic', 'meanings', 'marathon', 'maiden', 'maguire', 'lubitsch', 'lowbrow', 'lin', 'lightly', 'lecture', 'lang', 'knack', 'keitel', 'joanna', 'izzard', 'itd', 'italians', 'irrational', 'intellect', 'inherited', 'incompetence', 'improvised', 'idiocy', 'hustler', 'hopeful', 'honeymoon', 'holland', 'hmmm', 'hesitate', 'guru', 'goofs', 'gimmicks', 'gannon', 'frenzy', 'footsteps', 'floriane', 'flipping', 'firsttime', 'finely', 'featurelength', 'farewell', 'fable', 'exwife', 'explanations', 'expanded', 'existential', 'enhances', 'embarrass', 'elmer', 'elevate', 'efficient', 'drugged', 'dopey', 'dogma', 'disdain', 'discernible', 'disappearing', 'dickinson', 'darling', 'dani', 'customs', 'custody', 'crowds', 'crenna', 'coverage', 'cortez', 'corky', 'contemplate', 'consisted', 'conquest', 'confronting', 'concludes', 'concentrates', 'compositions', 'companions', 'collecting', 'cocktail', 'coaster', 'classicbr', 'chocolate', 'celine', 'caution', 'casually', 'casebr', 'camps', 'bursts', 'buildup', 'btk', 'bothering', 'bonding', 'bishop', 'billion', 'beth', 'bald', 'awfulness', 'aweigh', 'astronaut', 'architecture', 'approximately', 'alienate', 'agobr', 'afghanistan', 'adequately', '48', '250', 'zealand', 'wits', 'wisecracking', 'wipe', 'wills', 'welcomed', 'weaver', 'walters', 'waits', 'viggo', 'victorias', 'versatile', 'vengeful', 'undeveloped', 'uncredited', 'toss', 'throats', 'themselvesbr', 'thatll', 'thankful', 'tested', 'tensions', 'tenants', 'teddy', 'suspended', 'surpasses', 'supporters', 'suggestive', 'subtleties', 'submit', 'strikingly', 'stoic', 'stepped', 'stature', 'squeeze', 'spielbergs', 'spectacularly', 'sparse', 'snippets', 'snappy', 'smarter', 'slows', 'slipped', 'sleuth', 'shootings', 'shaolin', 'shakespearean', 'rushes', 'rugged', 'rizzo', 'ripoffs', 'rightfully', 'rico', 'revive', 'rests', 'rehearsal', 'regal', 'regain', 'rebecca', 'rack', 'proverbial', 'profit', 'productionbr', 'prevented', 'prevalent', 'preteen', 'premises', 'postmodern', 'plants', 'planted', 'performancesbr', 'pauses', 'passenger', 'partial', 'pam', 'outrage', 'oppressive', 'oddball', 'norton', 'nineties', 'naval', 'murphys', 'mourning', 'mostel', 'monstrous', 'mold', 'micheal', 'metropolis', 'melinda', 'maverick', 'marred', 'lyrical', 'luzhin', 'lung', 'lucio', 'lovingly', 'loop', 'looney', 'locales', 'listing', 'limbs', 'lange', 'kramer', 'kiddie', 'kerr', 'keeler', 'kaufman', 'kamal', 'jock', 'january', 'it´s', 'islam', 'irs', 'insignificant', 'insects', 'insanely', 'impeccable', 'immersed', 'illiterate', 'hug', 'horn', 'hitchhiker', 'hilariousbr', 'healing', 'harrys', 'harlem', 'guided', 'graves', 'grain', 'goodnatured', 'goers', 'garnered', 'garcia', 'gage', 'fulllength', 'fugitive', 'friendships', 'flip', 'fatherson', 'fanatics', 'examined', 'everybodys', 'empathize', 'elliot', 'ella', 'eliminate', 'dyke', 'dusty', 'duryea', 'durbin', 'dreadfully', 'downtown', 'documents', 'discussions', 'diabolical', 'dental', 'democracy', 'delve', 'december', 'deathstalker', 'daphne', 'daisies', 'cruella', 'creeps', 'cowriter', 'corridors', 'converted', 'continent', 'connor', 'conduct', 'condescending', 'conclusionbr', 'conception', 'compromise', 'comebr', 'collar', 'coleman', 'cocky', 'citys', 'cillian', 'choke', 'chock', 'chewing', 'chapters', 'carole', 'capt', 'candidates', 'callahan', 'bury', 'bucket', 'brink', 'branch', 'braindead', 'bombing', 'bolivia', 'betrays', 'believer', 'bearable', 'bash', 'barbarian', 'balloon', 'backwoods', 'babysitter', 'atomic', 'association', 'assist', 'ash', 'architect', 'apprentice', 'apologize', 'apartheid', 'alternately', 'allison', 'albums', 'ahmad', 'adventurous', 'adopt', 'acknowledged', '400', '2009', '1949', '1938', '1931', '18th', 'woven', 'wondrous', 'witless', 'willem', 'wheels', 'welch', 'weirdo', 'voiceovers', 'villagers', 'variations', 'vanishing', 'untrue', 'unrated', 'universally', 'unimpressive', 'undertaker', 'unborn', 'tucker', 'truebr', 'til', 'throughoutbr', 'thinner', 'tepid', 'telly', 'tedium', 'switzerland', 'swamp', 'surrogate', 'surfers', 'stubborn', 'stripped', 'straw', 'strangest', 'stir', 'stimulating', 'spectrum', 'soulless', 'sorvino', 'societies', 'snatch', 'smoothly', 'smitten', 'sloane', 'siege', 'shouts', 'shinae', 'shack', 'sentenced', 'seinfeld', 'sciencefiction', 'satellite', 'sans', 'sacrificed', 'rollercoaster', 'rohmer', 'rigid', 'revelations', 'retain', 'requisite', 'render', 'recalls', 'ranging', 'rainer', 'psychologically', 'presumed', 'prehistoric', 'practicing', 'plotted', 'platoon', 'pita', 'philadelphia', 'pavarotti', 'pauls', 'paperhouse', 'palette', 'overt', 'overseas', 'outtakes', 'outta', 'oriental', 'obscene', 'nuance', 'november', 'norwegian', 'norma', 'mutated', 'mpaa', 'morgana', 'mocking', 'misplaced', 'mischievous', 'mining', 'millennium', 'menbr', 'matching', 'marquis', 'malcolm', 'mac', 'lotr', 'locks', 'll', 'lizard', 'livesbr', 'lineup', 'lieutenant', 'layered', 'lamas', 'kinky', 'kindness', 'kentucky', 'jessie', 'janitor', 'irwin', 'intruder', 'intestines', 'interpreted', 'insulted', 'insteadbr', 'illustrates', 'hurting', 'hungarian', 'hoods', 'honorable', 'hogan', 'hockey', 'hispanic', 'hisher', 'heroin', 'hedy', 'hating', 'harmony', 'hardest', 'haired', 'guevara', 'grumpy', 'grips', 'greta', 'granger', 'gesture', 'gen', 'gamut', 'gamebr', 'gaining', 'futurebr', 'forgivable', 'floors', 'flee', 'fireworks', 'fatherbr', 'exposing', 'exhibit', 'evolved', 'equals', 'eponymous', 'episodic', 'entertainer', 'edits', 'dw', 'duties', 'duff', 'dominick', 'distributors', 'disgruntled', 'directorbr', 'directionbr', 'dimwitted', 'desolate', 'dense', 'denied', 'darkest', 'culkin', 'crow', 'criminally', 'connolly', 'connecting', 'confirm', 'comicbook', 'cloud', 'classified', 'chore', 'cheaper', 'celebrating', 'cbc', 'cathy', 'casted', 'carson', 'caroline', 'carnival', 'carlito', 'carface', 'careerbr', 'bryan', 'bets', 'benson', 'batwoman', 'basil', 'barker', 'backyard', 'assassins', 'anyonebr', 'andersons', 'anchor', 'amok', 'allegedly', 'admirably', 'administration', 'adapting', 'achieving', '510', '500', 'zatoichi', 'yetbr', 'wicker', 'weaves', 'wb', 'voting', 'voters', 'vivah', 'usage', 'unsuccessful', 'unnamed', 'unfinished', 'unfairly', 'undertones', 'underdog', 'twodimensional', 'transform', 'transferred', 'transcends', 'tigerland', 'texture', 'textbook', 'terriblebr', 'teds', 'tearjerker', 'tasteful', 'talentless', 'swift', 'swat', 'supplies', 'streisands', 'streak', 'stills', 'stealth', 'spreading', 'spears', 'spaces', 'soles', 'societal', 'smalltown', 'smallest', 'slug', 'skywalker', 'skimpy', 'singin', 'shrink', 'shakes', 'shadowy', 'seriouslybr', 'secluded', 'schemes', 'sacred', 'rumors', 'rewatch', 'retrospect', 'rerun', 'request', 'redeemed', 'rabid', 'puzzling', 'pursues', 'prototype', 'prevents', 'preserved', 'positions', 'poppins', 'polite', 'pokes', 'plantation', 'phyllis', 'pets', 'patch', 'participation', 'owning', 'ounce', 'otoole', 'osullivan', 'orphanage', 'orgy', 'organs', 'operas', 'onesided', 'olympic', 'napoleon', 'motif', 'monumental', 'monstrosity', 'monastery', 'mj', 'miracles', 'michel', 'mastroianni', 'marvellous', 'marlene', 'mamet', 'lombard', 'logo', 'liza', 'leno', 'leia', 'lap', 'lambs', 'kisses', 'kingsley', 'jew', 'jed', 'jackass', 'itchy', 'interpret', 'integrated', 'instruments', 'insisted', 'indulge', 'inch', 'inc', 'imdbs', 'hosts', 'holidays', 'historians', 'hiring', 'hi', 'hawaii', 'hardships']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwWhYOOXm27C",
        "outputId": "fcde0645-ced4-43d1-c1fa-0b0030871440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# dummy data creation\n",
        "\n",
        "max_len = 100\n",
        "max_words = 333\n",
        "emb_dim = 126\n",
        "\n",
        "n_sample = 5\n",
        "X = np.random.randint(0,max_words, (n_sample,max_len))\n",
        "Y = np.random.randint(0,2, n_sample)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, emb_dim, input_length=max_len))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(Attention(return_sequences=True)) # receive 3D and output 3D\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile('adam', 'binary_crossentropy')\n",
        "model.fit(X,Y, epochs=3)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-e1a074e88542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# receive 3D and output 3D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/dense_attention.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, use_scale, **kwargs)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/dense_attention.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, causal, dropout, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m   def __init__(self, causal=False, dropout=0.0,\n\u001b[1;32m     71\u001b[0m                **kwargs):\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseDenseAttention\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcausal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     }\n\u001b[1;32m    331\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1168\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1170\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'return_sequences')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvTyvy8MGpoP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f8a6c6fa-cac3-4247-a4e6-b7fcddb73baf"
      },
      "source": [
        "from keras import backend as K\n",
        "units = 64\n",
        "EMBEDDING_DIM=10000\n",
        "max_length = 50\n",
        "\n",
        "\n",
        "_input = tf.keras.Input(shape = (max_length)) # dtype = 'float32'\n",
        "embeddings = tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        input_length=max_length )(_input)\n",
        "print (embeddings.get_shape())\n",
        "    # input_dim = len(encoder.get_vocabulary()),\n",
        "    #                               output_dim = 64,\n",
        "    #                               input_length=max_length,\n",
        "    #                               mask_zero = True)(_input)\n",
        "activations = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences = True)) (embeddings)\n",
        "\n",
        "attention = tf.keras.layers.Dense(1, activation = 'tanh') (activations)\n",
        "attention = tf.keras.layers.Flatten()(attention)\n",
        "attention = tf.keras.layers.Activation('softmax') (attention)\n",
        "attention = tf.keras.layers.RepeatVector (units*2) (attention)\n",
        "attention = tf.keras.layers.Permute ([2,1]) (attention)\n",
        "\n",
        "attention_weight = tf.keras.layers.Multiply()([activations, attention])\n",
        "attention_weight = tf.keras.layers.Lambda(lambda x: K.sum(x, axis = 1)) (attention_weight)\n",
        "output_layer = tf.keras.layers.Dense(1, activation = 'sigmoid') (attention_weight)\n",
        "\n",
        "model = tf.keras.Model(inputs = _input, outputs = output_layer)\n",
        "# model = tf.keras.Sequential([encoder,\n",
        "#                               tf.keras.layers.Embedding(\n",
        "#                                   input_dim = len(encoder.get_vocabulary()),\n",
        "#                                   output_dim = 64,\n",
        "#                                   mask_zero = True),\n",
        "#                               tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences = True)),\n",
        "#                               #tf.keras.layers.Attention(name='attention_weight'),\n",
        "#                               #tf.keras.layers.SeqSelfAttention(attention_activation='sigmoid'),\n",
        "#                               #tf.keras.layers.Flatten(),\n",
        "#                               Attention(),\n",
        "#                               tf.keras.layers.Dense(32, activation='relu'),\n",
        "#                               tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "\n",
        "print(model.summary())\n",
        "# Compile the model for training\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit (train_dataset,\n",
        "                    epochs = 5, \n",
        "                    validation_data = test_dataset)\n",
        "# testing the model\n",
        "### pred_label = tf.argmax(model.predict(test),1)\n",
        "pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate (test_dataset)\n",
        "print('Test acurracy: ', test_acc)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "printing_eval_scores (true_label, pred_label, report=True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 50, 64)\n",
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 50)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)        (None, 50, 64)       640000      ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_8 (Bidirectional  (None, 50, 128)     66048       ['embedding_8[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 50, 1)        129         ['bidirectional_8[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_6 (Flatten)            (None, 50)           0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 50)           0           ['flatten_6[0][0]']              \n",
            "                                                                                                  \n",
            " repeat_vector_6 (RepeatVector)  (None, 128, 50)     0           ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " permute_6 (Permute)            (None, 50, 128)      0           ['repeat_vector_6[0][0]']        \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)          (None, 50, 128)      0           ['bidirectional_8[0][0]',        \n",
            "                                                                  'permute_6[0][0]']              \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)              (None, 128)          0           ['multiply_6[0][0]']             \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 1)            129         ['lambda_6[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 706,306\n",
            "Trainable params: 706,306\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-dfcc399fb20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m history = model.fit (train,\n\u001b[1;32m     51\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     validation_data = test)\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;31m# testing the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m### pred_label = tf.argmax(model.predict(test),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Input to reshape is a tensor with 63936 values, but the requested shape requires a multiple of 50\n\t [[node model_6/flatten_6/Reshape\n (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core/flatten.py:96)\n]] [Op:__inference_train_function_30587]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_6/flatten_6/Reshape:\nIn[0] model_6/dense_14/Tanh (defined at /usr/local/lib/python3.7/dist-packages/keras/activations.py:373)\t\nIn[1] model_6/flatten_6/Const (defined at /usr/local/lib/python3.7/dist-packages/keras/layers/core/flatten.py:91)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-40-dfcc399fb20b>\", line 52, in <module>\n>>>     validation_data = test)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/layers/core/flatten.py\", line 96, in call\n>>>     return tf.reshape(inputs, flattened_shape)\n>>> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN952WZUMxtl",
        "outputId": "0ac60c0b-01f0-4f73-a486-642da4013a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "def set_shape(value):\n",
        "    value.set_shape((180,))\n",
        "    return value\n",
        "\n",
        "train_dataset = train_dataset.map(set_shape).batch(hp.batch_size)\n",
        "train_dataset"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6e6911437937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   2003\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 2004\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5457\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5458\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5459\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5460\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4533\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4534\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m   3244\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3245\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4508\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4509\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4510\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4511\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__set_shape() takes 1 positional argument but 2 were given\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg6MoKQN1YVq",
        "outputId": "1c71150c-a5e4-4b70-d8ca-89c706be4be1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "units=250\n",
        "EMBEDDING_DIM=310\n",
        "MAX_LENGTH_PER_SENTENCE=65\n",
        "encoder_input = keras.Input(shape=(MAX_LENGTH_PER_SENTENCE))\n",
        "x =layers.Embedding(input_dim=len(embedding_matrix), output_dim=EMBEDDING_DIM, input_length=MAX_LENGTH_PER_SENTENCE,\n",
        "                              weights=[embedding_matrix],\n",
        "                              trainable=False)(encoder_input)\n",
        "                              \n",
        "activations =layers.Bidirectional(tf.keras.layers.LSTM(units))(x)\n",
        "activations = layers.Dropout(0.5)(activations)\n",
        "\n",
        "attention=layers.Dense(1, activation='tanh')(activations)\n",
        "attention=layers.Flatten()(attention)\n",
        "attention=layers.Activation('softmax')(attention)\n",
        "attention=layers.RepeatVector(units*2)(attention)\n",
        "attention=layers.Permute((2, 1))(attention)\n",
        "\n",
        "sent_representation = layers.Multiply()([activations, attention])\n",
        "sent_representation = layers.Lambda(lambda xin: K.sum(xin, axis=-2), output_shape=(units*2,))(sent_representation)\n",
        "\n",
        "sent_representation = layers.Dropout(0.5)(sent_representation)\n",
        "\n",
        "probabilities = layers.Dense(4, activation='softmax')(sent_representation)\n",
        "\n",
        "\n",
        "encoder = keras.Model(inputs=[encoder_input], outputs=[probabilities],name='encoder')\n",
        "encoder.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-32bbe38e4ee4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m310\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMAX_LENGTH_PER_SENTENCE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_LENGTH_PER_SENTENCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m x =layers.Embedding(input_dim=len(embedding_matrix), output_dim=EMBEDDING_DIM, input_length=MAX_LENGTH_PER_SENTENCE,\n\u001b[1;32m      6\u001b[0m                               \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qiIXoK7UUJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "8a5853be-3802-412b-c361-29d3370d9d20"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class attention(Layer):\n",
        "    \n",
        "    def __init__(self, return_sequences=True):\n",
        "        self.return_sequences = return_sequences\n",
        "        super(attention,self).__init__()\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
        "                               initializer=\"zeros\")\n",
        "        \n",
        "        super(attention,self).build(input_shape)\n",
        "        \n",
        "    def call(self, x):\n",
        "        \n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x*a\n",
        "        \n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "        \n",
        "        return K.sum(output, axis=1)\n",
        "\n",
        "max_len = 100\n",
        "max_words = len(encoder.get_vocabulary())\n",
        "emb_dim = 64\n",
        "# n_sample = 5\n",
        "# X = np.random.randint(0,max_words, (n_sample,max_len))\n",
        "# Y = np.random.randint(0,2, n_sample)\n",
        "model = tf.keras.Sequential([encoder,\n",
        "                              tf.keras.layers.Embedding(\n",
        "                                  input_dim = len(encoder.get_vocabulary()),\n",
        "                                  output_dim = 64,\n",
        "                                  mask_zero = True),\n",
        "                              tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences = True)),\n",
        "                              attention(return_sequences=True),\n",
        "                              tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n",
        "# model = Sequential()\n",
        "# model.add(encoder)\n",
        "# model.add(Embedding(max_words, emb_dim, input_length=max_len))\n",
        "# model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "# model.add(attention(return_sequences=True)) # receive 3D and output 3D\n",
        "# model.add(LSTM(32))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile('adam', 'binary_crossentropy')\n",
        "train_dataset2 = list(train_dataset)\n",
        "model.fit(tf.data.Dataset.from_tensor_slices(train_dataset2),\n",
        "          epochs = 5, \n",
        "          validation_data = test_dataset)\n",
        "\n",
        "#Compile the model for training\n",
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(from_logits = False),\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit (train,\n",
        "                    epochs = 5, \n",
        "                    validation_data = test)\n",
        "# testing the model\n",
        "### pred_label = tf.argmax(model.predict(test),1)\n",
        "pred_label = (model.predict(test_dataset) > 0.5).astype(\"int32\")\n",
        "true_label = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "\n",
        "test_loss, test_acc = model.evaluate (test_dataset)\n",
        "print('Test acurracy: ', test_acc)\n",
        "print('\\nTesting performance:\\n Loss: {:.3f} - Accuracy: {:.3f}'. format(test_loss, test_acc))\n",
        "printing_eval_scores (true_label, pred_label, report=True)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-12698c7dabf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m                               \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                               \u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                               tf.keras.layers.Dense(1, activation = 'sigmoid')]) \n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;31m# model = Sequential()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# model.add(encoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-12698c7dabf5>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     16\u001b[0m                                initializer=\"normal\")\n\u001b[1;32m     17\u001b[0m         self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n\u001b[0;32m---> 18\u001b[0;31m                                initializer=\"zeros\")\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HPCODIzeatg",
        "outputId": "1745b397-80f9-4b32-b1c1-20660625ee84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "#from keras_self_attention import SeqSelfAttention, SeqWeightedAttention\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "# data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen= maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# model \n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
        "model = models.Sequential()\n",
        "# model.add( Embedding(max_features, 32,  mask_zero=True))\n",
        "model.add( Embedding(max_features, 32))\n",
        "model.add(Bidirectional( LSTM(32, return_sequences=True)))\n",
        "# add an attention layer\n",
        "# model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "#model.add(SeqWeightedAttention())\n",
        "\n",
        "model.add( Dense(1, activation='sigmoid') )\n",
        "\n",
        "# compile and fit\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train, epochs=5, batch_size=128, )#validation_split=0.2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, None, 32)          320000    \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirecti  (None, None, 64)         16640     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, None, 1)           65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 336,705\n",
            "Trainable params: 336,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-361c92a9160f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;31m#validation_split=0.2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1807, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5158, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, None, 1) vs (None,)).\n"
          ]
        }
      ]
    }
  ]
}