{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LING5412_Final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/HuyenNguyenHelen/LING-5412/blob/main/LING5412_Final_project.ipynb",
      "authorship_tag": "ABX9TyOJp/iGjxFauHFoeiLaqBnb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/LING5412_Final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G99qOVzxSOwP"
      },
      "source": [
        "import tarfile\n",
        "import pandas as pd\n",
        "import csv\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree             # tree.DecisionTreeClassifier()\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm #clf = svm.SVC(decision_function_shape='ovo')\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# !pip install imbalanced-learn\n",
        "# import imblearn\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import recall_score, roc_auc_score"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5u8SwyQcnwY",
        "outputId": "96007425-5aac-43ce-b439-bc086e4433de"
      },
      "source": [
        "import gensim\n",
        "import gensim.downloader as api\n",
        "nlp = api.load('word2vec-google-news-300')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHh5b74YomXY"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvw2VYN_dTtE"
      },
      "source": [
        "\n",
        "# Unzip the dataset\n",
        "#!unzip \"/content/dontpatronizeme_v1.3.zip\" -d \"/content/drive/MyDrive/\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DJ3zR_fCre"
      },
      "source": [
        "# Opening the file from MyDrive\n",
        "file = open(r'/content/drive/MyDrive/dontpatronizeme_v1.3/dontpatronizeme_pcl.tsv')\n",
        "reader = csv.reader(file, delimiter=\"\\t\")\n",
        "data = []\n",
        "for row in reader:\n",
        "  data.append(row)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6W8pqT5PjG-L",
        "outputId": "4d2451f4-3907-4b94-e888-00777c3eb8d7"
      },
      "source": [
        "df = pd.DataFrame(data[5:],  columns = ['docID', 'keyword', 'country', 'paragraph', 'label' ] )\n",
        "df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docID</th>\n",
              "      <th>keyword</th>\n",
              "      <th>country</th>\n",
              "      <th>paragraph</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@@4703096</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>jm</td>\n",
              "      <td>NBC and Spanish-language Univision both declin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@@25567226</td>\n",
              "      <td>in-need</td>\n",
              "      <td>hk</td>\n",
              "      <td>A second T-Home project is being launched in t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@@1824078</td>\n",
              "      <td>poor-families</td>\n",
              "      <td>tz</td>\n",
              "      <td>Camfed would like to see this trend reversed ....</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@@1921089</td>\n",
              "      <td>refugee</td>\n",
              "      <td>tz</td>\n",
              "      <td>Kagunga village was reported to lack necessary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@@40039380</td>\n",
              "      <td>women</td>\n",
              "      <td>ng</td>\n",
              "      <td>Haruna stressed the need for specific approach...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10053</th>\n",
              "      <td>@@16413808</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>my</td>\n",
              "      <td>To me , I am always mindful that we are dealin...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10054</th>\n",
              "      <td>@@8676630</td>\n",
              "      <td>vulnerable</td>\n",
              "      <td>jm</td>\n",
              "      <td>Other themes included promoting the inclusion ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10055</th>\n",
              "      <td>@@7688552</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>gb</td>\n",
              "      <td>It came as the CDU was also humiliated by the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10056</th>\n",
              "      <td>@@4916290</td>\n",
              "      <td>hopeless</td>\n",
              "      <td>in</td>\n",
              "      <td>Those were only days of helplessness , she say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10057</th>\n",
              "      <td>@@2973614</td>\n",
              "      <td>immigrant</td>\n",
              "      <td>ie</td>\n",
              "      <td>They include a community college student , a c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10058 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            docID  ... label\n",
              "0       @@4703096  ...     0\n",
              "1      @@25567226  ...     0\n",
              "2       @@1824078  ...     4\n",
              "3       @@1921089  ...     0\n",
              "4      @@40039380  ...     0\n",
              "...           ...  ...   ...\n",
              "10053  @@16413808  ...     4\n",
              "10054   @@8676630  ...     0\n",
              "10055   @@7688552  ...     0\n",
              "10056   @@4916290  ...     0\n",
              "10057   @@2973614  ...     0\n",
              "\n",
              "[10058 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtakLrrIoo9_"
      },
      "source": [
        "# Exploring data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6BfIKFam55W",
        "outputId": "8208a2ff-99b1-402f-8f7b-a16a33afb528"
      },
      "source": [
        "# Length of text\n",
        "def length (txt):\n",
        "  length = len(txt.split())\n",
        "  return length\n",
        "\n",
        "txt_length = df['paragraph'].apply(lambda x: length(x))\n",
        "txt_length.sort_values(ascending = False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3534    1519\n",
              "6266    1095\n",
              "8519    1040\n",
              "4613     772\n",
              "8819     729\n",
              "        ... \n",
              "1930       4\n",
              "1385       3\n",
              "7375       3\n",
              "5112       3\n",
              "5742       0\n",
              "Name: paragraph, Length: 10058, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nAz-vJxo_wn",
        "outputId": "531788e0-f652-4142-923d-6621c0b69881"
      },
      "source": [
        "# Observing labels\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    8206\n",
              "1     906\n",
              "3     435\n",
              "4     369\n",
              "2     142\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy38u3cFVWjW",
        "outputId": "1428fb77-2e40-4fde-92ab-758d13b4dea8"
      },
      "source": [
        "df['label'] = df['label'].astype(str)\n",
        "df['label']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        4\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "10053    4\n",
              "10054    0\n",
              "10055    0\n",
              "10056    0\n",
              "10057    0\n",
              "Name: label, Length: 10058, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlKftt3JVk-n",
        "outputId": "e1e4baa3-8f95-48b6-a9fd-fe92d9b23484"
      },
      "source": [
        "# Missing data\n",
        "#checking missing values\n",
        "print('Is null: \\n', df.isnull().sum() )\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is null: \n",
            " docID        0\n",
            "keyword      0\n",
            "country      0\n",
            "paragraph    0\n",
            "label        0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "JQyvG1B0pvEI",
        "outputId": "fa1859ae-71a7-479d-a3e8-928be5c1b733"
      },
      "source": [
        "# Turning labels to binary\n",
        "\n",
        "label_dic = {'0':0,\n",
        "             '1':0,\n",
        "             '2':1,\n",
        "             '3':1,\n",
        "             '4':1}\n",
        "df['label'] = df['label'].map(label_dic)\n",
        "print(df['label'].value_counts())\n",
        "sns.countplot(x='label', data=df)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    9112\n",
            "1     946\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcAMX5reo0e1"
      },
      "source": [
        "# Developing models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvza5K7YbJ4H",
        "outputId": "7370e589-44a2-467a-9b69-62b01868b538"
      },
      "source": [
        "# Splitting the data into training (80%) and test set(20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df['paragraph']\n",
        "y = df['label']\n",
        "X_train, X_test, y_train, y_test = train_test_split (X, y, train_size = 0.8, random_state = 42, shuffle = True, stratify=y)\n",
        "print ('Shapes of X_train, y_train: ', X_train.shape, y_train.shape)\n",
        "print ('Shapes of X_test, y_test: ', X_test.shape, y_test.shape)\n",
        "print(y_train.value_counts())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of X_train, y_train:  (8046,) (8046,)\n",
            "Shapes of X_test, y_test:  (2012,) (2012,)\n",
            "0    7289\n",
            "1     757\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvxZkMMco7sB"
      },
      "source": [
        "## Classic ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kso-92jebtft"
      },
      "source": [
        "### Text representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ez7hEFCa5_U",
        "outputId": "151154f5-08e1-40c7-b902-cf6bf81944a8"
      },
      "source": [
        "!pip install stop-words\n",
        "from stop_words import get_stop_words\n",
        "stopwords = get_stop_words('en')\n",
        "from textblob import Word\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#BOW based approaches\n",
        "nlp.init_sims(replace=True) # calling for using syn0norm\n",
        "\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stop-words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=a02bf58ce43c3b3f07cb1420028ca71f81dd505cac6290600f2aae58d6b1e7a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aopPSRVb4lL",
        "outputId": "8b7ff513-4399-463a-b519-b007faff9ded"
      },
      "source": [
        "# Tokenize, and apply word vector averaging to tokenized text\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import logging\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens\n",
        "    \n",
        "\n",
        "X_train_tokenized = X_train.apply(lambda x: w2v_tokenize_text(x)).values\n",
        "X_test_tokenized = X_test.apply(lambda x: w2v_tokenize_text(x)).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(nlp,X_train_tokenized)\n",
        "X_test_word_average = word_averaging_list(nlp,X_test_tokenized)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "WARNING:root:cannot compute similarity with no input []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0O8PduWdnjt"
      },
      "source": [
        "### Creating models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJdUeuNUdmij"
      },
      "source": [
        "# Printing model performance \n",
        "def printing_eval_scores (y_true, y_pred):\n",
        "  print('accuracy score: {}'.format(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
        "  print('precision score: {}'.format(sklearn.metrics.precision_score(y_true, y_pred, average = 'weighted', zero_division=1)))\n",
        "  print('recall score: {}'.format(sklearn.metrics.recall_score(y_true, y_pred,  average = 'weighted', zero_division=1)))\n",
        "  print('F1 score: {}'.format(sklearn.metrics.f1_score(y_true, y_pred,  average = 'weighted', zero_division=1)))\n",
        "  print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2JRHYC7dxi8"
      },
      "source": [
        "# Define a function for creating over sampling \n",
        "def score_model(model):\n",
        "    cv = StratifiedKFold(n_splits=5, random_state=42, shuffle = True)\n",
        "\n",
        "    oversampler = SMOTE(random_state=42)\n",
        "    #oversampler = RandomOverSampler(sampling_strategy='minority')\n",
        "    scores = []\n",
        "\n",
        "    ## on training set, do cv\n",
        "    for train_fold_index, val_fold_index in cv.split(X_train_word_average, y_train):\n",
        "        # Get the training data\n",
        "        X_train_fold, y_train_fold = X_train_word_average[train_fold_index], y_train.iloc[train_fold_index]\n",
        "        # Get the validation data\n",
        "        X_val_fold, y_val_fold = X_train_word_average[val_fold_index], y_train.iloc[val_fold_index]\n",
        "\n",
        "        # Upsample only the data in the training section\n",
        "        X_train_fold_upsample, y_train_fold_upsample = oversampler.fit_resample(X_train_fold,\n",
        "                                                                           y_train_fold)\n",
        "        # Fit the model on the upsampled training data\n",
        "        model.fit(X_train_fold_upsample, y_train_fold_upsample)\n",
        "        # Score the model on the (non-upsampled) validation data\n",
        "        score = accuracy_score(y_val_fold, model.predict(X_val_fold)) #  average= 'weighted' for F1\n",
        "        scores.append(score)\n",
        "    print('Average of acuracy score in training: %s' % np.array(scores).mean())\n",
        "\n",
        "    ## on test set\n",
        "    y_pred = model.predict(X_test_word_average)\n",
        "    test_score = accuracy_score( y_test,y_pred)\n",
        "    printing_eval_scores (y_test, y_pred)\n",
        "    report_scores = {'accuracy_folds':np.array(scores),'accuracy_test':test_score, 'y_predicted':y_pred }\n",
        "    return report_scores #(np.array(scores),test_score,y_pred )       #(np.array(scores).mean(), np.array(scores).std())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzbE1tOCiUp9",
        "outputId": "7603fe68-80ab-4334-f81d-66b20ade0833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Running all models together\n",
        "# Compare Algorithms\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='lbfgs', max_iter=700)))\n",
        "models.append(('RF', RandomForestClassifier()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('DT', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC(decision_function_shape='ovo', probability=True)))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "score_test = []\n",
        "names = []\n",
        "report_scores_all = []\n",
        "for name, model in models:\n",
        "  #fold_scores, test_score = score_model(model)\n",
        "  report_scores = score_model(model)\n",
        "  report_scores_all.append(report_scores)\n",
        "  #results.append(fold_scores)\n",
        "  #score_test.append(test_score)\n",
        "  results.append(report_scores['accuracy_folds'])\n",
        "  score_test.append(report_scores['accuracy_test'])\n",
        "  names.append(name)\n",
        "  # msg = \"%s: %f (%f)\" % (name, fold_scores.mean(), fold_scores.std())\n",
        "  msg = \"%s: %f (%f)\" % (name, report_scores['accuracy_folds'].mean(), report_scores['accuracy_folds'].std())\n",
        "  print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-9537f2e0c30a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m#fold_scores, test_score = score_model(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mreport_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mreport_scores_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m#results.append(fold_scores)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-e86f2205bb54>\u001b[0m in \u001b[0;36mscore_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0moversampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#oversampler = RandomOverSampler(sampling_strategy='minority')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SMOTE' is not defined"
          ]
        }
      ]
    }
  ]
}