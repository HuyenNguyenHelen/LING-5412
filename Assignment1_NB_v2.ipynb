{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVP2fZtKSWigsXn7/6BK1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HuyenNguyenHelen/LING-5412/blob/main/Assignment1_NB_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykgkcRVuf_ff"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tarfile\n",
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import cross_validate\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l31ENtp0gCLt"
      },
      "source": [
        "my_tar = tarfile.open('/content/lingspam_public.tar.gz')\n",
        "my_tar.extractall('/content/') \n",
        "my_tar.close()\n",
        "train_path = '/content/lingspam_public/lemm_stop/part1'  # for training      #spams: spmsg*.txt\n",
        "test_path = '/content/lingspam_public/lemm_stop/part10'   # for testing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7NlgNF1gEYW",
        "outputId": "02176382-c392-4cdf-cdb8-dba59ba50b9e"
      },
      "source": [
        "def to_dict (path):\n",
        "  data_dict = dict()\n",
        "  data_dict[1] = []\n",
        "  data_dict[0] = []\n",
        "  for file in os.listdir(path):  \n",
        "    doc = open (path + '/'+ file, 'r')\n",
        "    if 'spmsg' in file:\n",
        "      data_dict[1].append(doc.read())\n",
        "    else:\n",
        "      data_dict[0].append(doc.read())\n",
        "  print ('number of spams: {}'.format(len(data_dict[1])))\n",
        "  print ('number of not_spams: {}'.format(len(data_dict[0])))\n",
        "  n_docs = len(os.listdir(path))\n",
        "  return data_dict, n_docs\n",
        "\n",
        "print('training set:')\n",
        "training, n_docs_train = to_dict (train_path)\n",
        "print('number of doc: {}'.format(n_docs_train))\n",
        "\n",
        "print('\\ntesting set:')\n",
        "testing, n_docs_test = to_dict (test_path)\n",
        "print('number of doc: {}'.format(n_docs_test))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set:\n",
            "number of spams: 48\n",
            "number of not_spams: 241\n",
            "number of doc: 289\n",
            "\n",
            "testing set:\n",
            "number of spams: 49\n",
            "number of not_spams: 242\n",
            "number of doc: 291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ki_OX4JlgHb0",
        "outputId": "bab3dcfb-2691-4fa9-eaba-78e97b694b33"
      },
      "source": [
        "def to_bow (data_dict):\n",
        "  bows = {}\n",
        "  bows[0], bows[1] = [], []\n",
        "  for doc in data_dict[0]:\n",
        "    bows[0].extend(doc.split())\n",
        "  for doc in data_dict[1]:\n",
        "    bows[1].extend(doc.split())\n",
        "  return bows\n",
        "\n",
        "def train_NB (training):\n",
        "  bows = to_bow (training)\n",
        "  set_V = set(bows[1] + bows[0])\n",
        "  print(len(bows[1] + bows[0]), len(set_V))\n",
        "  results={}\n",
        "  for c in training.keys():\n",
        "    results[c]={}\n",
        "    loglikelihood_c = {}\n",
        "    n_c = len(training[c])\n",
        "    logprior_c = np.log(n_c/n_docs_train)\n",
        "    count_w_c = {}\n",
        "    for doc in training[c]:\n",
        "      for token in doc.split():\n",
        "        count_w_c[token] = count_w_c.get(token, 0)+1\n",
        "    for w in count_w_c.keys():\n",
        "      loglikelihood_w = np.log(count_w_c[w]+1/(sum(count_w_c.values())+len(set_V)))\n",
        "      loglikelihood_c[w] = loglikelihood_w\n",
        "\n",
        "    results[c]['likelihood_w']=loglikelihood_c\n",
        "    print(sum(count_w_c.values()))\n",
        "    results[c]['logprior_c']=logprior_c\n",
        "    results[c]['set_V']=set_V\n",
        "  #print(results[1]['likelihood_w'])\n",
        "  return results\n",
        "\n",
        "train_result = train_NB (training)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99476 11602\n",
            "30645\n",
            "68831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0qcXlnBkAOd",
        "outputId": "11c7ce8b-7e99-464e-d50d-6e24fb48f434"
      },
      "source": [
        "train_result[1].keys()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['likelihood_w', 'logprior_c', 'set_V'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2GZmGBNgNFK",
        "outputId": "d200d469-8307-4993-cd14-bb73c085f60f"
      },
      "source": [
        "X_train = training[0]+ training[1]\n",
        "y_train = [0]*len(training[0]) + [1]*len(training[1])\n",
        "\n",
        "X_test = testing[0]+ testing[1]\n",
        "y_true = [0]*len(testing[0]) + [1]*len(testing[1])\n",
        "def test_NB (testing):\n",
        "  prediction = []\n",
        "  X_test = testing[0]+ testing[1]\n",
        "  for doc in X_test:\n",
        "    spam_loglikelihoods, nonspam_loglikelihoods = [], []\n",
        "    spam_score=0\n",
        "    nonspam_score = 0\n",
        "    for w in doc.split():\n",
        "      if w not in train_result[0]['set_V']: continue\n",
        "      spam_loglikelihoods.append(train_result[1]['likelihood_w'][w] if w in train_result[1]['likelihood_w'].keys() else 0)\n",
        "      nonspam_loglikelihoods.append(train_result[0]['likelihood_w'][w] if w in train_result[0]['likelihood_w'].keys() else 0)\n",
        "    spam_score += sum(spam_loglikelihoods)\n",
        "    nonspam_score += sum(nonspam_loglikelihoods)\n",
        "\n",
        "    spam_logprior = train_result[1]['logprior_c']\n",
        "    nonspam_logprior = train_result[0]['logprior_c']\n",
        "    spam_score += spam_logprior\n",
        "    nonspam_score += nonspam_logprior\n",
        "    if spam_score > nonspam_score:\n",
        "      prediction.append(1)\n",
        "    else:\n",
        "      prediction.append(0)\n",
        "  return prediction\n",
        "\n",
        "y_pred = test_NB (testing)\n",
        "# print(y_true)\n",
        "# print(y_pred)\n",
        "\n",
        "print('accuracy on training set: {}'.format(sklearn.metrics.accuracy_score(y_train, test_NB(training))))\n",
        "print(classification_report(y_train, test_NB(training)))\n",
        "\n",
        "print('\\naccuracy on test set: {}'.format(sklearn.metrics.accuracy_score(y_true, y_pred)))\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on training set: 0.9307958477508651\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      1.00      0.96       241\n",
            "           1       1.00      0.58      0.74        48\n",
            "\n",
            "    accuracy                           0.93       289\n",
            "   macro avg       0.96      0.79      0.85       289\n",
            "weighted avg       0.94      0.93      0.92       289\n",
            "\n",
            "\n",
            "accuracy on test set: 0.852233676975945\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.98      0.92       242\n",
            "           1       0.67      0.24      0.36        49\n",
            "\n",
            "    accuracy                           0.85       291\n",
            "   macro avg       0.77      0.61      0.64       291\n",
            "weighted avg       0.83      0.85      0.82       291\n",
            "\n"
          ]
        }
      ]
    }
  ]
}